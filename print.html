<!DOCTYPE HTML>
<html lang="zh-CN" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Siu 的笔记本</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
        <link rel="stylesheet" href="theme/style.css">
        

        

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');
                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }
                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="SUMMARY.html"><strong aria-hidden="true">1.</strong> 思考和总结🤔</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="mgmt/srcwd/index.html"><strong aria-hidden="true">1.1.</strong> 团队人员定义模型</a></li><li class="chapter-item "><a href="tech/backend/java-mem-mgmt/java-memory-management.html"><strong aria-hidden="true">1.2.</strong> 谈谈 Java 的内存管理（doing）</a></li></ol></li><li class="chapter-item expanded "><a href="SUMMARY.html"><strong aria-hidden="true">2.</strong> 架构和设计</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="tech/project/AAA/index.html"><strong aria-hidden="true">2.1.</strong> DDD 实践：应用架构原型（doing）</a></li><li class="chapter-item "><a href="tech/backend/Java-Backend-Framework-Selection-Guide.html"><strong aria-hidden="true">2.2.</strong> Java 后端框架选型指南（doing）</a></li><li class="chapter-item "><a href="tech/project/PGHA/pg-ha-solution.html"><strong aria-hidden="true">2.3.</strong> PG HA 方案</a></li><li class="chapter-item "><a href="tech/project/kubesphere/基于Linux安装kubesphere3多节点集群(prod).html"><strong aria-hidden="true">2.4.</strong> KuberSphere 生产部署方案</a></li><li class="chapter-item "><a href="tech/project/lwpoc/lwpoc/架构/构建实时湖仓.html"><strong aria-hidden="true">2.5.</strong> 构建实时湖仓</a></li><li class="chapter-item "><a href="tech/project/cicd/index.html"><strong aria-hidden="true">2.6.</strong> CICD 设计</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="tech/project/cicd/design/CICD架构.html"><strong aria-hidden="true">2.6.1.</strong> CI/CD 架构</a></li><li class="chapter-item "><a href="tech/project/cicd/design/Jenkins_Cluster.html"><strong aria-hidden="true">2.6.2.</strong> Jenkins 集群</a></li><li class="chapter-item "><a href="tech/project/cicd/design/多分支流水线设计.html"><strong aria-hidden="true">2.6.3.</strong> 多分支流水线设计</a></li><li class="chapter-item "><a href="tech/project/cicd/design/cec-jpl设计.html"><strong aria-hidden="true">2.6.4.</strong> cec-jpl 设计</a></li><li class="chapter-item "><a href="tech/project/cicd/design/数据库自动化.html"><strong aria-hidden="true">2.6.5.</strong> 数据库自动化</a></li><li class="chapter-item "><a href="tech/project/cicd/design/账号体系.html"><strong aria-hidden="true">2.6.6.</strong> 账号体系</a></li></ol></li><li class="chapter-item "><a href="tech/db/doris/doris-uniq-model/index.html"><strong aria-hidden="true">2.7.</strong> Doris Uniq 模型：分析场景下保证 Key 的唯一性</a></li></ol></li><li class="chapter-item expanded "><a href="SUMMARY.html"><strong aria-hidden="true">3.</strong> 最佳实践</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/index.html"><strong aria-hidden="true">3.1.</strong> 怎样写一个技术方案的大纲</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/template.html"><strong aria-hidden="true">3.1.1.</strong> 《技术解决方案》模版</a></li></ol></li><li class="chapter-item "><a href="tech/bestpractices/my-toolchain.html"><strong aria-hidden="true">3.2.</strong> 分享一下我的工具清单</a></li><li class="chapter-item "><a href="tech/bestpractices/sql性能测试工具的设计.html"><strong aria-hidden="true">3.3.</strong> sql 性能测试工具的设计</a></li><li class="chapter-item "><a href="tech/project/jrudf/index.html"><strong aria-hidden="true">3.4.</strong> Doris Remote UDF 的开发和测试</a></li><li class="chapter-item "><a href="tech/bestpractices/禅道工作流.html"><strong aria-hidden="true">3.5.</strong> 禅道工作流</a></li><li class="chapter-item "><a href="tech/bestpractices/单元测试规范.html"><strong aria-hidden="true">3.6.</strong> 单元测试规范</a></li><li class="chapter-item "><a href="tech/bestpractices/数据库自动化-Flyway使用规范.html"><strong aria-hidden="true">3.7.</strong> 数据库自动化：Flyway</a></li><li class="chapter-item "><a href="tech/bestpractices/语义化版本控制规范.html"><strong aria-hidden="true">3.8.</strong> 语义化版本</a></li><li class="chapter-item "><a href="tech/bestpractices/API设计规范.html"><strong aria-hidden="true">3.9.</strong> API设计规范</a></li><li class="chapter-item "><a href="tech/bestpractices/git-collaborative-development-tutorials/git协同开发指南.html"><strong aria-hidden="true">3.10.</strong> git 协同开发指南</a></li><li class="chapter-item "><a href="tech/bestpractices/code-review-guide-baseon-gitlab.html"><strong aria-hidden="true">3.11.</strong> Gitlab Code Review 指南</a></li><li class="chapter-item "><a href="tech/bestpractices/gitlab-issue-workflow.html"><strong aria-hidden="true">3.12.</strong> Gitlab Issue 工作流</a></li><li class="chapter-item "><a href="tech/bestpractices/Python编码规范.html"><strong aria-hidden="true">3.13.</strong> Python 编码规范</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Siu 的笔记本</h1>

                    <div class="right-buttons">
                        
                        
                        <a href="https://github.com/siu91/notebook" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                        

                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <!-- Page table of contents -->
                    <div class="sidetoc"><nav class="pagetoc"></nav></div>
                    <main>
                        <h1><a class="header" href="#siu-的笔记本" id="siu-的笔记本">Siu 的笔记本</a></h1>
<ul>
<li>
<p><a href="./SUMMARY.html">思考和总结🤔</a></p>
<ul>
<li><a href="./mgmt/srcwd/index.html">团队人员定义模型</a></li>
<li><a href="./tech/backend/java-mem-mgmt/java-memory-management.html">谈谈 Java 的内存管理（doing）</a></li>
</ul>
</li>
<li>
<p><a href="./SUMMARY.html">架构和设计</a></p>
<ul>
<li><a href="./tech/project/AAA/README.html">DDD 实践：应用架构原型（doing）</a></li>
<li><a href="./tech/backend/Java-Backend-Framework-Selection-Guide.html">Java 后端框架选型指南（doing）</a></li>
<li><a href="./tech/project/PGHA/pg-ha-solution.html">PG HA 方案</a></li>
<li><a href="./tech/project/kubesphere/%E5%9F%BA%E4%BA%8ELinux%E5%AE%89%E8%A3%85kubesphere3%E5%A4%9A%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4(prod).html">KuberSphere 生产部署方案</a></li>
<li><a href="./tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/%E6%9E%84%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%B9%96%E4%BB%93.html">构建实时湖仓</a></li>
<li><a href="./tech/project/cicd/README.html">CICD 设计</a>
<ul>
<li><a href="./tech/project/cicd/design/CICD%E6%9E%B6%E6%9E%84.html">CI/CD 架构</a></li>
<li><a href="./tech/project/cicd/design/Jenkins_Cluster.html">Jenkins 集群</a></li>
<li><a href="./tech/project/cicd/design/%E5%A4%9A%E5%88%86%E6%94%AF%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%AE%BE%E8%AE%A1.html">多分支流水线设计</a></li>
<li><a href="./tech/project/cicd/design/cec-jpl%E8%AE%BE%E8%AE%A1.html">cec-jpl 设计</a></li>
<li><a href="./tech/project/cicd/design/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%87%AA%E5%8A%A8%E5%8C%96.html">数据库自动化</a></li>
<li><a href="./tech/project/cicd/design/%E8%B4%A6%E5%8F%B7%E4%BD%93%E7%B3%BB.html">账号体系</a></li>
</ul>
</li>
<li><a href="./tech/db/doris/doris-uniq-model/index.html">Doris Uniq 模型：分析场景下保证 Key 的唯一性</a></li>
</ul>
</li>
<li>
<p><a href="./SUMMARY.html">最佳实践</a></p>
<ul>
<li><a href="./tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/index.html">怎样写一个技术方案的大纲</a>
<ul>
<li><a href="./tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/template.html">《技术解决方案》模版</a></li>
</ul>
</li>
<li><a href="./tech/bestpractices/my-toolchain.html">分享一下我的工具清单</a></li>
<li><a href="./tech/bestpractices/sql%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E7%9A%84%E8%AE%BE%E8%AE%A1.html">sql 性能测试工具的设计</a></li>
<li><a href="./tech/project/jrudf/README.html">Doris Remote UDF 的开发和测试</a></li>
<li><a href="./tech/bestpractices/%E7%A6%85%E9%81%93%E5%B7%A5%E4%BD%9C%E6%B5%81.html">禅道工作流</a></li>
<li><a href="./tech/bestpractices/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E8%A7%84%E8%8C%83.html">单元测试规范</a></li>
<li><a href="./tech/bestpractices/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%87%AA%E5%8A%A8%E5%8C%96-Flyway%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83.html">数据库自动化：Flyway</a></li>
<li><a href="./tech/bestpractices/%E8%AF%AD%E4%B9%89%E5%8C%96%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E8%A7%84%E8%8C%83.html">语义化版本</a></li>
<li><a href="./tech/bestpractices/API%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83.html">API设计规范</a></li>
<li><a href="./tech/bestpractices/git-collaborative-development-tutorials/git%E5%8D%8F%E5%90%8C%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.html">git 协同开发指南</a></li>
<li><a href="./tech/bestpractices/code-review-guide-baseon-gitlab.html">Gitlab Code Review 指南</a></li>
<li><a href="./tech/bestpractices/gitlab-issue-workflow.html">Gitlab Issue 工作流</a></li>
<li><a href="./tech/bestpractices/Python%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83.html">Python 编码规范</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#团队人员定义模型" id="团队人员定义模型">团队人员定义模型</a></h1>
<blockquote>
<p>By <a href="mgmt/srcwd/">Siu</a> 2022/4/13</p>
</blockquote>
<p>最近看到一个组织/团队人员定义的模型，对于管理来说人员的定义也是比较重要的一部分，可以从人员定义看到团队的状态、发展、个体的诉求、改进的方向；同时人员定义模型对于组织团队、招聘、考核、人员培养、团队整合等都有一定的指导意义。</p>
<p>没有找到一些很全的资料，遂整理了一个模型图，一遍整理一边立体的理解。</p>
<p>理解的过程还是有很多问题，比如：</p>
<ul>
<li>
<p>Rabbit 的危害有多大？</p>
</li>
<li>
<p>清理了 Rabbit，就能解决死海效应吗？</p>
</li>
<li>
<p>怎么留住 Star ？</p>
</li>
<li>
<p>Star 变成 Cow 是不是不一定是坏处？</p>
</li>
<li>
<p>Wolf 是不是可能变成 Star ？</p>
</li>
<li>
<p>这个模型是不是还有本质的缺陷，或是盲区？</p>
</li>
</ul>
<p><img src="mgmt/srcwd/assets/srcwd.png" alt="srcwd" /></p>
<h1><a class="header" href="#谈谈-java-内存的管理" id="谈谈-java-内存的管理">谈谈 Java 内存的管理</a></h1>
<blockquote>
<p>By <a href="tech/backend/java-mem-mgmt/">Siu</a> 2022/3/31</p>
</blockquote>
<p>从 VM、GC 语言角度，JavaEr 很少会关注到内存的管理，但是所有程序的执行都避不开对内存使用的申请，以及回收；从现有主流的语言来看内存的管理大致会分为3类：</p>
<ul>
<li>使用和分配都由用户去决定；C 就是一个代表</li>
<li>使用由用户来关注，回收交给 GC；典型如 Java，GO</li>
<li>由编译系统来管理：Rust 的所有权系统就是这样的一个强大的内存管理系统</li>
</ul>
<p>C 选择了“相信”用户，Java 选择了”包容“用户，Rust 选择了“教育”用户。</p>
<p>Java 用GC 给用户带来了友好，只需要关注定义、赋值、创建对象，其它交给 GC；孰优孰劣，不是今天的主题，还是回到 Java 内存的管理是怎样的？</p>
<h2><a class="header" href="#栈和堆" id="栈和堆">栈和堆</a></h2>
<p>栈和堆是编程语言中最基础的数据结构，栈和堆的的作用就是为程序提供运行时的内存空间。</p>
<p><strong>栈（Stack）</strong></p>
<p>栈是先入后出（FILO），可以类比为叠盘子，增加一个盘子<strong>只能</strong>从顶部（入栈），取下一个盘子<strong>只能</strong>从顶部（出栈）。</p>
<p>栈中的所有数据都必须占用已知且固定大小的内存空间。</p>
<p><strong>堆（Heap）</strong></p>
<p>与栈不同，对于大小未知或者可能变化的数据，我们需要将它存储在堆上。</p>
<p>当向堆上放入数据时，需要请求一定大小的内存空间。</p>
<p><strong>性能</strong></p>
<p>写入方面：入栈比在堆上分配内存要快，因为入栈时操作系统无需分配新的空间，只需要将新数据放入栈顶即可。相比之下，在堆上分配内存则需要更多的工作，这是因为操作系统必须首先找到一块足够存放数据的内存空间，接着做一些记录为下一次分配做准备。</p>
<p>读取方面：栈数据往往可以直接存储在 CPU 高速缓存中（高速缓存和内存的访问速度差异在 10 倍以上！），而堆数据只能存储在内存中。访问堆上的数据比访问栈上的数据慢，因为必须先访问栈再通过栈上的指针来访问内存。</p>
<p>因此，处理器处理和分配在栈上数据会比在堆上的数据更加高效。</p>
<h2><a class="header" href="#jvm-规范" id="jvm-规范">JVM 规范</a></h2>
<p><strong>JVM 规范定义</strong></p>
<p><img src="tech/backend/java-mem-mgmt/assets/jvm.png" alt="JVM" /></p>
<blockquote>
<p><em><strong>注：</strong></em></p>
<ul>
<li>
<p>类加载系统：负责从文件系统或是从网络中加载class信息，加载的信息存放在一个称之为“方法区”的内存空间</p>
</li>
<li>
<p>执行引擎：是jvm非常核心的组件，它负责执行jvm的字节码，一般先会编译成机器码后执行。</p>
</li>
<li>
<p>垃圾收集系统：GC垃圾回收，保证我们程序能够有足够的内存空间运行，回收掉内存中已经无效的数据。回收算法一般有<strong>标记清除</strong>算法，<strong>复制</strong>算法，<strong>标记整理</strong>算法等。</p>
</li>
</ul>
</blockquote>
<h3><a class="header" href="#jvm-的内存结构runtime-data-area" id="jvm-的内存结构runtime-data-area">JVM 的内存结构（Runtime Data Area）</a></h3>
<p><img src="tech/backend/java-mem-mgmt/assets/jvm-runtime-data-area.png" alt="jvm-runtime-data-area" /></p>
<p>JVM 规范定义中的内存模型如上图中的运行时数据区中的描述，有以下主要定义：</p>
<ul>
<li>
<p>方法区（Method Area）：存储已被类加载系统加载的类信息、常量、静态变量等；</p>
<ul>
<li>
<p>JVM 规范中的定义：实现有“元空间”、“永久代”；</p>
</li>
<li>
<p>方法区在JDK7及之前，是由堆中的”永久代（PermGen）“作为实现，逻辑上与堆是连续的内存空间；</p>
</li>
<li>
<p>JDK7 开始移除永久代，在 JDK8时正式被移除，方法区的定义由元空间在本地内存中实现；</p>
</li>
<li>
<p>内存异常：OutOfMemoryError：Metaspace、OutOfMemoryError：PermGen space</p>
</li>
</ul>
</li>
<li>
<p>VM 栈（Java Virtual Machine Stack）：</p>
<ul>
<li>描述方法执行过程的内存模型；</li>
<li>方法执行时，同时会创建一个栈镇（Stack Frame）用于存储：
<ul>
<li>局部变量表：方法参数、方法体内局部变量、基本类型、对象引用（指针）、返回地址类型</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#方法区method-area" id="方法区method-area">方法区（Method Area）</a></h4>
<p>方法区（Methed Area）用于存储已被虚拟机加载的<strong>类信息、常量、静态变量</strong>、即时编译后的代码等数据。</p>
<blockquote>
<p>知识点：<strong>方法区、永久代（PermGen space）、</strong> <strong>Metaspace（元空间）的区别</strong></p>
<p>方法区， 是 《JVM 规范》 定义的，所有虚拟机必须有的。
针对 HotSpot 虚拟机 ：</p>
<ul>
<li>JDK7及之前， PermGen space 就是 方法区。</li>
<li>JDK8及之后， PermGen space 被移除， 换成 Metaspace（元空间），也是对<strong>方法区</strong>的新的实现。</li>
</ul>
<p><code>其实，移除永久代的工作从JDK1.7就开始了。JDK1.7中，存储在永久代的部分数据就已经转移到了Java Heap或者是 Native Heap。但永久代仍存在于JDK1.7中，并没完全移除，譬如符号引用(Symbols)转移到了native heap；字面量(interned strings)转移到了java heap；类的静态变量(class statics)转移到了java heap。</code></p>
<p>元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代最大的区别在于：元空间不在虚拟机设置的内存中，而是使用本地内存</p>
<p><strong>永久代</strong>
<strong>Java7及以前版本的Hotspot中方法区位于永久代中</strong>。同时，永久代和堆是相互隔离的，但它们使用的物理内存是连续的。也有将方法去归于堆的，但称之为非堆。</p>
<p><strong>元空间</strong></p>
<p>在Java8中，元空间(Metaspace)登上舞台，方法区存在于元空间(Metaspace)。同时，元空间不再与堆连续，而且是存在于本地内存（Native memory）。</p>
<p>元空间存在于本地内存，意味着只要本地内存足够，它不会出现像永久代中“java.lang.OutOfMemoryError: PermGen space”这种错误。</p>
<p>Metaspace 区域位于堆外，所以它的最大内存大小取决于系统内存，而不是堆大小。</p>
<p>默认情况下元空间是可以无限使用本地内存的，但为了不让它如此膨胀，JVM同样提供了参数来限制它使用的使用。</p>
<ul>
<li>-XX:MetaspaceSize，metadata的初始空间配额，以bytes为单位，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当的降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize（如果设置了的话），适当的提高该值。</li>
<li>-XX：MaxMetaspaceSize，可以为metadata分配的最大空间。默认是没有限制的。</li>
</ul>
</blockquote>
<h4><a class="header" href="#堆heap" id="堆heap">堆（Heap）</a></h4>
<p>Java堆（Java Heap）是Java虚拟机中内存最大的一块，是被所有线程共享的，在虚拟机启动时候创建，Java堆唯一的目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。</p>
<p>这个区域被划分为年轻代和老年代的，我们经常接触的GC垃圾回收机制，就是主要回收堆空间的垃圾数据。
堆空间里的数据，是被所有线程所共享的，所以会存在线程安全问题，所以那些锁就是为了解决堆空间数线程安全问题而生的。</p>
<p>随着JIT编译器的发展和逃逸分析技术的逐渐成熟，栈上分配、标量替换优化的技术将会导致一些微妙的变化，所有的对象都分配在堆上渐渐变得不那么“绝对”了。</p>
<h4><a class="header" href="#vm-栈" id="vm-栈">VM 栈</a></h4>
<p>Java虚拟机栈（Java Virtual Machine Stacks）描述的是Java方法执行的内存模型。</p>
<p>每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储:</p>
<ul>
<li>
<p>局部变量表（Local Variable Array）</p>
</li>
<li>
<p>操作数栈（Operand Stack）</p>
</li>
<li>
<p>动态链接（Dynamic Linking）</p>
</li>
<li>
<p>返回地址（Return Address）</p>
</li>
<li>
<p>指向运行时常量池的引用</p>
</li>
</ul>
<p>每个方法从调用直至执行完成的过程，都对应着一个栈帧在虚拟机栈中入栈到出栈的过程。</p>
<p>栈空间是每个线程独有的，互相直接不能访问。</p>
<blockquote>
<p>知识点：动态链接</p>
<p>每一个栈帧内部都包含一个指向<strong>运行时常量池</strong>中该栈帧所属方法的引用，包含这个引用的目的就是为了支持当前方法的代码能够实现<strong>动态链接（Dynamic Linking）</strong>。比如：invokedynamic指令</p>
<p>在Java源文件被编译到字节码文件时，所有的变量和方法引用都作为符号引用（Symbilic Reference）保存在class文件的常量池里。</p>
<p>比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，<strong>动态链接的作用就是为了将这些符号引用转为调用方法的直接引用</strong>。</p>
</blockquote>
<h5><a class="header" href="#压栈出栈过程" id="压栈出栈过程">压栈出栈过程</a></h5>
<p>当方法运行过程中需要创建局部变量时，就将局部变量的值存入栈帧中的局部变量表中。</p>
<p>Java 虚拟机栈的栈顶的栈帧是当前正在执行的活动栈，也就是当前正在执行的方法，PC 寄存器也会指向这个地址。只有这个活动的栈帧的本地变量可以被操作数栈使用，当在这个栈帧中调用另一个方法，与之对应的栈帧又会被创建，新创建的栈帧压入栈顶，变为当前的活动栈帧。</p>
<p>方法结束后，当前栈帧被移出，栈帧的返回值变成新的活动栈帧中操作数栈的一个操作数。如果没有返回值，那么新的活动栈帧中操作数栈的操作数没有变化。</p>
<blockquote>
<p>由于 Java 虚拟机栈是与线程对应的，数据不是线程共享的（也就是线程私有的)，因此不用关心数据一致性问题，也不会存在同步锁的问题。</p>
</blockquote>
<h5><a class="header" href="#局部变量表" id="局部变量表">局部变量表</a></h5>
<p>定义为一个数字数组，主要用于存储方法参数、定义在方法体内部的局部变量，数据类型包括各类<strong>基本数据类型，对象引用，以及 return address 类型</strong>。</p>
<p>局部变量表容量大小是在编译期确定下来的。最基本的存储单元是 slot，32 位占用一个 slot，64 位类型（long 和 double）占用两个 slot。</p>
<p>对于 slot 的理解：</p>
<ul>
<li>JVM 虚拟机会为局部变量表中的每个 slot 都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值。</li>
<li>如果当前帧是由构造方法或者实例方法创建的，那么该对象引用 this，会存放在 index 为 0 的 slot 处，其余的参数表顺序继续排列。</li>
<li>栈帧中的局部变量表中的槽位是可以重复的，如果一个局部变量过了其作用域，那么其作用域之后申明的新的局部变量就有可能会复用过期局部变量的槽位，从而达到节省资源的目的。</li>
</ul>
<p>在栈帧中，与性能调优关系最密切的部分，就是局部变量表，方法执行时，虚拟机使用局部变量表完成方法的传递局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收。</p>
<h5><a class="header" href="#操作数栈" id="操作数栈">操作数栈</a></h5>
<ul>
<li><strong>栈顶缓存技术</strong>：由于操作数是存储在内存中，频繁的进行内存读写操作影响执行速度，将栈顶元素全部缓存到物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率。</li>
<li>每一个操作数栈会拥有一个明确的栈深度，用于存储数值，最大深度在编译期就定义好。32bit 类型占用一个栈单位深度，64bit 类型占用两个栈单位深度操作数栈。</li>
<li>并非采用访问索引方式进行数据访问，而是只能通过标准的入栈、出栈操作完成一次数据访问。</li>
</ul>
<h5><a class="header" href="#方法的调用" id="方法的调用">方法的调用</a></h5>
<ul>
<li>静态链接：当一个字节码文件被装载进 JVM 内部时，如果被调用的目标方法在编译期可知，且运行时期间保持不变，这种情况下降调用方的符号引用转为直接引用的过程称为静态链接。</li>
<li>动态链接：如果被调用的方法无法再编译期被确定下来，只能在运行期将调用的方法的符号引用转为直接引用，这种引用转换过程具备动态性，因此被称为动态链接。</li>
<li>方法绑定
<ul>
<li>早期绑定：被调用的目标方法如果再编译期可知，且运行期保持不变。</li>
<li>晚期绑定：被调用的方法在编译期无法被确定，只能够在程序运行期根据实际的类型绑定相关的方法。</li>
</ul>
</li>
<li>非虚方法：如果方法在编译期就确定了具体的调用版本，则这个版本在运行时是不可变的。这样的方法称为非虚方法静态方法，私有方法，final 方法，实例构造器，父类方法都是非虚方法,除了这些以外都是虚方法。</li>
<li>虚方法表：面向对象的编程中，会很频繁的使用动态分配，如果每次动态分配的过程都要重新在类的方法元数据中搜索合适的目标的话，就可能影响到执行效率，因此为了提高性能，JVM 采用在类的方法区建立一个虚方法表，使用索引表来代替查找。
<ul>
<li>每个类都有一个虚方法表，表中存放着各个方法的实际入口。</li>
<li>虚方法表会在类加载的链接阶段被创建，并开始初始化，类的变量初始值准备完成之后，JVM 会把该类的方法也初始化完毕。</li>
</ul>
</li>
<li>方法重写的本质
<ul>
<li>找到操作数栈顶的第一个元素所执行的对象的实际类型，记做 C。如果在类型 C 中找到与常量池中描述符和简单名称都相符的方法，则进行访问权限校验。</li>
<li>如果通过则返回这个方法的直接引用，查找过程结束；如果不通过，则返回 java.lang.IllegalAccessError 异常。</li>
<li>否则，按照继承关系从下往上依次对 C 的各个父类进行上一步的搜索和验证过程。</li>
<li>如果始终没有找到合适的方法，则抛出 java.lang.AbstractMethodError 异常。</li>
</ul>
</li>
</ul>
<p>Java 中任何一个普通方法都具备虚函数的特征（运行期确认，具备晚期绑定的特点），C++ 中则使用关键字 virtual 来显式定义。如果在 Java 程序中，不希望某个方法拥有虚函数的特征，则可以使用关键字 final 来标记这个方法。</p>
<h5><a class="header" href="#java-虚拟机栈的特点" id="java-虚拟机栈的特点">Java 虚拟机栈的特点</a></h5>
<ul>
<li>运行速度特别快,仅仅次于 PC 寄存器。</li>
<li>局部变量表随着栈帧的创建而创建，它的大小在编译时确定，创建时只需分配事先规定的大小即可。在方法运行过程中，局部变量表的大小不会发生改变。</li>
<li>Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。
<ul>
<li>StackOverFlowError 若 Java 虚拟机栈的大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度时，抛出 StackOverFlowError 异常。</li>
<li>OutOfMemoryError 若允许动态扩展，那么当线程请求栈时内存用完了，无法再动态扩展时，抛出 OutOfMemoryError 异常。</li>
</ul>
</li>
<li>Java 虚拟机栈也是线程私有，随着线程创建而创建，随着线程的结束而销毁。</li>
<li>出现 StackOverFlowError 时，内存空间可能还有很多。</li>
</ul>
<h4><a class="header" href="#本地方法栈" id="本地方法栈">本地方法栈</a></h4>
<p>本地方法栈（Native Method Stack）与虚拟机栈的作用是一样的，只不过 VM栈是服务Java方法的，而本地方法栈是为调用Native方法服务的（即JDK中用native修饰的方法）。</p>
<p>在Java虚拟机规范中对于本地方法栈没有特殊的要求，虚拟机可以自由的实现它，因此在Sun HotSpot虚拟机直接把本地方法栈和虚拟机栈合二为一了。</p>
<h4><a class="header" href="#程序计数器寄存器" id="程序计数器寄存器">程序计数器/寄存器</a></h4>
<p>程序计数器是一块较小的内存空间，是当前线程正在执行的那条字节码指令的地址。若当前线程正在执行的是一个本地方法，那么此时程序计数器为<code>Undefined</code>。</p>
<h5><a class="header" href="#作用" id="作用">作用</a></h5>
<ul>
<li>字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制。</li>
<li>在多线程情况下，程序计数器记录的是当前线程执行的位置，从而当线程切换回来时，就知道上次线程执行到哪了。</li>
</ul>
<h5><a class="header" href="#特点" id="特点">特点</a></h5>
<ul>
<li>是一块较小的内存空间。</li>
<li>线程私有，每条线程都有自己的程序计数器。</li>
<li>生命周期：随着线程的创建而创建，随着线程的结束而销毁。</li>
<li>是唯一一个不会出现 <code>OutOfMemoryError</code> 的内存区域。</li>
</ul>
<h4><a class="header" href="#直接内存" id="直接内存">直接内存</a></h4>
<p>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但这部分也是被频繁的读写使用，也可能会导致<code>OutOfMemoryError</code>异常的出现。</p>
<p>Java的 <code>NIO</code>中的<code>allocateDirect</code>方法是可以直接使用直接内存的，能显著的提高读写的速度。</p>
<h2><a class="header" href="#从线程共享角度看内存区域" id="从线程共享角度看内存区域">从线程共享角度看内存区域</a></h2>
<h3><a class="header" href="#再看-java-中的栈内存和堆内存" id="再看-java-中的栈内存和堆内存">再看 Java 中的栈内存和堆内存</a></h3>
<h2><a class="header" href="#引用" id="引用">引用</a></h2>
<h2><a class="header" href="#字符串" id="字符串">字符串</a></h2>
<h2><a class="header" href="#gc" id="gc">GC</a></h2>
<h2><a class="header" href="#oom" id="oom">OOM</a></h2>
<ul>
<li><a href="https://github.com/TangBean/understanding-the-jvm/blob/master/Ch1-Java%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/01-OOM%E5%BC%82%E5%B8%B8.md#java-%E5%A0%86%E6%BA%A2%E5%87%BA">Java 堆溢出</a></li>
<li><a href="https://github.com/TangBean/understanding-the-jvm/blob/master/Ch1-Java%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/01-OOM%E5%BC%82%E5%B8%B8.md#java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88%E5%92%8C%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88%E6%BA%A2%E5%87%BA">Java 虚拟机栈和本地方法栈溢出</a></li>
<li><a href="https://github.com/TangBean/understanding-the-jvm/blob/master/Ch1-Java%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/01-OOM%E5%BC%82%E5%B8%B8.md#%E6%96%B9%E6%B3%95%E5%8C%BA%E5%92%8C%E8%BF%90%E8%A1%8C%E6%97%B6%E5%B8%B8%E9%87%8F%E6%B1%A0%E6%BA%A2%E5%87%BA">方法区和运行时常量池溢出</a></li>
<li><a href="https://github.com/TangBean/understanding-the-jvm/blob/master/Ch1-Java%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/01-OOM%E5%BC%82%E5%B8%B8.md#%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA">直接内存溢出</a></li>
</ul>
<h2><a class="header" href="#逃逸分析" id="逃逸分析">逃逸分析</a></h2>
<h2><a class="header" href="#另一种实现netty-中的内存管理" id="另一种实现netty-中的内存管理">另一种实现：Netty 中的内存管理</a></h2>
<h2><a class="header" href="#ref" id="ref">ref</a></h2>
<p><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/index.html">Java 虚拟机规范（英文）</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/346471261">方法区、永久代、元空间辨析</a></p>
<p><a href="https://juejin.cn/post/6844903815754285069">JVM 的组成</a></p>
<p><a href="https://www.cnblogs.com/jichi/p/12580906.html">堆内存：年轻代、年老代、永久代</a></p>
<p><a href="https://www.cnblogs.com/paddix/p/5309550.html">Java 8 内存模型：永久区、元空间实例代码测试</a></p>
<p><a href="https://blog.csdn.net/Ethan_199402/article/details/110431404">元空间和直接内存</a></p>
<p><a href="https://jverson.com/thinking-in-java/jvm/jvm-components.html">jverson.com/thinking-in-java/</a></p>
<p><a href="https://www.zhihu.com/question/48267791">栈帧中的动态链接作用是什么？</a></p>
<p><a href="https://github.com/TangBean/understanding-the-jvm/tree/master/Ch1-Java%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6">深入理解虚拟机笔记</a></p>
<p><a href="https://juejin.cn/post/7026561428538523684">直接内存溢出</a></p>
<p><a href="https://www.cnblogs.com/halberts/p/11918326.html">JVM参数设置-jdk8 </a></p>
<p><a href="https://segmentfault.com/a/1190000037628881">Java 字节码子令集概述</a></p>
<p><a href="https://segmentfault.com/a/1190000039083244">字节码和字节码分析</a></p>
<p><a href="https://blog.csdn.net/antony1776/article/details/89843145">深入理解 JVM 中的 returnAddress</a></p>
<h1><a class="header" href="#siu-的笔记本-1" id="siu-的笔记本-1">Siu 的笔记本</a></h1>
<ul>
<li>
<p><a href="./SUMMARY.html">思考和总结🤔</a></p>
<ul>
<li><a href="./mgmt/srcwd/index.html">团队人员定义模型</a></li>
<li><a href="./tech/backend/java-mem-mgmt/java-memory-management.html">谈谈 Java 的内存管理（doing）</a></li>
</ul>
</li>
<li>
<p><a href="./SUMMARY.html">架构和设计</a></p>
<ul>
<li><a href="./tech/project/AAA/README.html">DDD 实践：应用架构原型（doing）</a></li>
<li><a href="./tech/backend/Java-Backend-Framework-Selection-Guide.html">Java 后端框架选型指南（doing）</a></li>
<li><a href="./tech/project/PGHA/pg-ha-solution.html">PG HA 方案</a></li>
<li><a href="./tech/project/kubesphere/%E5%9F%BA%E4%BA%8ELinux%E5%AE%89%E8%A3%85kubesphere3%E5%A4%9A%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4(prod).html">KuberSphere 生产部署方案</a></li>
<li><a href="./tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/%E6%9E%84%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%B9%96%E4%BB%93.html">构建实时湖仓</a></li>
<li><a href="./tech/project/cicd/README.html">CICD 设计</a>
<ul>
<li><a href="./tech/project/cicd/design/CICD%E6%9E%B6%E6%9E%84.html">CI/CD 架构</a></li>
<li><a href="./tech/project/cicd/design/Jenkins_Cluster.html">Jenkins 集群</a></li>
<li><a href="./tech/project/cicd/design/%E5%A4%9A%E5%88%86%E6%94%AF%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%AE%BE%E8%AE%A1.html">多分支流水线设计</a></li>
<li><a href="./tech/project/cicd/design/cec-jpl%E8%AE%BE%E8%AE%A1.html">cec-jpl 设计</a></li>
<li><a href="./tech/project/cicd/design/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%87%AA%E5%8A%A8%E5%8C%96.html">数据库自动化</a></li>
<li><a href="./tech/project/cicd/design/%E8%B4%A6%E5%8F%B7%E4%BD%93%E7%B3%BB.html">账号体系</a></li>
</ul>
</li>
<li><a href="./tech/db/doris/doris-uniq-model/index.html">Doris Uniq 模型：分析场景下保证 Key 的唯一性</a></li>
</ul>
</li>
<li>
<p><a href="./SUMMARY.html">最佳实践</a></p>
<ul>
<li><a href="./tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/index.html">怎样写一个技术方案的大纲</a>
<ul>
<li><a href="./tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/template.html">《技术解决方案》模版</a></li>
</ul>
</li>
<li><a href="./tech/bestpractices/my-toolchain.html">分享一下我的工具清单</a></li>
<li><a href="./tech/bestpractices/sql%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E7%9A%84%E8%AE%BE%E8%AE%A1.html">sql 性能测试工具的设计</a></li>
<li><a href="./tech/project/jrudf/README.html">Doris Remote UDF 的开发和测试</a></li>
<li><a href="./tech/bestpractices/%E7%A6%85%E9%81%93%E5%B7%A5%E4%BD%9C%E6%B5%81.html">禅道工作流</a></li>
<li><a href="./tech/bestpractices/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E8%A7%84%E8%8C%83.html">单元测试规范</a></li>
<li><a href="./tech/bestpractices/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%87%AA%E5%8A%A8%E5%8C%96-Flyway%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83.html">数据库自动化：Flyway</a></li>
<li><a href="./tech/bestpractices/%E8%AF%AD%E4%B9%89%E5%8C%96%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E8%A7%84%E8%8C%83.html">语义化版本</a></li>
<li><a href="./tech/bestpractices/API%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83.html">API设计规范</a></li>
<li><a href="./tech/bestpractices/git-collaborative-development-tutorials/git%E5%8D%8F%E5%90%8C%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.html">git 协同开发指南</a></li>
<li><a href="./tech/bestpractices/code-review-guide-baseon-gitlab.html">Gitlab Code Review 指南</a></li>
<li><a href="./tech/bestpractices/gitlab-issue-workflow.html">Gitlab Issue 工作流</a></li>
<li><a href="./tech/bestpractices/Python%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83.html">Python 编码规范</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#application-architecture-archetype应用架构原型" id="application-architecture-archetype应用架构原型">Application Architecture Archetype（应用架构原型）</a></h1>
<blockquote>
<p>By <a href="tech/project/AAA/">Siu</a> 2022/4/19</p>
</blockquote>
<h2><a class="header" href="#前言" id="前言">前言</a></h2>
<p>前一段时间在整理后端的架构和选型，关于微服务设计这部分，也预留 DDD 的”作业“，但对于如何工程化落地 DDD 还没有一个清晰的思路，现有应用架构中的分层模型还是 MVC；关于领域划分，边界上下文、防腐层等 DDD 的经典理论抱有”赞同“，却又限制于没有实践指导的“工具”，故一直没有这部分的”行动“。</p>
<p>最近看了 COLA 的架构和一些设计，觉得 COLA 具有足够的理论依据也具有相当的落地实践性，是一个不错的 DDD 落地的方法论和实践指导，但个人在理解 COLA 的设计时还是觉得有一些问题。 主要集中在没有足够的场景案例去分析整个落地实践的路径，没有深入阐述分层分包的原则和实际开发联系；特别是 DEMO 上比较粗糙，与 COLA 阐述的一些架构原则没有呼应，细节上 COLA 中的 DEMO 不具典型意义；另外就是没有介绍对于 DDD 、CQRS 的借鉴，在架构和实践中的关系。</p>
<p>由此，并就想着开始准备自己组装一个 DDD 的落地实践，使用 COLA 的设计理念，融合微服务框架以及包含一些后端开发时会涉及的常用的库/组件（ORM、Flyawy、Skywaking、MapStruct、EventBus等），按照当前我个的理解把这个“脚手架”项目命名为 AAA（Application Architecture Archetype（应用架构原型）），希望能够真正落地实践 DDD，并用于实际项目指导目前团队的应用架构的演进。</p>
<h2><a class="header" href="#ddd-分层架构-todo" id="ddd-分层架构-todo">DDD 分层架构 （todo）</a></h2>
<img src="tech/project/AAA/assets/ddd-layer-arch.webp" style="zoom:50%;" />
<p><em><strong><code>图片来源：《DDD 实战》</code></strong></em></p>
<h2><a class="header" href="#cola-分层架构-todo" id="cola-分层架构-todo">COLA 分层架构 （todo）</a></h2>
<p><img src="tech/project/AAA/assets/cola-layer-arch.png" alt="cola" /></p>
<h2><a class="header" href="#aaa-todo" id="aaa-todo">AAA （todo）</a></h2>
<h1><a class="header" href="#ref-1" id="ref-1">ref</a></h1>
<p><a href="https://www.51cto.com/article/644144.html">DDD 里面的 CQRS 是什么？</a></p>
<p><a href="https://github.com/alibaba/COLA/issues/203">COLA 层次划分理解</a></p>
<p><a href="https://github.com/alibaba/COLA/issues/271">COLA POJO 代码太多的讨论</a></p>
<h1><a class="header" href="#java-后端框架选型指南" id="java-后端框架选型指南">Java 后端框架选型指南</a></h1>
<blockquote>
<p>By <a href="tech/backend/">Siu</a> 2022/3/26</p>
</blockquote>
<h2><a class="header" href="#前言-1" id="前言-1">前言</a></h2>
<p>其实从 2019 年疫情😷刚开始时就开始准备这部分的工作，2020-2021 其实也有了很所实践和总结，但整体还不够全面和立体，故这段时间趁着整理过往的实践再次梳理和总结关于 Java 后端的框架的选型。</p>
<h2><a class="header" href="#整体架构" id="整体架构">整体架构</a></h2>
<blockquote>
<p>整体架构包括了：前端、后端、基础设施、规范、工具链等；这里先放出架构全景，这些其实是经过两年多的实践总结不断迭代的一个成果。</p>
</blockquote>
<p><em><strong><code>图-1:整体架构</code></strong></em></p>
<p><img src="tech/backend/assets/arch-summary.png" alt="" /></p>
<h2><a class="header" href="#服务端架构" id="服务端架构">服务端架构</a></h2>
<p><em><strong><code>图-1:服务端架构</code></strong></em></p>
<p><img src="tech/backend/assets/arch-backend.png" alt="" /></p>
<h2><a class="header" href="#选型" id="选型">选型</a></h2>
<p><em><strong><code>表-1:服务端选型列表</code></strong></em></p>
<table><thead><tr><th>序号</th><th>大类</th><th>分类</th><th>框架/组件/工具/方法模型等</th><th>版本/规格/标准</th><th>备注</th></tr></thead><tbody>
<tr><td>1</td><td>服务端</td><td>语言</td><td>Java</td><td>Oracle JDK 1.8.0_161+</td><td>主要的技术栈为 Java；是否需要考虑 OpenJDK 方案/升级订阅商业版？</td></tr>
<tr><td>2</td><td>服务端</td><td>语言</td><td>Python</td><td>2.7、3.6</td><td>少量使用，多作为脚本或工具模块;</td></tr>
<tr><td>3</td><td>服务端</td><td>语言</td><td>Scala</td><td>2.11.8</td><td>少量使用;Spark  数据处理；</td></tr>
<tr><td>4</td><td>服务端</td><td>框架</td><td>Spring Boot</td><td>2.3.12.RELEASE</td><td>另外关注到的还有更面向云原生的方案（GraalVM）  Quarkus、Spring Native</td></tr>
<tr><td>5</td><td>服务端</td><td>框架</td><td>nacos</td><td>2.1.4.RELEASE</td><td>微服务注册与配置</td></tr>
<tr><td>6</td><td>服务端</td><td>数据库</td><td>MySQL</td><td>5.7.24</td><td>目前Mysql与PG相比，国内占比高，落地方案丰富。运维上无论是当前人员还是招聘市场都是熟悉Mysql远高于PG</td></tr>
<tr><td>7</td><td>服务端</td><td>本地缓存</td><td>Ehcache</td><td>2.x (latest)</td><td>少量项目使用；主要考量本地持久化，当前  Spring Boot 中推荐用 3.x</td></tr>
<tr><td>8</td><td>服务端</td><td>数据库连接池</td><td>Hikari</td><td>/</td><td>1.Druid  高级特性项目中并未被使用，运维本身有其他方式监控SQL     2.Hikari默认被spring体系采用，版本维护与Spring Boot 主版本绑定     3.数据连接池本身与业务代码解耦，变更不涉及到业务代码改动。</td></tr>
<tr><td>9</td><td>服务端</td><td>中间件,OSS</td><td>MinIO</td><td>RELEASE.2020-06-22T03-12-50Z、latest（2021.8 dockerhub）</td><td>MinIO是一套高性能对象存储系统，兼容 Amazon  S3 云存储服务，提供一套完整的OSS方案，支持云原生。近9000多家企业也都在使用MinIO产品。</td></tr>
<tr><td>10</td><td>服务端</td><td>框架,权限</td><td>Shiro</td><td>1.5.3</td><td>权限框架；封装在 UAC  的二方库中；按目前生态的发展会更倾向 Spring Security     风险点：当前的福州在用系统都要从shiro切换到Spring  Security，涉及平台众多，改造工作量较大。从业务角度，改造后没有业务上直接提升。该部分暂时不做变动。</td></tr>
<tr><td>11</td><td>服务端</td><td>中间件,缓存</td><td>Redis</td><td>5.0.x</td><td>缓存；客户端使用 Lettuce 版本与Spring Boot  主版本绑定，封装在 framework2中，redis module</td></tr>
<tr><td>12</td><td>服务端</td><td>中间件,MQ</td><td>Kafka</td><td>1.0.0</td><td>消息队列，客户端使用  Spring Kafka 版本与Spring Boot 主版本绑定；业务上没有特别多的需求，故靠近已有的大数据使用的 kafka</td></tr>
<tr><td>13</td><td>服务端</td><td>框架,ORM</td><td>Mybatis</td><td>/</td><td>封装在 framework2中，data module；也有调研  JPA+QueryDSL 、JOOQ</td></tr>
<tr><td>14</td><td>服务端</td><td>框架,ORM</td><td>MyBatis-Plus</td><td>3.3.2</td><td>MyBatis-Plus VS  tk-mybatis都是基于Mybaits插件功能开发的增强器，当前在功能丰富度和用户热度上  MyBatis-Plus要略优于tk-mybatis。因此统一选型后保留了MyBatis-Plus。</td></tr>
<tr><td>15</td><td>服务端</td><td>工具库,数据自动化</td><td>Flyway</td><td>/</td><td>数据库版本/数据库迁移管理工具；版本与Spring  Boot 主版本绑定</td></tr>
<tr><td>16</td><td>服务端</td><td>框架,单元测试</td><td>Junit</td><td>Junit4</td><td>单元测试</td></tr>
<tr><td>17</td><td>服务端</td><td>框架,参数验证</td><td>Hibernator Validator</td><td>/</td><td>参数校验；</td></tr>
<tr><td>18</td><td>服务端</td><td>工具库,配置加密</td><td>jasypt</td><td>3.0.x</td><td>用于配置文件中的参数值加密，如数据库账号密码；已封装在二方库中</td></tr>
<tr><td>19</td><td>服务端</td><td>工具库,验证码</td><td>kaptcha</td><td>2.3.2</td><td>验证码工具库，https://github.com/penggle/kaptcha</td></tr>
<tr><td>20</td><td>服务端</td><td>工具库,样板代码</td><td>Lombok</td><td>/</td><td>基于注解方式，有效减少样板代码的工具库；版本与Spring  Boot 主版本绑定</td></tr>
<tr><td>21</td><td>服务端</td><td>工具库,JSON</td><td>Jackson</td><td>/</td><td>Spring Boot 默认；版本与Spring Boot  主版本绑定</td></tr>
<tr><td>22</td><td>服务端</td><td>工具库,Log</td><td>Logback + Slf4j</td><td>/</td><td>Spring Boot 默认；版本与Spring Boot  主版本绑定</td></tr>
<tr><td>23</td><td>服务端</td><td>工具库,API 文档</td><td>Swagger</td><td>2.8.0</td><td>封装在 framework2中，data  module；大量使用，默认和前端的API文档对接方式，前端会使用 API json 接口做 mock</td></tr>
<tr><td>24</td><td>服务端</td><td>工具库,API 文档</td><td>Knife4j</td><td>2.0.4</td><td>Swagger UI 增强；</td></tr>
<tr><td>25</td><td>服务端</td><td>可观测性,诊断工具</td><td>SkyWalking</td><td>8.9.1</td><td>微服务日志链路追踪</td></tr>
<tr><td>26</td><td>服务端</td><td>框架,低代码</td><td>magic-api</td><td>1.7.1</td><td>少量实践使用；能有效提高开发效率，比较适用于大屏展示、报表等；同类的还调研了  Dataway</td></tr>
<tr><td>27</td><td>服务端</td><td>构建工具,依赖管理</td><td>Maven</td><td>3.6</td><td>默认唯一的工具，团队开发中约束，主要基于大多数人熟悉 Maven</td></tr>
<tr><td>28</td><td>服务端</td><td>CI</td><td>Jenkins Pipeline</td><td>/</td><td>使用 Jenkins  共享库的方式，自定义编排流水线（Gitlab+Jenkins+Nexus），后续会合并Harbor+k8s</td></tr>
<tr><td>29</td><td>服务端</td><td>云原生,容器化</td><td>Docker</td><td>20.10.5</td><td>实践较少；使用 airflow 时用到 Rancher  1.x + docker（当前已迁移用 docker-compose 方式）；Jenkins 主从集群使用 Docker 构建</td></tr>
<tr><td>30</td><td>服务端</td><td>云原生,容器化</td><td>k8s</td><td>1.18</td><td>运维统一维护支持，开发环境正在使用KubeSphere 容器云纳管工具平台+ k8s ;线上环境构建k8s  使用Grafana监控</td></tr>
<tr><td>31</td><td>服务端</td><td>云原生,微服务框架</td><td>Spring Cloud</td><td>/</td><td>偏向于spring  cloud Alibaba</td></tr>
<tr><td>32</td><td>服务端</td><td>云原生,DevOps</td><td>KubeSphere</td><td>3.1.1</td><td>开发、测试环境使用</td></tr>
<tr><td>33</td><td>服务端</td><td>云原生,持续交付</td><td>Jenkins</td><td>2.277.1</td><td>在非云环境中使用经验较多（交付到主机、虚拟机）；验证环境调研使用过  KubeSphere DevOps</td></tr>
</tbody></table>
<h3><a class="header" href="#适用说明" id="适用说明">适用说明</a></h3>
<h3><a class="header" href="#java-和-spring" id="java-和-spring">Java 和 Spring</a></h3>
<h3><a class="header" href="#数据库连接池orm" id="数据库连接池orm">数据库、连接池、ORM</a></h3>
<h3><a class="header" href="#数据库自动化" id="数据库自动化">数据库自动化</a></h3>
<blockquote>
<p>这部分往往特别容易被忽视，但往往都会因为没有尽早考虑“数据库自动化”而引发不同程度的问题。</p>
</blockquote>
<p>数据库自动化主要的收益有3大部分：</p>
<ul>
<li>开发：sql 也是代码的一部分，要编码-》测试-》集成-》上线，用开发最熟悉的方式去管理；</li>
<li>CI：对于ci ，数据库自动化是特别容易忽视，到问题出现时才会去想到要去构建数据库自动化的方案；</li>
<li>产品化：对于很多产品来说产品的迭代升级是一个重要的管理工作，数据库自动化会为此带来不可或缺的收益：多个版本的升级可以是一个”内治理的平衡“，不需要团队花费过多的精力。</li>
</ul>
<p>在实践中主要的矛盾在于，“数据库自动化”这部分对于运维/DBA是黑盒，他们往往希望能够去审计上线的 SQL，所以需要根据团队具体情况去沟通，让运维/DBA了解这部分的收益和风险。</p>
<h3><a class="header" href="#api-文档" id="api-文档">API 文档</a></h3>
<h3><a class="header" href="#项目文档wiki" id="项目文档wiki">项目文档、WIKI</a></h3>
<h3><a class="header" href="#cicd--gitflow" id="cicd--gitflow">CICD &amp; GitFlow</a></h3>
<h4><a class="header" href="#ci-的工具链" id="ci-的工具链">CI 的工具链</a></h4>
<p>目前经过两年过的实践比较合适目前团队的 CI 工具链主要由一下构成的：</p>
<ul>
<li>代码版本管理 Gitlab</li>
<li>强大的、可扩展能力的 CI/CD 引擎 Jenkins</li>
<li>Jenkins Piepline Library： 可定义和编排了 CI/CD 流水线(<em><strong><code>Pipeline as Code</code></strong></em>)</li>
<li>依赖管理、制品管理 Nexus/Harbor</li>
<li>Devops 工具：Kubersphere （ks 其实还有更多关于微服务、云原生一站式的功能） </li>
</ul>
<h4><a class="header" href="#ci-流水线" id="ci-流水线">CI 流水线</a></h4>
<p><em><strong><code>图-1:CI流水线</code></strong></em></p>
<p><img src="tech/backend/assets/arch-ci-pipeline-v3.png" alt="" /></p>
<h4><a class="header" href="#gitflow" id="gitflow">GitFlow</a></h4>
<p><em><strong><code>图-1:GitFlow</code></strong></em></p>
<p><img src="tech/backend/assets/arch-gitflow.png" alt="" /></p>
<h3><a class="header" href="#repo-model" id="repo-model">Repo model</a></h3>
<h4><a class="header" href="#mono-repo" id="mono-repo">Mono Repo</a></h4>
<h4><a class="header" href="#mutilple-repo" id="mutilple-repo">Mutilple Repo</a></h4>
<h3><a class="header" href="#maven" id="maven">Maven</a></h3>
<h3><a class="header" href="#其它中间件" id="其它中间件">其它中间件</a></h3>
<h3><a class="header" href="#微服务和云原生" id="微服务和云原生">微服务和云原生</a></h3>
<p><em><strong><code>图-3:微服务选型关注点</code></strong></em></p>
<p><img src="tech/backend/assets/arch-microser-keypoint.png" alt="" /></p>
<p><em><strong><code>图-1:微服务主流方案对比</code></strong></em></p>
<p><img src="tech/backend/assets/arch-micro-compare.png" alt="" /></p>
<h2><a class="header" href="#" id=""></a></h2>
<h2><a class="header" href="#开发规范和最佳实践" id="开发规范和最佳实践">开发规范和最佳实践</a></h2>
<table><thead><tr><th>序号</th><th>大类</th><th>分类</th><th>框架/组件/工具/方法模型等</th><th>版本/规格/标准</th><th>备注</th></tr></thead><tbody>
<tr><td>99</td><td>规范</td><td>代码管理</td><td>代码仓库使用规范</td><td>/</td><td>已修订，主要约束了 gitlab  中仓库组的层级、分类；仓库组的权限控制规则</td></tr>
<tr><td>100</td><td>规范</td><td>代码管理</td><td>代码提交规范</td><td>/</td><td>已修订，主要约束了 git commit message 的规格</td></tr>
<tr><td>101</td><td>规范</td><td>代码管理</td><td>代码风格规范</td><td>/</td><td>已修订，主要约束开发中使用的语言、脚本的风格，包括  Java、Scala、Python、Shell、JS</td></tr>
<tr><td>102</td><td>规范</td><td>代码管理</td><td>git 协同开发规范</td><td>/</td><td>已修订，主要约束代码仓库的分支规范、协同的工作流，参考  gitflow、gitlab flow</td></tr>
<tr><td>103</td><td>规范</td><td>代码管理</td><td>Code Review 指南</td><td>/</td><td>已修订，主要约束、指导了 CR 的原则和要点，评审人和  Commiter 的各自角色的关注点、协作方式</td></tr>
<tr><td>104</td><td>规范</td><td>代码管理</td><td>PR 模板、ISSUE 模板</td><td>/</td><td>已修订，可能要针对不同的类型的项目做调整</td></tr>
<tr><td>105</td><td>规范</td><td>中间件使用</td><td>数据库开发规范</td><td>/</td><td>已修订，针对 PostgreSQL 做了开发规范约束</td></tr>
<tr><td>106</td><td>规范</td><td>中间件使用</td><td>缓存使用规范</td><td>/</td><td>未修订</td></tr>
<tr><td>107</td><td>规范</td><td>中间件使用</td><td>消息队列使用规范</td><td>/</td><td>未修订</td></tr>
<tr><td>108</td><td>规范</td><td>中间件使用</td><td>数据库自动化使用规范</td><td>/</td><td>已修订，主要约束了 Flyway SQL  的格式，并描述了最佳的实践方式</td></tr>
<tr><td>109</td><td>规范</td><td>中间件使用</td><td>三方库使用规范</td><td>/</td><td>未修订，需要包括前端、后端</td></tr>
<tr><td>110</td><td>规范</td><td>服务调用协议和标准</td><td>RestFul API 设计规范</td><td>/</td><td>已修订，主要内容包括 RestFul Path、Http  Method，Http Code，Header，Return Json Schema，最佳实践；参考：Paypal、Microsoft</td></tr>
<tr><td>112</td><td>规范</td><td>开发流程</td><td>打包构建、制品规范</td><td>/</td><td>已修订，主要约束构建工具、构建方式、构建环境、构建产物规格；还有待调整补充</td></tr>
<tr><td>113</td><td>规范</td><td>开发流程</td><td>配置文件规约</td><td>/</td><td>未修订</td></tr>
<tr><td>114</td><td>规范</td><td>开发流程</td><td>单元测试规约</td><td>/</td><td>已修订</td></tr>
<tr><td>115</td><td>规范</td><td>开发流程</td><td>日志规约</td><td>/</td><td>未修订</td></tr>
<tr><td>116</td><td>规范</td><td>开发流程</td><td>前后端分离开发协同开发指南</td><td>/</td><td>未修订，主要规约协同的工具、方法、职责和流程</td></tr>
<tr><td>117</td><td>规范</td><td>基础</td><td>软件版本控制规范</td><td>Semver 2.0</td><td>已修订，主要参考 Semver 2.0 制定</td></tr>
<tr><td>119</td><td>规范</td><td>基础</td><td>全局的命名规约</td><td>/</td><td>未修订，如用户ID，状态码，系统名称</td></tr>
</tbody></table>
<h2><a class="header" href="#开发工具" id="开发工具">开发工具</a></h2>
<table><thead><tr><th>序号</th><th>大类</th><th>分类</th><th>框架/组件/工具/方法模型等</th><th>版本/规格/标准</th><th>备注</th></tr></thead><tbody>
<tr><td>120</td><td>规范</td><td>工具</td><td>IDE： WebStorm</td><td>2021+</td><td>前端必须唯一使用；收费，无社区版</td></tr>
<tr><td>121</td><td>规范</td><td>工具</td><td>IDE： IntelliJ IDEA</td><td>2021+ Community</td><td>后端必须唯一使用；迫于公司未统一采购，推荐用社区版</td></tr>
<tr><td>122</td><td>规范</td><td>工具</td><td>Markdown 编辑器：Typora</td><td>&lt;1.0、0.9.x(beta)</td><td>迫于公司未统一采购，推荐使用 1.0 之前的免费版；能用  Markdown 就一定用，保持最佳的可见性</td></tr>
<tr><td>123</td><td>规范</td><td>工具</td><td>画图工具：Draw.io</td><td>14+</td><td>多端都可以使用，在 vs code 、idea 里也可以集成</td></tr>
<tr><td>124</td><td>规范</td><td>工具</td><td>脑图工具：Xmind</td><td>8+</td><td>推荐 Xmind，迫于收费，需要自行解决</td></tr>
<tr><td>125</td><td>规范</td><td>工具</td><td>数据库模型设计工具：DBeaver</td><td>23+</td><td>待讨论，目前用 PowerDesigner 16  比较多，但只限于 win 环境；Navicat/DbSchema 可以多端，需要收费；</td></tr>
<tr><td>126</td><td>规范</td><td>工具</td><td>阿里 Java 代码规约插件</td><td>latest</td><td>IDEA 插件</td></tr>
<tr><td>127</td><td>规范</td><td>工具</td><td>standard</td><td>16.x</td><td>前端默认代码规范检测工具</td></tr>
<tr><td>128</td><td>规范</td><td>工具</td><td>commitlint</td><td>12.x</td><td>git commit  格式规范工具</td></tr>
<tr><td>129</td><td>规范</td><td>工具</td><td>docz</td><td>2.x</td><td>react组件库文档工具，使用mdx格式，可直接生成组件使用、代码案例等；目前bui、zui等组件库均用其编写</td></tr>
<tr><td>130</td><td>规范</td><td>工具</td><td>Docsify</td><td>4.x</td><td>文档站点工具；将  markdown 文档生成 web 站点，主要用于项目文档展示</td></tr>
</tbody></table>
<h2><a class="header" href="#ddd" id="ddd">DDD</a></h2>
<h2><a class="header" href="#总结" id="总结">总结</a></h2>
<h1><a class="header" href="#pg-ha-方案" id="pg-ha-方案">PG HA 方案</a></h1>
<blockquote>
<p>By <a href="https://siu91.github.io/notes/#/./%E6%95%B0%E6%8D%AE%E5%BA%93/PG/PGHA/PG%20HA%E6%96%B9%E6%A1%88">Siu</a> 2020年12月</p>
</blockquote>
<h1><a class="header" href="#1-介绍" id="1-介绍">1 介绍</a></h1>
<blockquote>
<p>​       方案中使用 <a href="https://www.postgresql.org/docs/10/warm-standby-failover.html">PostgreSQL Failover、Warm Standby</a> 的特性，安装 <a href="https://github.com/citusdata/pg_auto_failover">pg_auto_failover</a> 扩展服务，为PostgreSQL 服务实现安全的自动故障转移。</p>
</blockquote>
<p><em><strong>以下方案或验证中，考虑实际单个机房内某台主机的故障情况；非应对整个机房瘫痪的双活/异地容灾高可用方案。</strong></em></p>
<p><strong>高可用的几个阶段：</strong></p>
<ul>
<li>
<p>冷备：需要停机恢复，数据丢失风险；</p>
</li>
<li>
<p>双机热备：需要停机恢复；</p>
</li>
<li>
<h5><a class="header" href="#activestandby-模式进一步可以配置单写多读读写分离" id="activestandby-模式进一步可以配置单写多读读写分离">Active/Standby 模式：进一步可以配置单写多读，读写分离；</a></h5>
</li>
<li>
<p><del>互为主备</del>：相比于 Active/Standby ，更合理理由服务器资源。目前 PG 没有合适的候选方案；</p>
</li>
<li>
<p>同城双活：可以解决某个 IDC 机房整体挂掉的情况（停电，断网等）；</p>
</li>
<li>
<p>异地双活：应对大部分的灾备情况，但是碰到大面积停电，或者自然灾害的时候，服务依然会中断；</p>
</li>
<li>
<p>异地多活：理想方案。</p>
</li>
</ul>
<h2><a class="header" href="#11-架构" id="11-架构">1.1 架构</a></h2>
<h3><a class="header" href="#111-two-standby-sync-架构" id="111-two-standby-sync-架构">1.1.1 two-standby-sync 架构</a></h3>
<blockquote>
<p>​		<a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture-multi-standby.html?#number-sync-standbys">two-standby-sync 架构</a>，这种架构下两个 standby 节点都参与复制仲裁 （Node B、Node C），<a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture.html#synchronous-vs-asynchronous-replication">number_sync_standby = 1</a> ，系统始终维护至少<strong>两个数据集副本</strong>，一个在 Node A 主数据库上，另一个在 Node B 或 Node C 上。丢失<strong>任意一个</strong>节点，仍可保证拥有两个数据集副本，三个节点实现 Postgres <strong>服务和数据集</strong>的<strong>高可用性</strong>。</p>
<p>​		如果需要增加可用的数据副本数，按同样的配置增加节点 ，即可变成 <strong>N-standby-sync 架构</strong>。</p>
</blockquote>
<p><img src="tech/project/PGHA/assets/arch-two-standby-sync.svg" alt="" /></p>
<p><em><strong>注：</strong></em></p>
<blockquote>
<ul>
<li>Streaming Replication : <strong>流复制</strong>，PG的特性之一。</li>
<li><a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture.html#synchronous-vs-asynchronous-replication">number_sync_standby</a> ：同步复制的 standby 节点数；写操作都会阻塞，直到至少收到<code>number_sync_standby</code> 个standby 节点报告同步完成。</li>
<li><a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture-multi-standby.html?#replication-quorum">replication quorum</a>：是否参与复制仲裁；例图中 3 个 replication quorum = true ，Primary 节点的写操作只要任意一个 Secondary 节点确认即可。</li>
<li>candidate priority ：选举优先级；当故障转移时，候选节点成为主节点的优先级。</li>
<li>[replication quorum = true 的节点数]  &gt; number_sync_standbys；一般配置为 [replication quorum = true 的 standby 节点数]  = number_sync_standbys + 1 。</li>
<li>当可用 standby 节点数 &lt; number_sync_standbys 时 PG 服务将<strong>降级为只读</strong>；故并不是越多的数据副本代表更高的可用性，数据可用副本只是保证了数据的完整性，在实际场景中要权衡。</li>
<li>上图架构中 Node B、C 两个 standby 故障时，PG 将降级为只读；将 number_sync_standbys 设置为0，将允许写入数据，即使两个备用节点都处于故障状态也是如此。 在这种情况下，将保留生产数据集的单个副本，如果主数据库随后发生故障，则某些数据将丢失， 多少取决于数据备份和恢复机制。</li>
</ul>
</blockquote>
<h3><a class="header" href="#112-three-standby-one-async-架构" id="112-three-standby-one-async-架构">1.1.2 three-standby-one-async 架构</a></h3>
<blockquote>
<p>​		<a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture-multi-standby.html?#sample-architectures-with-three-standby-nodes">three-standby-one-async 架构</a>，与 two-standby-sync 不同的是多了一个<strong>异步复制</strong>的节点 <strong>Node D</strong> 。</p>
<p>​		这种架构适合以下情况：</p>
<p>​		Node A，B ， C 部署在<strong>同一数据中心</strong>或可用性区域中，而 Node D 部署在另一个数据中心或可用性区域中。 </p>
</blockquote>
<p><img src="tech/project/PGHA/assets/arch-three-standby-one-async.svg" alt="" /></p>
<p><em><strong>注：</strong></em></p>
<blockquote>
<ul>
<li>Node D 不会作为故障转移的候选者（candidate priority = 0 ）。</li>
</ul>
</blockquote>
<h2><a class="header" href="#12-可用性分析" id="12-可用性分析">1.2 可用性分析</a></h2>
<blockquote>
<p>依据 two-standby-sync 架构做分析。</p>
</blockquote>
<table><thead><tr><th></th><th>Monitor</th><th>PG Nodes</th><th>Available</th><th>Failover</th><th></th></tr></thead><tbody>
<tr><td>1</td><td>:heavy_check_mark: 正常</td><td>大于 2 个节点可用</td><td><strong>是</strong></td><td><strong>是</strong></td><td>/</td></tr>
<tr><td>2</td><td>:heavy_check_mark:正常</td><td>小于等于 1 个节点可用</td><td><strong>否</strong></td><td><strong>否</strong></td><td>与配置策略相关，当 number_sync_standbys &gt; 0 and synchronous_standby_names 非空时<strong>不可写</strong></td></tr>
<tr><td>3</td><td>:x:故障</td><td>Primary 可用，至少1个 Secondary 可用</td><td><strong>是</strong></td><td><strong>否</strong></td><td>/</td></tr>
<tr><td>4</td><td>:x:故障</td><td>Primary 不可用，Secondary 任意状态</td><td><strong>否</strong></td><td><strong>否</strong></td><td><strong>不可写</strong></td></tr>
<tr><td>5</td><td><em><strong>any</strong></em></td><td>所有节点故障</td><td><strong>否</strong></td><td><strong>否</strong></td><td><strong>完全故障</strong></td></tr>
</tbody></table>
<p><em><strong>注：</strong></em></p>
<blockquote>
<p>​		只有 Primary 节点时（所有 standby 故障），服务可能降级为只读，取决于 number_sync_standbys 和 synchronous_standby_names 的设置。</p>
</blockquote>
<h2><a class="header" href="#a-hrefhttpspg-auto-failoverreadthedocsioenlatestfaqhtmlthe-monitor-is-a-spof-in-pg-auto-failover-design-how-should-we-handle-that13-monitor-spof-a" id="a-hrefhttpspg-auto-failoverreadthedocsioenlatestfaqhtmlthe-monitor-is-a-spof-in-pg-auto-failover-design-how-should-we-handle-that13-monitor-spof-a"><a href="https://pg-auto-failover.readthedocs.io/en/latest/faq.html#the-monitor-is-a-spof-in-pg-auto-failover-design-how-should-we-handle-that">1.3 Monitor SPOF </a></a></h2>
<ul>
<li>Monitor 故障时，将无法提供<strong>故障转移</strong>服务；</li>
<li>Monitor 故障时，将无法分配状态给PG节点（添加节点、故障转移、节点维护）；</li>
<li>Monitor 故障时，可以<strong>无状态</strong>下<strong>快速恢复</strong>；</li>
<li>Monitor 故障时，可以从备份数据中<strong>快速恢复</strong>；</li>
<li>Monitor 故障时，<strong>不影响PG服务</strong>；</li>
</ul>
<p><em><strong>注：</strong></em></p>
<blockquote>
<p><a href="https://baike.baidu.com/item/%E5%8D%95%E7%82%B9%E6%95%85%E9%9A%9C/3570893">SPOF</a>: 单点故障 (single point of failure)</p>
</blockquote>
<h3><a class="header" href="#131-monitor-spof-优化" id="131-monitor-spof-优化">1.3.1 Monitor SPOF 优化</a></h3>
<blockquote>
<p>​		在 <a href="https://github.com/citusdata/pg_auto_failover">pg_auto_failover</a> 原有功能基础上，利用 keepalived 的功能设计实现保证 Monitor 节点的高可用。在 Keepalived 中配置 <strong>VRRP instance</strong> ，将<code>VIP</code>绑定到可用的节点，使用 <strong>track_script 、notify_master、notify_backup</strong> 将 keepalived 的状态和 pgafom 的状态绑定，同步<code>MASTER</code>和<code>BACKUP</code>数据；使得同一时间内，两台 Monitor节点只要保证一台主机正常，就能保证<strong>有且只有一个</strong> Monitor 服务在线工作。</p>
</blockquote>
<img src="tech/project/PGHA/./assets/monitor-spof-solution.svg" style="zoom:175%" />
<p><strong>Monitor 故障转移：</strong></p>
<img src="tech/project/PGHA/./assets/arch-2standy-Monitor-Failover-Timing-diagram.svg" style="zoom:100%" />
<p><strong>注：</strong></p>
<blockquote>
<ul>
<li>在此配置中 pgafo 服务不需要设置 <code>systemed enable</code>；</li>
<li><a href="https://www.jianshu.com/p/7410507d57c3">VRRP即虚拟路由冗余协议(Virtual Router Redundancy Protocol)</a>，它是为了<strong>避免路由器出现单点故障</strong>的一种容错协议。</li>
<li>MASTER、BACKUP 数据同步直接采用数据<strong>增量</strong>文件同步（rsync）的方式，主要考虑：
<ul>
<li>1、数据量非常小 </li>
<li>2、互为 hot standy 容易数据不一致，且两个节点以上配置切换复杂。</li>
</ul>
</li>
</ul>
</blockquote>
<h3><a class="header" href="#132-优化后的架构" id="132-优化后的架构">1.3.2 优化后的架构</a></h3>
<img src="tech/project/PGHA/./assets/arch-2standy-pgafo-arch-optimization.svg" style="zoom:150%" />
<blockquote>
<p>​		在此架构下，解决了Monitor 服务的单点故障问题，保证了同一时间内有且只有一个 Monitor 服务在线。上图中也可以看出，优化方案对<strong>应用接入</strong>这一层没有任何影响。</p>
</blockquote>
<h2><a class="header" href="#14-方案回退" id="14-方案回退">1.4 方案回退</a></h2>
<blockquote>
<p>pg-auto-failover 本身对PG数据库没有侵入，回退或切换方案，只要做相应的数据迁移。</p>
</blockquote>
<h2><a class="header" href="#15-主流方案对比" id="15-主流方案对比">1.5 主流方案对比</a></h2>
<blockquote>
<p>所有对比方案，均采用 <a href="https://www.postgresql.org/docs/10/warm-standby-failover.html">PostgreSQL Failover、Warm Standby</a> 作为HA核心功能的解决方案。</p>
</blockquote>
<table><thead><tr><th></th><th><a href="https://pgpool.net/mediawiki/index.php/Main_Page">Pgpool-II</a></th><th><a href="https://repmgr.org/">Repmgr</a></th><th><a href="https://patroni.readthedocs.io/en/latest/">Patroni</a></th><th><a href="https://github.com/citusdata/pg_auto_failover">pg_auto_failover</a></th></tr></thead><tbody>
<tr><td><strong>类型</strong></td><td>middleware</td><td>afo tool</td><td>afo tool</td><td>afo tool</td></tr>
<tr><td><strong>开源协议</strong></td><td><a href="https://pgpool.net/mediawiki/index.php/pgpool-II_License">非开源、当前免费</a></td><td><a href="https://repmgr.org/GPL-v3.txt">GPL v3</a></td><td><a href="https://github.com/zalando/patroni/blob/master/LICENSE">License (MIT)</a></td><td><a href="https://github.com/citusdata/pg_auto_failover/blob/master/LICENSE">PostgreSQL License</a></td></tr>
<tr><td><strong>源码</strong></td><td>/</td><td><a href="https://github.com/2ndQuadrant/repmgr">2ndQuadrant/repmgr</a></td><td><a href="https://github.com/zalando/patroni">zalando/patroni</a></td><td><a href="https://github.com/citusdata/pg_auto_failover">citusdata/pg_auto_failover</a></td></tr>
<tr><td><strong>配置复杂度</strong></td><td>较高</td><td>中</td><td>高</td><td>低</td></tr>
<tr><td><strong>维护难度</strong></td><td>高</td><td>低</td><td>中</td><td>低</td></tr>
<tr><td><strong>文档</strong></td><td><a href="https://www.pgpool.net/mediawiki/index.php/Documentation">规范、详细 </a></td><td><a href="https://repmgr.org/docs/5.1/index.html">规范、详细 </a></td><td><a href="https://patroni.readthedocs.io/en/latest/">规范、详细 </a></td><td><a href="https://pg-auto-failover.readthedocs.io/">规范、详细、友好 </a></td></tr>
<tr><td><strong>扩展性</strong></td><td>不支持动态增加节点（待确定）</td><td><em><strong>未收集相关信息</strong></em></td><td><em><strong>未收集相关信息</strong></em></td><td>支持动态增加节点，删除节点</td></tr>
<tr><td><strong>功能</strong></td><td>连接池、VIP、负载均衡、读写分离、故障转移、数据复制</td><td>故障转移、数据复制</td><td>故障转移、数据复制</td><td>故障转移、数据复制、节点扩展</td></tr>
<tr><td><strong>问题</strong></td><td>Watchdog leader 、数据一致性导致故障转移失败</td><td>未知（未验证）</td><td>未知（未验证）</td><td>Monitor SPOF</td></tr>
<tr><td><strong>团队/品牌</strong></td><td>Pgpool-II</td><td>2ndQuadrant</td><td>Zalando SE</td><td>Microsoft/Citus Data</td></tr>
</tbody></table>
<blockquote>
<ul>
<li>类型：这部分各有有点，中间件对业务是透明的，无侵入，如果中间件稳定功能丰富且适合业务需求，是比较好的选择；Patrotni和其它两个的区别在于它是一个Python的模板，可用于自主配置PG HA工具；</li>
<li>开源部分：主要考量主要在于开源热度、团队和品牌、许可范围；</li>
<li>配置和运维：主要考量目前团队对新组件在预期内的掌握程度和未来交维的能力；pg-pool 维护难度较高一部分是配置较为复杂、一部分是功能上丰富，带来一定的熟悉难度；</li>
<li>扩展性：这个和后期运维关系紧密</li>
<li>功能：主要考量我们目前的业务需求和未来的主要规划；</li>
<li>性能：性能部分未单独考量，因为只有pg-pool方式需要特别考虑性能（中间件和连接池），其它列出的几种方式都是直接连接PG，只跟PG 驱动和同步复制相关；基准测试部分会有个基础依据；</li>
</ul>
</blockquote>
<p><strong>注：pg 驱动支持读写分离，负载均衡（待验证）</strong></p>
<h1><a class="header" href="#2-准备" id="2-准备">2 准备</a></h1>
<h2><a class="header" href="#21-主机规划" id="21-主机规划">2.1 主机规划</a></h2>
<blockquote>
<p>开发测试环境</p>
</blockquote>
<table><thead><tr><th>节点名称</th><th>CPU</th><th>内存</th><th>系统盘</th><th>数据盘1</th><th>数据盘2</th><th>备注</th><th>是否必须</th></tr></thead><tbody>
<tr><td>pg-node1</td><td>4C</td><td>16G</td><td>60G</td><td>1T</td><td>60G</td><td>Postgres 节点</td><td>是</td></tr>
<tr><td>pg-node2</td><td>4C</td><td>16G</td><td>60G</td><td>1T</td><td>60G</td><td>Postgres 节点</td><td>是</td></tr>
<tr><td>pg-node3</td><td>4C</td><td>16G</td><td>60G</td><td>1T</td><td>60G</td><td>Postgres 节点</td><td>是</td></tr>
<tr><td>pg-afom1</td><td>2C</td><td>2G</td><td>60G</td><td>60G</td><td>/</td><td>pg afo  monitor 节点</td><td>是</td></tr>
<tr><td>pg-afom2</td><td>2C</td><td>2G</td><td>60G</td><td>60G</td><td>/</td><td>pg afo  monitor 节点</td><td><strong>否</strong></td></tr>
</tbody></table>
<blockquote>
<p>说明：</p>
<ul>
<li>pg-node 数据盘1作为postgres 的数据盘，统一挂载在 /data/pg10 ;数据盘2作为pg-auto-failover monito的数据备份盘统一挂载在 /pgafo/monitor</li>
<li>pg-afom 数据盘1作为pg-auto-failover monito的数据盘和数据备份盘统一挂载在 /pgafo/monitor</li>
<li>注：测试、开发环境资源不足可以暂时规划 <code>4C/8G/20G/200G/20G</code> <code>2C/2G/20G/20G/</code></li>
<li>生产环境根据业务规模规划</li>
</ul>
<p>磁盘挂载：https://cloud.tencent.com/developer/article/1496311</p>
<ul>
<li>
<p>设置主机名：hostnamectl set-hostname [host-name]</p>
<p>192.168.5.149 pg-node1
192.168.5.150 pg-node2
192.168.5.151 pg-node3
192.168.6.170 pg-afom1</p>
</li>
</ul>
</blockquote>
<h2><a class="header" href="#22-a-hrefhttpswwwpostgresqlorgdocs10kernel-resourceshtmlpostgres-kernel-调优a" id="22-a-hrefhttpswwwpostgresqlorgdocs10kernel-resourceshtmlpostgres-kernel-调优a">2.2 <a href="https://www.postgresql.org/docs/10/kernel-resources.html">Postgres Kernel 调优</a></a></h2>
<blockquote>
<p>针对数据库相关的内核参数，按需调优。<a href="https://www.postgresql.org/docs/10/kernel-resources.html">参考</a></p>
</blockquote>
<h2><a class="header" href="#23-配置节点时钟同步" id="23-配置节点时钟同步">2.3 配置节点时钟同步</a></h2>
<blockquote>
<p><strong>生产必须</strong></p>
</blockquote>
<h2><a class="header" href="#24-配置ssh互信" id="24-配置ssh互信">2.4 配置SSH互信</a></h2>
<blockquote>
<p>SSH方式自动部署必须配置，参考：./pgafo -a</p>
</blockquote>
<h1><a class="header" href="#3-安装" id="3-安装">3 安装</a></h1>
<pre><code class="language-shell"># 解压部署包，目录下 config为配置文件
unzip PGHA.zip &amp;&amp; cd PGHA &amp;&amp; chmod +x pgafo
# -p 初始化各节点
# -c 清理旧的afo环境（重新安装时需要）
# -i 安装afo基础环境
./pgafo -p -c -i

# -r 启动afo
su ha-admin
./pgafo -r
</code></pre>
<p>配置文件如下（按实际配置）：</p>
<pre><code class="language-shell"># ha-admin password,operation user
HA_ADMIN_PASS='ha1234'
# PG server trusted network segment
PG_HBA_MD5=&quot;192.168.31.1/24 192.168.1.1/24 192.168.2.1/24&quot;
# PG version
PG_VERSION='10'
# PG subversion
PG_SUB_VERSION='15'

# PG port
PG_PORT='5432'
# PG afo monitor port
PGM_PORT='5431'

# PG afo monitor hostname
PG_AFOM_HOSTNAME=&quot;pg-afom&quot;
# node list info
NODE_LIST=&quot;${PG_AFOM_HOSTNAME}:192.168.5.151 pg-node1:192.168.5.149 pg-node2:192.168.5.150 pg-node3:192.168.6.170&quot;
</code></pre>
<h1><a class="header" href="#4-运维" id="4-运维">4 运维</a></h1>
<h2><a class="header" href="#41-pgafo" id="41-pgafo">4.1 pgafo</a></h2>
<pre><code class="language-shell">[root@pg-node1 PGHA]# ./pgafo -v

  ================================================
  #                 pgafo 工具                   #
  # 版本： 1.0.0                                 #
  # 作者： Siu                                   #
  # 支持： postgres 10,11,12                     #
  # GCC: (GNU) 4.8.5 20150623 (Red Hat 4.8.5-28) #
  ================================================



Usage: ./pgafo -p
       ./pgafo -s
       ./pgafo -l
       ./pgafo -c local
       ./pgafo -p -c -i
       ./pgafo -d pg-node5

Options:
  -a      设置当前用户 ssh 免密
  -p      初始化主机
  -c      清理旧 afo 环境（重装时需要，必须输入验证码二次确认）
  -i      安装 afo 基础环境（必须输入验证码二次确认）
  -r      启动 afo、afom
  -b      备份 afo monitor数据
  -n      查看节点信息
  -s      查看节点信息（节点情况、连接串、pg_autoctl 配置文件、节点配置）
  -d      删除节点（必须二次确认）
  -o      主动故障转移（必须二次确认）
  -g      设置 postgresql.conf（需要重启PG）
  -l      查看服务日志
  -m      维护节点
  -R      维护完成，启用节点
  -h      帮助信息
  -v      pgafo 工具版本信息
</code></pre>
<h2><a class="header" href="#42-运维操作" id="42-运维操作">4.2 运维操作</a></h2>
<h3><a class="header" href="#421-查看节点状态" id="421-查看节点状态">4.2.1 查看节点状态</a></h3>
<blockquote>
<p>./pgafo -n 2  # 每隔两秒输出当前节点的状态</p>
</blockquote>
<p><img src="tech/project/PGHA/./assets/image-1-show-nodes.png" alt="image-20201209105213328" /></p>
<h3><a class="header" href="#422-查看系统日志" id="422-查看系统日志">4.2.2 查看系统日志</a></h3>
<blockquote>
<p>./pgafo -l</p>
</blockquote>
<p><img src="tech/project/PGHA/./assets/image-2-show-logs.png" alt="image-20201209105432929" /></p>
<h3><a class="header" href="#423-节点维护" id="423-节点维护">4.2.3 节点维护</a></h3>
<blockquote>
<p>将节点置为维护状态，适用于主机内核升级等情况；</p>
</blockquote>
<p><strong>Secondary 节点维护</strong></p>
<blockquote>
<p>./pgafo -m</p>
</blockquote>
<p><img src="tech/project/PGHA/./assets/image-3-maintenance-secondary.png" alt="image-20201209105723122" /></p>
<p><strong>Primary 节点维护</strong></p>
<blockquote>
<p>./pgafo -m</p>
</blockquote>
<p><img src="tech/project/PGHA/./assets/image-4-maintenance-primary.png" alt="image-20201209110001608" /></p>
<h3><a class="header" href="#424-节点伸缩" id="424-节点伸缩">4.2.4 节点伸缩</a></h3>
<p><strong>删除节点</strong></p>
<blockquote>
<p>./pgafo -d [hostname]</p>
</blockquote>
<p><strong>增加节点</strong></p>
<blockquote>
<p>参考安装，只需要在新的节点安装为 postgres 节点即可成为新的节点加入。</p>
</blockquote>
<h1><a class="header" href="#5-测试" id="5-测试">5 测试</a></h1>
<table><thead><tr><th>序号</th><th>测试项</th><th>预期</th><th>目的</th></tr></thead><tbody>
<tr><td>1</td><td>故障转移测试</td><td>1）、任意一个节点故障，不影响PG服务和数据完整<br/>2）、任意两个节点故障： <br/>                                   a、所有 standby 故障， 当可用 standby 节点数 &lt; number_sync_standbys 时 PG 服务将降级为只读；<br/>                                   b、主节点和其中一个 standby 节点故障，不影响PG服务，有可能影响数据完整性（取绝于接管主PG服务的节点是否是最后执行复制仲裁的节点或故障时有无读请求）<br/>3）、Monitor 故障不影响PG服务和数据完整性，只会影响故障转移；<br/>4）、Monitor SPOF 解决方案的可行性；<br/>5）、Monitor SPOF 解决方案的可靠性；<br/>6）、基于pg-auto-failover 的PG HA方案的可靠性；</td><td>验证 HA，failover可靠性</td></tr>
<tr><td>2</td><td>JDBC 应用测试</td><td>应用正常使用</td><td>验证现有应用使用 JDBC HA方式能正常使用，业务上无侵入。</td></tr>
<tr><td>3</td><td>数据库基准测试</td><td>性能差距在 <strong>5% 左右</strong>，小于 10%</td><td>验证方案，JDBC HA方式连接对性能没有影响 。</td></tr>
<tr><td>4</td><td>数据库压测</td><td>/</td><td>测试数据稳定性，发现未知问题。</td></tr>
</tbody></table>
<h2><a class="header" href="#51--故障转移测试" id="51--故障转移测试">5.1  故障转移测试</a></h2>
<blockquote>
<p>依据 two-standby-sync 架构做整体方案的功能和可靠性验证。</p>
</blockquote>
<h3><a class="header" href="#511-场景一-任意一个-pg-节点故障" id="511-场景一-任意一个-pg-节点故障">5.1.1 场景一 ：任意一个 PG 节点故障</a></h3>
<blockquote>
<p>​		由于这种场景下 Secondary 节点故障并不会触发故障转移（重新选择主节点），故在测试中制造 Primary 节点故障。</p>
</blockquote>
<table><thead><tr><th>Monitor</th><th>Primary</th><th>Scondary1</th><th>Scondary2</th><th>Available</th><th>Failover</th></tr></thead><tbody>
<tr><td>:heavy_check_mark:</td><td>:heavy_check_mark:</td><td>:heavy_check_mark:</td><td>:heavy_check_mark:</td><td><strong>是</strong></td><td><strong>是</strong></td></tr>
</tbody></table>
<p><strong>故障转移测试：</strong></p>
<ul>
<li>
<p>手动造成 Primary 节点服务故障（断电，关机）；</p>
<p><img src="tech/project/PGHA/./assets/image-5-show-nodes-2.png" alt="" />
<img src="tech/project/PGHA/./assets/image-20201201170824122.png" alt="image-20201201170824122" /></p>
</li>
<li>
<p>观察故障转移：新主节点产生，原主节点被降级</p>
<p><img src="tech/project/PGHA/./assets/image-7-show-nodes-3.png" alt="image-20201201171005957" /></p>
</li>
<li>
<p>重启原 Primary 节点</p>
</li>
<li>
<p>观察故障转移：原 Primary 节点重新加入，开始同步 LSN</p>
<p><img src="tech/project/PGHA/./assets/image-8-show-nodes-4.png" alt="image-20201201171116383" /></p>
</li>
<li>
<p>观察故障转移：新的 Primary 节点状态 从 join_primary 变为 primary</p>
<p><img src="tech/project/PGHA/./assets/image-9-show-nodes-5.png" alt="image-20201201170543638" /></p>
</li>
</ul>
<h3><a class="header" href="#512-场景二-任意两个-pg-节点故障" id="512-场景二-任意两个-pg-节点故障">5.1.2 场景二 ：任意两个 PG 节点故障</a></h3>
<blockquote>
<p>验证 number_sync_standbys 和 synchronous_standby_names 配置的影响</p>
</blockquote>
<p><strong>故障转移测试1：两个 Secondary 节点故障</strong></p>
<table><thead><tr><th>Monitor</th><th>Primary</th><th>Scondary1</th><th>Scondary2</th><th>Available</th><th>Failover</th></tr></thead><tbody>
<tr><td>:heavy_check_mark:</td><td>:heavy_check_mark:</td><td>:x:</td><td>:x:</td><td><strong>否</strong></td><td><strong>否</strong></td></tr>
</tbody></table>
<ul>
<li>
<p>手动造成两个 Secondary 节点故障（断电/关机）；</p>
<ul>
<li>
<p>关机前节点状态</p>
<p><img src="tech/project/PGHA/./assets/image-23-show-nodes-12.png" alt="image-20201217141232815" /></p>
</li>
<li>
<p>pg-node2、pg-node3 关机 （pg-node1 降级只读，写阻塞）</p>
<p><img src="tech/project/PGHA/./assets/image-24-show-nodes-13.png" alt="image-20201217144349908" /></p>
<p><img src="tech/project/PGHA/./assets/image-25-primary-node-write-block.png" alt="image-20201217142245830" /></p>
</li>
<li>
<p>设置 number-sync-standbys=0 ,synchronous_standby_names=''（pg-node1 可读写）</p>
<pre><code class="language-shell"># 设置 number-sync-standbys = 0
/usr/pgsql-10/bin/pg_autoctl set formation number-sync-standbys 0 --pgdata /pgafo/monitor/pgafomonitor

# 设置 synchronous_standby_names = ''
/usr/pgsql-10/bin/pg_autoctl set node replication-quorum false --name pg-node2 --pgdata /pgafo/monitor/pgafomonitor
/usr/pgsql-10/bin/pg_autoctl set node replication-quorum false --name pg-node3 --pgdata /pgafo/monitor/pgafomonitor
</code></pre>
<p><img src="tech/project/PGHA/./assets/image-26-enable-write-on-all-standby-fail.png" alt="image-20201217144234770" /></p>
<p><img src="tech/project/PGHA/./assets/image-27-primary-node-writable.png" alt="image-20201217144520951" /></p>
</li>
</ul>
</li>
</ul>
<p><strong>故障转移测试2：Primary 节点故障，一个Secondary 故障</strong></p>
<table><thead><tr><th>Monitor</th><th>Primary</th><th>Scondary1</th><th>Scondary2</th><th>Available</th><th>Failover</th></tr></thead><tbody>
<tr><td>:heavy_check_mark:</td><td>:x:</td><td>:heavy_check_mark:</td><td>:x:</td><td><strong>是</strong></td><td><strong>否</strong></td></tr>
</tbody></table>
<ul>
<li>
<p>手动造成 Primary 和一个 Secondary 节点故障（断电/关机）；</p>
<ul>
<li>
<p>关机前节点状态</p>
<p><img src="tech/project/PGHA/C:%5CUsers%5CWorkstation%5Cnotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CPG%5CPGHA%5Cassets%5Cimage-20201218093034525.png" alt="image-20201218093034525" /></p>
</li>
<li>
<p>关机后故障转移（synchronous_standby_names 自动配置为空）</p>
<p><img src="tech/project/PGHA/C:%5CUsers%5CWorkstation%5Cnotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CPG%5CPGHA%5Cassets%5Cimage-20201218093551078.png" alt="image-20201218093551078" /></p>
<p><img src="tech/project/PGHA/C:%5CUsers%5CWorkstation%5Cnotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CPG%5CPGHA%5Cassets%5Cimage-20201218093736339.png" alt="image-20201218093736339" /></p>
</li>
<li>
<p>故障节点重新加入（重启 pg-node2、pg-node3）</p>
<p><img src="tech/project/PGHA/C:%5CUsers%5CWorkstation%5Cnotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CPG%5CPGHA%5Cassets%5Cimage-20201218100929700.png" alt="image-20201218100929700" /></p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>​		Primary 节点和 Secondary 节点同时故障，另一个 Secondary 节点变成唯一副本，会升级为主节点（wait_primary），synchronous_standby_names 自动配置为空；待故障节点重新加入时，synchronous_standby_names 自动配置为相应的配置。</p>
</blockquote>
<h3><a class="header" href="#513-场景三monitor-节点故障" id="513-场景三monitor-节点故障">5.1.3 场景三：Monitor 节点故障</a></h3>
<table><thead><tr><th>Monitor</th><th>Primary</th><th>Scondary1</th><th>Scondary2</th><th>Available</th><th>Failover</th></tr></thead><tbody>
<tr><td>:x:</td><td>:heavy_check_mark:</td><td>:heavy_check_mark:</td><td><em><strong>any</strong></em></td><td><strong>是</strong></td><td><strong>否</strong></td></tr>
</tbody></table>
<p><strong>故障转移测试：</strong></p>
<ul>
<li>
<p>手动造成 一个 Monitor 节点故障（断电/关机）；</p>
</li>
<li>
<p>手动造成 一个 Secondary 节点故障（断电/关机）；</p>
</li>
<li>
<p>观察PG服务是否可用；</p>
<p><img src="tech/project/PGHA/./assets/image-15-show-pg-status.png" alt="image-20201202154927886" /></p>
</li>
<li>
<p>重启 故障节点，恢复：</p>
<p><img src="tech/project/PGHA/./assets/image-16-show-nodes-11.png" alt="image-20201202160018382" /></p>
</li>
</ul>
<p><em><strong>注：</strong></em></p>
<blockquote>
<p><strong>可增加 Monitor SPOF 解决方案，防止单点影响</strong>。</p>
</blockquote>
<h3><a class="header" href="#514-monitor-故障转移测试" id="514-monitor-故障转移测试">5.1.4 Monitor 故障转移测试</a></h3>
<table><thead><tr><th>Monitor1</th><th>Monitor2</th><th>Failover</th></tr></thead><tbody>
<tr><td>:x:</td><td>:heavy_check_mark:</td><td><strong>是</strong></td></tr>
</tbody></table>
<p><strong>故障转移测试：</strong></p>
<ul>
<li>
<p>手动造成 一个 Monitor 节点（MASTER）故障（断电/关机）；</p>
<img src="tech/project/PGHA/./assets/image-17-show-monitor-1.png" style="zoom:70%" align=left />
</li>
</ul>
<img src="tech/project/PGHA/./assets/image-18-reboot.png" style="zoom:70%" align=left />
<ul>
<li>
<p>另一个备用 Monitor 节点接管服务</p>
<img src="tech/project/PGHA/./assets/image-19-monitor-failover.png" style="zoom:170%" align=left />
</li>
</ul>
<img src="tech/project/PGHA/./assets/image-20-show-monitor-2.png" style="zoom:70%" align=left />
<h3><a class="header" href="#515-monitor-failover-压测" id="515-monitor-failover-压测">5.1.5 Monitor Failover 压测</a></h3>
<blockquote>
<p>7 X 24小时 ，模拟Monitor 节点故障（两个节点先后故障，间隔5分钟，每小时触发一次）</p>
</blockquote>
<p><strong>两个节点每个小时定时重启</strong></p>
<pre><code class="language-shell"># Node1
crontab -l
25 * * * * /sbin/reboot

# Node2
crontab -l
31 * * * * /sbin/reboot
</code></pre>
<p><em><strong>failover 日志：</strong></em></p>
<img src="tech/project/PGHA/./assets/image-21-monitor-failover-dblogs.png" style="zoom:120%" align=left />
<h3><a class="header" href="#516-primary-failover-压测" id="516-primary-failover-压测">5.1.6 Primary Failover 压测</a></h3>
<blockquote>
<p>7 X 24小时 ，每个小时让 Primary 节点故障两次（间隔10分钟）</p>
</blockquote>
<pre><code class="language-shell"># Node1
crontab -l
5 * * * * sh /opt/PGHA/failovertest.sh
55 * * * * sh /opt/PGHA/failovertest.sh

# Node2
crontab -l
5 * * * * sh /opt/PGHA/failovertest.sh
55 * * * * sh /opt/PGHA/failovertest.sh

# Node3
crontab -l
5 * * * * sh /opt/PGHA/failovertest.sh
55 * * * * sh /opt/PGHA/failovertest.sh
</code></pre>
<pre><code class="language-shell">#!/bin/bash
# failovertest.sh

is_secondary=$(sudo su postgres -c &quot;psql -p 5432 -c 'select * from pg_is_in_recovery();'&quot; | head -n 3|tail -n 1)
is_secondary=`echo $is_secondary`

# 如果是主节点
if [[ ${is_secondary} == &quot;f&quot; ]]; then
  echo &quot;10秒后重启系统&quot;
  sleep 10
  /sbin/reboot
fi
</code></pre>
<p><em><strong>failover 日志</strong></em></p>
<p><img src="tech/project/PGHA/./assets/image-22-node-failover-dblogs.png" alt="image-20201216112912520" /></p>
<p><strong>压测中进行故障转移：</strong></p>
<p><img src="tech/project/PGHA/C:%5CUsers%5CWorkstation%5Cnotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CPG%5CPGHA%5Cassets%5Cimage-20201223103411327.png" alt="image-20201223103411327" /></p>
<h2><a class="header" href="#52-a-hrefhttpsjdbcpostgresqlorgdocumentationheadconnecthtmlconnection-parametersjdbc-测试a" id="52-a-hrefhttpsjdbcpostgresqlorgdocumentationheadconnecthtmlconnection-parametersjdbc-测试a">5.2 <a href="https://jdbc.postgresql.org/documentation/head/connect.html#connection-parameters">JDBC 测试</a></a></h2>
<blockquote>
<p>驱动版本：<a href="https://github.com/pgjdbc/pgjdbc">postgresql-42.2.11</a></p>
</blockquote>
<h3><a class="header" href="#521-ha-jdbc连接" id="521-ha-jdbc连接">5.2.1 HA JDBC连接</a></h3>
<p><code>url: jdbc:postgresql://pg-node3:5432,pg-node2:5432,pg-node1:5432/dbname?targetServerType=master </code></p>
<blockquote>
<p><strong>测试结果正常</strong></p>
</blockquote>
<h3><a class="header" href="#522-读写分离jdbc连接" id="522-读写分离jdbc连接">5.2.2 读写分离JDBC连接</a></h3>
<blockquote>
<p>（待验证）</p>
</blockquote>
<p><code>url: jdbc:postgresql://pg-node3:5432,pg-node2:5432,pg-node1:5432/dbname?targetServerType=perferSlave </code></p>
<h2><a class="header" href="#53-数据库基准测试" id="53-数据库基准测试">5.3 数据库基准测试</a></h2>
<blockquote>
<p>​		基准测试主要了从 JDBC 驱动层到数据库层完全执行一个指令所需的时钟周期，即测试中实际执行的事务。</p>
</blockquote>
<h3><a class="header" href="#531-测试环境" id="531-测试环境">5.3.1 测试环境</a></h3>
<ul>
<li><a href="https://sourceforge.net/projects/benchmarksql/">测试工具：BenchMarkSQL 5.0</a> | <a href="https://support.huaweicloud.com/tstg-kunpengdbs/kunpengbenchmarksql_06_0002.html">使用方法</a></li>
<li>PG 版本： 10.15</li>
<li>PG 服务器主要参数： 4C 8G</li>
<li>PG 驱动版本：postgresql-42.2.11</li>
<li>客户端参数：略</li>
</ul>
<blockquote>
<p>​		BenchmarkSQL is an open source implementation of the popular TPC/C OLTP
database benchmark. Version 5.0 is a major overhaul of the benchmark driver.
This version supports Firebird, Oracle and PostgreSQL, adds foreign keys to
the schema (as required by the specifications) and captures detailed benchmark</p>
</blockquote>
<h3><a class="header" href="#532-测试模型tpc-c-标准测试" id="532-测试模型tpc-c-标准测试">5.3.2 测试模型：TPC-C 标准测试</a></h3>
<p><strong>TPC-C 标准测试模拟了 5 种事务处理，通过这些事务处理来模拟真实的用户操作，事务分别为</strong>:</p>
<ul>
<li>新订单（New-Order）</li>
<li>支付操作(Payment)</li>
<li>订单状态查询(Order-Status)</li>
<li>发货(Delivery)</li>
<li>库存状态查询(Stock-Level)</li>
</ul>
<h3><a class="header" href="#533-benchmarksql-指标说明" id="533-benchmarksql-指标说明">5.3.3 BenchmarkSQL 指标说明</a></h3>
<ul>
<li>Latency 表示完全执行一个指令所需的时钟周期，潜伏期越少越好。</li>
<li>tmpC 表示每分钟执行的事务数(NewOrders)</li>
<li>tmpTOTAL 表示每分钟执行的总事务数</li>
<li>runMins BenchmarkSQL 测试模式，分为 runTxnsPerTerminal 和 runMins ：
<ul>
<li>runTxnsPerTerminal ：每个终端执行数模式</li>
<li>runMins：执行时长模式</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#534-ha-jdbc-连接基准测试" id="534-ha-jdbc-连接基准测试">5.3.4 HA JDBC 连接基准测试</a></h3>
<blockquote>
<p>采用 BenchmarkSQL runMins 模式进行测试。</p>
</blockquote>
<h4><a class="header" href="#5341-a-hreftechprojectpghapressure-testsingle_t16_10m1reporthtml基准参照数据a" id="5341-a-hreftechprojectpghapressure-testsingle_t16_10m1reporthtml基准参照数据a">5.3.4.1 <a href="tech/project/PGHA/./pressure-test/single_t16_10m#1/report.html">基准参照数据</a></a></h4>
<blockquote>
<p>​		基准参照数据取单机 JDBC 连接的的基准测试，单机是指只有一个主节点，没有 standby 节点数据复制的影响。测试多组，以下指标展示为典型值。</p>
</blockquote>
<p><strong>Run Properties</strong></p>
<blockquote>
<p>10:45:09,874 [main] INFO   jTPCC : Term-00, +-------------------------------------------------------------+
10:45:09,875 [main] INFO   jTPCC : Term-00,      BenchmarkSQL v5.0
10:45:09,875 [main] INFO   jTPCC : Term-00, +-------------------------------------------------------------+
10:45:09,875 [main] INFO   jTPCC : Term-00,  (c) 2003, Raul Barbosa
10:45:09,875 [main] INFO   jTPCC : Term-00,  (c) 2004-2016, Denis Lussier
10:45:09,876 [main] INFO   jTPCC : Term-00,  (c) 2016, Jan Wieck
10:45:09,877 [main] INFO   jTPCC : Term-00, +-------------------------------------------------------------+
10:45:09,877 [main] INFO   jTPCC : Term-00,
10:45:09,878 [main] INFO   jTPCC : Term-00, db=postgres
10:45:09,878 [main] INFO   jTPCC : Term-00, driver=org.postgresql.Driver
10:45:09,879 [main] INFO   jTPCC : Term-00, conn=<strong>jdbc:postgresql://pg-node1:5432/pressure</strong>
10:45:09,879 [main] INFO   jTPCC : Term-00, user=postgres
10:45:09,879 [main] INFO   jTPCC : Term-00,
10:45:09,879 [main] INFO   jTPCC : Term-00, warehouses=10
10:45:09,879 [main] INFO   jTPCC : Term-00, terminals=16
10:45:09,880 [main] INFO   jTPCC : Term-00, runMins=10
10:45:09,880 [main] INFO   jTPCC : Term-00, limitTxnsPerMin=100000
10:45:09,880 [main] INFO   jTPCC : Term-00, terminalWarehouseFixed=true
10:45:09,880 [main] INFO   jTPCC : Term-00,
10:45:09,880 [main] INFO   jTPCC : Term-00, newOrderWeight=45
10:45:09,881 [main] INFO   jTPCC : Term-00, paymentWeight=43
10:45:09,881 [main] INFO   jTPCC : Term-00, orderStatusWeight=4
10:45:09,881 [main] INFO   jTPCC : Term-00, deliveryWeight=4
10:45:09,881 [main] INFO   jTPCC : Term-00, stockLevelWeight=4</p>
<p>10:55:31,085 [Thread-13] INFO   jTPCC : Term-00, Measured tpmC (NewOrders) = 5435.37
10:55:31,086 [Thread-13] INFO   jTPCC : Term-00, Measured tpmTOTAL = 12056.08
10:55:31,086 [Thread-13] INFO   jTPCC : Term-00, Session Start     = 2020-12-18 10:45:30
10:55:31,086 [Thread-13] INFO   jTPCC : Term-00, Session End       = 2020-12-18 10:55:31
10:55:31,086 [Thread-13] INFO   jTPCC : Term-00, Transaction Count = 120627</p>
</blockquote>
<p><strong>Result Summary</strong></p>
<table width="1100px" border="2">
    <tr>
      <th rowspan="2" width="16%"><b>Transaction<br/>Type</b></th>
      <th colspan="2" width="24%"><b>Latency</b></th>
      <th rowspan="2" width="12%"><b>Count</b></th>
      <th rowspan="2" width="12%"><b>Percent</b></th>
      <th rowspan="2" width="12%"><b>Rollback</b></th>
      <th rowspan="2" width="12%"><b>Errors</b></th>
      <th rowspan="2" width="12%"><b>Skipped<br/>Deliveries</b></th>
    </tr>
    <tr>
      <th width="12%"><b>90th&nbsp;%</b></th>
      <th width="12%"><b>Maximum</b></th>
    </tr>
    <tr>
      <td align="left">NEW_ORDER</td>
      <td align="right">0.139s</td>
      <td align="right">2.956s</td>
      <td align="right">54384</td>
      <td align="right">45.084%</td>
      <td align="right">1.081%</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">PAYMENT</td>
      <td align="right">0.050s</td>
      <td align="right">2.917s</td>
      <td align="right">51700</td>
      <td align="right">42.859%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">ORDER_STATUS</td>
      <td align="right">0.017s</td>
      <td align="right">0.193s</td>
      <td align="right">4781</td>
      <td align="right">3.963%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">STOCK_LEVEL</td>
      <td align="right">0.018s</td>
      <td align="right">0.617s</td>
      <td align="right">4863</td>
      <td align="right">4.031%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">DELIVERY</td>
      <td align="right">0.000s</td>
      <td align="right">0.001s</td>
      <td align="right">4899</td>
      <td align="right">4.061%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">DELIVERY_BG</td>
      <td align="right">0.441s</td>
      <td align="right">3.166s</td>
      <td align="right">4899</td>
      <td align="right">N/A</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">0</td>
    </tr>
    </table>
<p><strong>TPM and TL</strong></p>
<p><img src="tech/project/PGHA/./pressure-test/single_t16_10m#1/tpm_nopm.png" alt="" /></p>
<p><img src="tech/project/PGHA/./pressure-test/single_t16_10m#1/latency.png" alt="" /></p>
<h4><a class="header" href="#5342-a-hreftechprojectpghapressure-testha_t16_10m1reporthtmlha-jdbc-基准测试数据a" id="5342-a-hreftechprojectpghapressure-testha_t16_10m1reporthtmlha-jdbc-基准测试数据a">5.3.4.2 <a href="tech/project/PGHA/./pressure-test/ha_t16_10m#1/report.html">HA JDBC 基准测试数据</a></a></h4>
<blockquote>
<p>测试多组，以下指标展示为典型值。</p>
</blockquote>
<p><strong>Run Properties</strong></p>
<blockquote>
<p>12:17:50,020 [main] INFO   jTPCC : Term-00, +-------------------------------------------------------------+
12:17:50,020 [main] INFO   jTPCC : Term-00,      BenchmarkSQL v5.0
12:17:50,020 [main] INFO   jTPCC : Term-00, +-------------------------------------------------------------+
12:17:50,020 [main] INFO   jTPCC : Term-00,  (c) 2003, Raul Barbosa
12:17:50,020 [main] INFO   jTPCC : Term-00,  (c) 2004-2016, Denis Lussier
12:17:50,022 [main] INFO   jTPCC : Term-00,  (c) 2016, Jan Wieck
12:17:50,023 [main] INFO   jTPCC : Term-00, +-------------------------------------------------------------+
12:17:50,023 [main] INFO   jTPCC : Term-00,
12:17:50,023 [main] INFO   jTPCC : Term-00, db=postgres
12:17:50,023 [main] INFO   jTPCC : Term-00, driver=org.postgresql.Driver
12:17:50,023 [main] INFO   jTPCC : Term-00, conn=<strong>jdbc:postgresql://pg-node3:5432,pg-node2:5432,pg-node1:5432/pressure?targetServerType=master</strong>
12:17:50,023 [main] INFO   jTPCC : Term-00, user=postgres
12:17:50,023 [main] INFO   jTPCC : Term-00,
12:17:50,024 [main] INFO   jTPCC : Term-00, warehouses=10
12:17:50,024 [main] INFO   jTPCC : Term-00, terminals=16
12:17:50,025 [main] INFO   jTPCC : Term-00, runMins=10
12:17:50,025 [main] INFO   jTPCC : Term-00, limitTxnsPerMin=100000
12:17:50,025 [main] INFO   jTPCC : Term-00, terminalWarehouseFixed=true
12:17:50,025 [main] INFO   jTPCC : Term-00,
12:17:50,025 [main] INFO   jTPCC : Term-00, newOrderWeight=45
12:17:50,025 [main] INFO   jTPCC : Term-00, paymentWeight=43
12:17:50,025 [main] INFO   jTPCC : Term-00, orderStatusWeight=4
12:17:50,025 [main] INFO   jTPCC : Term-00, deliveryWeight=4
12:17:50,026 [main] INFO   jTPCC : Term-00, stockLevelWeight=4</p>
<p>12:28:21,752 [Thread-9] INFO   jTPCC : Term-00, Measured tpmC (NewOrders) = 4963.44
12:28:21,752 [Thread-9] INFO   jTPCC : Term-00, Measured tpmTOTAL = 10986.67
12:28:21,752 [Thread-9] INFO   jTPCC : Term-00, Session Start     = 2020-12-18 12:18:21
12:28:21,753 [Thread-9] INFO   jTPCC : Term-00, Session End       = 2020-12-18 12:28:21
12:28:21,753 [Thread-9] INFO   jTPCC : Term-00, Transaction Count = 109971</p>
</blockquote>
<p><strong>Result Summary</strong></p>
<table width="1100px" border="2">
    <tr>
      <th rowspan="2" width="16%"><b>Transaction<br/>Type</b></th>
      <th colspan="2" width="24%"><b>Latency</b></th>
      <th rowspan="2" width="12%"><b>Count</b></th>
      <th rowspan="2" width="12%"><b>Percent</b></th>
      <th rowspan="2" width="12%"><b>Rollback</b></th>
      <th rowspan="2" width="12%"><b>Errors</b></th>
      <th rowspan="2" width="12%"><b>Skipped<br/>Deliveries</b></th>
    </tr>
    <tr>
      <th width="12%"><b>90th&nbsp;%</b></th>
      <th width="12%"><b>Maximum</b></th>
    </tr>
    <tr>
      <td align="left">NEW_ORDER</td>
      <td align="right">0.170s</td>
      <td align="right">4.330s</td>
      <td align="right">49682</td>
      <td align="right">45.177%</td>
      <td align="right">1.012%</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">PAYMENT</td>
      <td align="right">0.062s</td>
      <td align="right">4.268s</td>
      <td align="right">47264</td>
      <td align="right">42.979%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">ORDER_STATUS</td>
      <td align="right">0.016s</td>
      <td align="right">0.271s</td>
      <td align="right">4330</td>
      <td align="right">3.937%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">STOCK_LEVEL</td>
      <td align="right">0.038s</td>
      <td align="right">0.447s</td>
      <td align="right">4386</td>
      <td align="right">3.988%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">DELIVERY</td>
      <td align="right">0.000s</td>
      <td align="right">0.001s</td>
      <td align="right">4309</td>
      <td align="right">3.918%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">DELIVERY_BG</td>
      <td align="right">0.455s</td>
      <td align="right">4.377s</td>
      <td align="right">4309</td>
      <td align="right">N/A</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">0</td>
    </tr>
    </table>
**TPM and TL**
<p><img src="tech/project/PGHA/./pressure-test/ha_t16_10m#1/tpm_nopm.png" alt="" /></p>
<p><img src="tech/project/PGHA/./pressure-test/ha_t16_10m#1/latency.png" alt="" /></p>
<h4><a class="header" href="#5343-基准测试结果" id="5343-基准测试结果">5.3.4.3 基准测试结果</a></h4>
<table width="1100px" border="2">
    <tr>
      <th rowspan="2" width="12%"><b>JDBC Type</b></th>
	  <th rowspan="2" width="8%"><b>Terminsls</b></th>
      <th colspan="3" width="30%" align="center"><b>tpmC</b></th>
	  <th colspan="3" width="30%" align="center"><b>tpmTOTAL</b></th>
	  <th colspan="2" width="20%" align="center"><b>Average</b></th>
    </tr>
    <tr>
      <th width="10%"><b>#1</b></th>
      <th width="10%"><b>#2</b></th>
      <th width="10%"><b>#3</b></th>
	  <th width="10%"><b>#1</b></th>
      <th width="10%"><b>#2</b></th>
      <th width="10%"><b>#3</b></th>
	  <th width="10%"><b>tpmC</b></th>
      <th width="10%"><b>tpmTOTAL</b></th>
    </tr>
    <tr>
      <td align="center">HA</td>
      <td align="center">16</td>
      <td align="right"><a href='./pressure-test/ha_t16_10m#1/report.html'>4963.44</a></td>
      <td align="right"><a href='./pressure-test/ha_t16_10m#2/report.html'>4898.79</a></td>
      <td align="right"><a href='./pressure-test/ha_t16_10m#3/report.html'>4657.05</a></td>
      <td align="right"><a href='./pressure-test/ha_t16_10m#1/report.html'>10986.67</a></td>
      <td align="right"><a href='./pressure-test/ha_t16_10m#2/report.html'>10883.45</a></td>
      <td align="right"><a href='./pressure-test/ha_t16_10m#3/report.html'>10324.87</a></td>
	  <td align="right">4839.76</td>
      <td align="right">10731.66</td>
    </tr>
    <tr>
      <td align="center">Single</td>
      <td align="center">16</td>
      <td align="right"><a href='./pressure-test/single_t16_10m#1/report.html'>5435.37</a></td>
      <td align="right"><a href='./pressure-test/single_t16_10m#2/report.html'>5114.47</a></td>
      <td align="right"><a href='./pressure-test/single_t16_10m#3/report.html'>5412.43</a></td>
      <td align="right"><a href='./pressure-test/single_t16_10m#1/report.html'>12056.08</a></td>
      <td align="right"><a href='./pressure-test/single_t16_10m#2/report.html'>11341.28</a></td>
      <td align="right"><a href='./pressure-test/single_t16_10m#3/report.html'>12007.29</a></td>
	  <td align="right">5320.76</td>
      <td align="right">11801.55</td>
    </tr>
    </table>
<h2><a class="header" href="#54-压测" id="54-压测">5.4 压测</a></h2>
<blockquote>
<p>压测主要指标解读参照基准测试。</p>
</blockquote>
<h4><a class="header" href="#a-hreftechprojectpghapressure-testha_t16_1h1reporthtmlterminal16-主要指标a" id="a-hreftechprojectpghapressure-testha_t16_1h1reporthtmlterminal16-主要指标a"><strong><a href="tech/project/PGHA/./pressure-test/ha_t16_1h#1/report.html">terminal=16 主要指标</a></strong></a></h4>
<p><strong>Run Properties</strong></p>
<blockquote>
<p>db=postgres
driver=org.postgresql.Driver
conn=jdbc:postgresql://pg-node3:5432,pg-node2:5432,pg-node1:5432/pressure?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;targetServerType=master
user=postgres</p>
<p>warehouses=10
terminals=16
runMins=60
limitTxnsPerMin=100000</p>
<p>Running Average tpmTOTAL: 5960.14    Current tpmTOTAL: 2365524    Memory Usage: 117MB / 159MB</p>
<p>Measured tpmC (NewOrders) = 2677.05
Measured tpmTOTAL = 5960.14
Session Start     = 2020-11-30 15:17:35
Session End       = 2020-11-30 16:17:37
Transaction Count = 357847</p>
</blockquote>
<p><strong>Result Summary</strong></p>
<table width="1100px" border="2">
    <tr>
      <th rowspan="2" width="16%"><b>Transaction<br/>Type</b></th>
      <th colspan="2" width="24%"><b>Latency</b></th>
      <th rowspan="2" width="12%"><b>Count</b></th>
      <th rowspan="2" width="12%"><b>Percent</b></th>
      <th rowspan="2" width="12%"><b>Rollback</b></th>
      <th rowspan="2" width="12%"><b>Errors</b></th>
      <th rowspan="2" width="12%"><b>Skipped<br/>Deliveries</b></th>
    </tr>
    <tr>
      <th width="12%"><b>90th&nbsp;%</b></th>
      <th width="12%"><b>Maximum</b></th>
    </tr>
    <tr>
      <td align="left">NEW_ORDER</td>
      <td align="right">0.362s</td>
      <td align="right">16.688s</td>
      <td align="right">160731</td>
      <td align="right">44.916%</td>
      <td align="right">0.978%</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">PAYMENT</td>
      <td align="right">0.189s</td>
      <td align="right">14.234s</td>
      <td align="right">154400</td>
      <td align="right">43.147%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">ORDER_STATUS</td>
      <td align="right">0.110s</td>
      <td align="right">2.864s</td>
      <td align="right">14371</td>
      <td align="right">4.016%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">STOCK_LEVEL</td>
      <td align="right">0.072s</td>
      <td align="right">13.617s</td>
      <td align="right">14038</td>
      <td align="right">3.923%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">DELIVERY</td>
      <td align="right">0.000s</td>
      <td align="right">0.001s</td>
      <td align="right">14307</td>
      <td align="right">3.998%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">DELIVERY_BG</td>
      <td align="right">0.914s</td>
      <td align="right">14.876s</td>
      <td align="right">14307</td>
      <td align="right">N/A</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">0</td>
    </tr>
    </table>
<p><strong>TPM and TL</strong></p>
<p><img src="tech/project/PGHA/./pressure-test/ha_t16_1h#1/tpm_nopm.png" alt="" /></p>
<p><img src="tech/project/PGHA/./pressure-test/ha_t16_1h#1/latency.png" alt="" /></p>
<h4><a class="header" href="#a-hreftechprojectpghapressure-testha_t32_1h1reporthtmlterminal32-主要指标a" id="a-hreftechprojectpghapressure-testha_t32_1h1reporthtmlterminal32-主要指标a"><strong><a href="tech/project/PGHA/./pressure-test/ha_t32_1h#1/report.html">terminal=32 主要指标</a></strong></a></h4>
<p><strong>Run Properties</strong></p>
<blockquote>
<p>db=postgres
driver=org.postgresql.Driver
conn=jdbc:postgresql://pg-node3:5432,pg-node2:5432,pg-node1:5432/pressure?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;targetServerType=master
user=postgres</p>
<p>warehouses=10
terminals=32
runMins=60
limitTxnsPerMin=100000</p>
<p>Running Average tpmTOTAL: 7846.76    Current tpmTOTAL: 3115428    Memory Usage: 44MB / 83MB</p>
<p>Measured tpmC (NewOrders) = 3519.94
Measured tpmTOTAL = 7846.88
Session Start     = 2020-11-30 11:40:57
Session End       = 2020-11-30 12:40:57
Transaction Count = 470833</p>
</blockquote>
<p><strong>Result Summary</strong></p>
<table width="1100px" border="2">
    <tr>
      <th rowspan="2" width="16%"><b>Transaction<br/>Type</b></th>
      <th colspan="2" width="24%"><b>Latency</b></th>
      <th rowspan="2" width="12%"><b>Count</b></th>
      <th rowspan="2" width="12%"><b>Percent</b></th>
      <th rowspan="2" width="12%"><b>Rollback</b></th>
      <th rowspan="2" width="12%"><b>Errors</b></th>
      <th rowspan="2" width="12%"><b>Skipped<br/>Deliveries</b></th>
    </tr>
    <tr>
      <th width="12%"><b>90th&nbsp;%</b></th>
      <th width="12%"><b>Maximum</b></th>
    </tr>
    <tr>
      <td align="left">NEW_ORDER</td>
      <td align="right">0.576s</td>
      <td align="right">13.890s</td>
      <td align="right">211206</td>
      <td align="right">44.858%</td>
      <td align="right">1.008%</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">PAYMENT</td>
      <td align="right">0.429s</td>
      <td align="right">14.443s</td>
      <td align="right">203260</td>
      <td align="right">43.170%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">ORDER_STATUS</td>
      <td align="right">0.166s</td>
      <td align="right">2.983s</td>
      <td align="right">18754</td>
      <td align="right">3.983%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">STOCK_LEVEL</td>
      <td align="right">0.065s</td>
      <td align="right">11.492s</td>
      <td align="right">18946</td>
      <td align="right">4.024%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">DELIVERY</td>
      <td align="right">0.000s</td>
      <td align="right">0.005s</td>
      <td align="right">18667</td>
      <td align="right">3.965%</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">N/A</td>
    </tr>
    <tr>
      <td align="left">DELIVERY_BG</td>
      <td align="right">1.344s</td>
      <td align="right">16.202s</td>
      <td align="right">18667</td>
      <td align="right">N/A</td>
      <td align="right">N/A</td>
      <td align="right">0</td>
      <td align="right">0</td>
    </tr>
    </table>
<p><strong>TPM and TL</strong></p>
<p><img src="tech/project/PGHA/./pressure-test/ha_t32_1h#1/tpm_nopm.png" alt="" /></p>
<p><img src="tech/project/PGHA/./pressure-test/ha_t32_1h#1/latency.png" alt="" /></p>
<h2><a class="header" href="#55-测试结论" id="55-测试结论">5.5 测试结论</a></h2>
<blockquote>
<ul>
<li>故障转移测试
<ul>
<li><a href="tech/project/PGHA/pg-ha-solution.html#%E5%9C%BA%E6%99%AF%E4%B8%80">场景一</a>：验证任意一个节点故障，都能保证PG服务可用和数据安全，<strong>符合预期</strong>；</li>
<li><a href="tech/project/PGHA/pg-ha-solution.html#%E5%9C%BA%E6%99%AF%E4%BA%8C">场景二</a>：验证了standby 故障，当可用 standby 节点数 &lt; number_sync_standbys 时 PG 服务将<strong>降级为只读</strong>，<strong>符合预期</strong>；验证了主节点和一个 standby 节点故障，不影响可用性，<strong>符合预期</strong>；</li>
<li><a href="tech/project/PGHA/pg-ha-solution.html#%E5%9C%BA%E6%99%AF%E4%B8%89">场景三</a> 验证 Monitor 节点故障不影响 PG 服务，<strong>符合预期</strong>；</li>
<li><a href="tech/project/PGHA/">Monitor 故障转移测试</a>验证了 Monitor SPOF 解决方案的功能可行，<strong>符合预期</strong>；</li>
</ul>
</li>
<li>应用 JDBC 连接测试正常，<strong>符合预期</strong>；</li>
<li>从基准测试结果的两组数据对比上看，HA 和单机连接单位时间内执行的事务数差距大概差距在8%-10%（这个差距依据测试模型中 newOrder 的数据得出），<strong>略大于预期的5%</strong>。</li>
<li>压测中发现，大量的写操作会造成复制节点pg_wal 大量增长，磁盘压力增大，需要增对 pg_wal 参数进行调优。</li>
</ul>
</blockquote>
<h1><a class="header" href="#6--应用" id="6--应用">6  应用</a></h1>
<blockquote>
<p>任何阶段的风险和不适用评估都会对下一阶段有决定性的影响。</p>
</blockquote>
<table><thead><tr><th>阶段</th><th>规模</th><th>目标</th><th>下个阶段</th><th>备注</th></tr></thead><tbody>
<tr><td>DEV_READY</td><td>2个应用</td><td>failover 压测稳定运行 1周</td><td>DEV</td><td><strong>已稳定运行7天</strong></td></tr>
<tr><td>DEV</td><td>全部应用</td><td>稳定运行 3周</td><td>TEST</td><td>/</td></tr>
<tr><td>TEST</td><td>全部应用</td><td>稳定运行 3周</td><td>PROD_READY</td><td>/</td></tr>
<tr><td>PROD_READY</td><td>符合业务规模的压力测试</td><td>稳定运行4周</td><td>PROD</td><td>/</td></tr>
<tr><td>PROD</td><td>待定</td><td>/</td><td>/</td><td>/</td></tr>
</tbody></table>
<h1><a class="header" href="#7-总结" id="7-总结">7 总结</a></h1>
<blockquote>
<p>​		PG HA方案解决了目前生产上 PG 单点故障问题，实现 Postgres 服务和数据集的高可用性，在原有 pg-auto-failover 之上补充了 Monitor SPOF 的解决方案。整体方案在 DEV_READY 阶段做了完整测试和验证，包括：故障转移（压测）、JDBC 应用层接入、数据库基准、数据库压测，测试结果基本符合预期；数据基准测试性能上的差距主因是同步的流复制，流复制是主流 PG Active/Standby HA 方案的基础，这部分性能上的差距在类似方案上也是存在的；在验证和测试部分下个阶段可以更深入关注异步复制的影响、基准上参照可以考虑对比非 pg-auto-failover 中自动配置的流复制。</p>
<p>​		整体上推荐方案进入下一阶段的使用和验证。</p>
<p>​</p>
</blockquote>
<h1><a class="header" href="#附录" id="附录">附录</a></h1>
<h2><a class="header" href="#a-hrefhttpspg-auto-failoverreadthedocsioenlatestarchitecturehtmlpg-auto-failover-glossarypg_auto_failover-glossarya" id="a-hrefhttpspg-auto-failoverreadthedocsioenlatestarchitecturehtmlpg-auto-failover-glossarypg_auto_failover-glossarya"><a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture.html#pg-auto-failover-glossary">pg_auto_failover Glossary</a></a></h2>
<table><thead><tr><th>概念</th><th>描述</th></tr></thead><tbody>
<tr><td>Formation</td><td><strong>编队</strong>是一起管理的 PG 服务的逻辑集合。</td></tr>
<tr><td>Monitor</td><td><strong>Monitor</strong> 是 pg-auto-failover 里的一个服务，用于跟踪一个或多个包含<strong>节点组</strong>的<strong>编队</strong>。Monitor 服务以一个 PG 扩展的方式实现，所以当创建 Monitor 服务时，将会初始化一个 PG 实例，并使用该扩展进行配置和启动。Monitor 服务时嵌入在 PG 实例里面的</td></tr>
<tr><td>Group</td><td><strong>节点组</strong>， 一个<strong>节点组</strong>由 PG 主节点和具有一个或多个同步复制的 standby 节点组成，以 HA 的方式提供单个 PG 服务。</td></tr>
<tr><td>Keeper</td><td><strong>Keeper</strong> 是 pg-auto-failover 的<strong>守护程序</strong>，必须在运行 PG 节点的服务器上运行。Keeper 控制本地的 PG 实例（通过 pg_ctl 命令和 SQL 查询），并与 <strong>Monitor</strong> 通信：<br/>      1、根据PG 的统计信息视图，发送本地节点的更新数据，例如服务器之间的 WAL 增量<br/>     2、从 Monitor 接受状态分配</td></tr>
<tr><td>Node</td><td><strong>节点</strong>是运行 PG 实例和 <strong>Keeper</strong> 服务的服务器。</td></tr>
<tr><td>State</td><td><strong>状态</strong>是每个实例和每个组情况的表示。</td></tr>
</tbody></table>
<h2><a class="header" href="#a-hrefhttpspg-auto-failoverreadthedocsioenlatestfailover-state-machinehtmlstate-referencefailover-state-referencea" id="a-hrefhttpspg-auto-failoverreadthedocsioenlatestfailover-state-machinehtmlstate-referencefailover-state-referencea"><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#state-reference">Failover State reference</a></a></h2>
<img src="tech/project/PGHA/./assets/arch-Failover-State-Machine.svg" style="zoom:175%" />
<table><thead><tr><th>状态</th><th>描述</th><th>场景</th></tr></thead><tbody>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#init">init</a></td><td>节点<strong>第一次</strong>向 Monitor <strong>注册</strong>时，被分配的状态；这时除了知道节点<strong>存在</strong>，并不知道节点的任何信息。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#single">single</a></td><td><strong>只有一个节点</strong>时，或其他节点被删除时；此时相当于当个 PG 实例，没有 HA 和 failover的能力。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#wait-primary">wait_primary</a></td><td>计划成为主节点（primary），但还未成为时；此时这个节点已知 standby 节点的信息（名称、IP），并允许 hot standby （复制连接）。</td><td>1、新的健康节点注册时 <br/>2、现有 Secondary 节点不健康时（这种情况下，从 priamry 到 wait_primary 这段时间内，同步复制和查询都会被限制）</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#join-primary">join_primary</a></td><td>当 standby 节点加入时，应用于主节点；此时主节点将修改HBA 设置，之后新的节点才能使用 pg_basebackup 命令。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#primary">primary</a></td><td>当主节点存在一个健康的 standby 节点，并且 WAL 复制落后为0。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#wait-standby">wait_standby</a></td><td>Monitor 判定为 standby 节点，此时等待主节点授权允许 hot standby（复制连接）。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#catchingup">catching_up</a></td><td>主节点允许 hot standby（复制连接）时，standby 节点被分配的状态。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#secondary">secondary</a></td><td>是主节点的 hot standby ，WAL 是最新的。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#maintenance">maintenance</a></td><td>节点进入维护状态。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#prepare-maintenance">prepare_maintenance</a></td><td>主节点进入维护状态前的中间状态，确保 standby 节点完成所有写确认。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#wait-maintenance">wait-maintenance</a></td><td>standby 节点进入维护状态前的中间状态；为了确保写不会被阻塞，节点会被切换到异步复制。</td><td>/</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#draining">draining</a></td><td>primary 和 demoted 之间的中间状态，等待复制缓冲区完成刷新；此时节点将不会接受新的写请求。</td><td>主节点故障时，被降级</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#demoted">demoted</a></td><td>主节点处于降级状态，PG 实例将会被停止。</td><td></td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#demote-timeout">demote-timeout</a></td><td>主节点被 Monitor 分配 demoted 状态，但主节点上的 keeper 服务未在超时窗口内进行确认收到，此时Monitor 会分配 demote-timeout 给主节点。</td><td>主节点突然断电或关机了，被降级，keeper 服务未报告状态。</td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#stop-replication">stop-replication</a></td><td>stop-replication 状态确保在故障转移时，主数据库先进入 demoted（降级）状态， standby 才变为单个数据库（可写）。</td><td></td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#prepare-promotion">prepare-promotion</a></td><td>prepare_promotion 状态用于准备将 standby 服务器升级。</td><td></td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#report-lsn">report-lsn</a></td><td>当故障转移时，存在多个 standby 节点时，将report_lsn 状态分配给 standby 节点；Monitor 将会选择偏移最大 LSN 作为新的主节点，所以所有 standby 会先报告最新的 LSN。</td><td></td></tr>
<tr><td><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#fast-forward">fast-forward</a></td><td>故障转移时，当一个 standby 节点被选为主节点是因为 candidate-priority 配置（比其它节点的大），而不是因为它的 LSN 偏移最大，此时节点会被分配 fast_forward 状态，由此节点会利用 PG 级联复制功能，从最大 LSN  standby 节点获取丢失的 WAL。</td><td></td></tr>
</tbody></table>
<h2><a class="header" href="#a-hrefhttpspg-auto-failoverreadthedocsioenlatestfailover-state-machinehtmlfailover-logicfailover-logica" id="a-hrefhttpspg-auto-failoverreadthedocsioenlatestfailover-state-machinehtmlfailover-logicfailover-logica"><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html#failover-logic">Failover logic</a></a></h2>
<h3><a class="header" href="#node-state-machine" id="node-state-machine">Node state machine</a></h3>
<p><img src="tech/project/PGHA/./assets/arch-auto-HA-node-states.svg" alt="" /></p>
<h3><a class="header" href="#group-state-machine" id="group-state-machine">Group state machine</a></h3>
<p><img src="tech/project/PGHA/./assets/arch-auto-HA-group-states.svg" alt="" /></p>
<h1><a class="header" href="#fqa" id="fqa">FQA</a></h1>
<p><a href="https://zhuanlan.zhihu.com/p/166218704">pg_wal 文件膨胀</a></p>
<p><a href="http://www.postgres.cn/docs/10/wal-configuration.html">wal configuration</a></p>
<p><a href="http://www.postgres.cn/news/viewone/1/273">如何遏制PostgreSQL WAL的疯狂增长</a></p>
<p>虚拟机下使用 huge_page 重启后，huge_page失效，PG会重启失败</p>
<p><a href="https://www.modb.pro/db/14150">PostgreSQL数据库Linux内核参数调优</a></p>
<p><a href="http://www.pgsql.tech/project_300_10000084">PostgreSQL优化之Linux 内核参数调优</a></p>
<p><a href="http://citusdb.cn/?p=1076">pg-auto-failover 介绍</a></p>
<p><a href="https://github.com/citusdata/pg_auto_failover">pg-auto-failover source code</a></p>
<p><a href="https://pg-auto-failover.readthedocs.io/en/latest/install.html">install pg-auto-failover</a></p>
<p><a href="https://pg-auto-failover.readthedocs.io/en/latest/tutorial.html">pg-auto-failover docs</a></p>
<p><a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture.html#pg-auto-failover-glossary">pg-auto-failover glossary</a></p>
<p><a href="https://pg-auto-failover.readthedocs.io/en/latest/failover-state-machine.html">pg-auto-failover: failover state machine</a></p>
<p><a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture.html#synchronous-vs-asynchronous-replication">pg-auto-failover : number_sync_standby</a></p>
<p><a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture.html#client-side-ha">pg-auto-failover : Client Side HA</a></p>
<p><a href="https://pg-auto-failover.readthedocs.io/en/latest/ref/configuration.html">pg-auto-failover configuration</a></p>
<p><a href="https://pg-auto-failover.readthedocs.io/en/latest/architecture-multi-standby.html?#number-sync-standbys">Set Number Sync Standbys</a></p>
<p><a href="https://jdbc.postgresql.org/documentation/head/connect.html#connection-parameters">postgres jdbc connection parameters</a></p>
<p><a href="https://pg-auto-failover.readthedocs.io/en/latest/faq.html#the-monitor-is-a-spof-in-pg-auto-failover-design-how-should-we-handle-that">the monitor is a spof in pg-auto-failover design how should we handle that</a></p>
<p><a href="https://help.aliyun.com/document_detail/173284.html">自动故障转移和读写分离</a></p>
<p><a href="https://developer.aliyun.com/article/73930">读写分离</a></p>
<p><a href="https://sourceforge.net/projects/benchmarksql/">测试工具：BenchMarkSQL</a> | <a href="https://support.huaweicloud.com/tstg-kunpengdbs/kunpengbenchmarksql_06_0002.html">使用方法</a></p>
<p><a href="https://pgpool.net/mediawiki/index.php/Main_Page">Pgpool-II</a></p>
<p><a href="https://patroni.readthedocs.io/en/latest/">Patroni</a></p>
<p><a href="https://repmgr.org/">Repmgr</a></p>
<p><a href="https://www.postgresql.org/docs/10/warm-standby-failover.html">PostgreSQL Failover、Warm Standby</a> </p>
<p><a href="https://jdbc.postgresql.org/documentation/head/connect.html#connection-parameters">PostgreSQl Connection parameters</a></p>
<p><a href="https://www.postgresql.org/docs/10/kernel-resources.html">Postgres Kernel Resources</a></p>
<p><a href="https://baike.baidu.com/item/%E5%8D%95%E7%82%B9%E6%95%85%E9%9A%9C/3570893">SPOF</a>: 单点故障 (single point of failure)</p>
<p><a href="https://www.cnblogs.com/kevingrace/p/6248941.html">Keepalived 原理和 VRRP 协议</a></p>
<p><a href="https://my.oschina.net/u/4262664/blog/3326804">Keepalived VIP 切换配置</a></p>
<p><a href="https://keepalived-doc.readthedocs.io/zh_CN/latest/%E6%9C%AF%E8%AF%AD.html">keepalived-doc</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1496311">Linux 逻辑卷创建、挂载</a></p>
<p><a href="https://blog.csdn.net/meanshe/article/details/52065873">yum rpm 缓存路径</a> | <a href="https://www.jianshu.com/p/a295d7b1e3b3">yum 缓存配置</a></p>
<p><a href="https://blog.csdn.net/msdnchina/article/details/81167888">BenchmarkSQL  推荐配置</a></p>
<blockquote>
<p>以下部署方案适合在预生产、生产环境中使用</p>
</blockquote>
<h1><a class="header" href="#准备" id="准备">准备</a></h1>
<p><strong>主机要求<a href="tech/project/kubesphere/./kubesphere/%E5%9F%BA%E4%BA%8ELinux%E5%AE%89%E8%A3%85kubesphere3%E5%A4%9A%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4?id=step-1-%E5%87%86%E5%A4%87%E4%B8%BB%E6%9C%BA">参考</a></strong></p>
<table><thead><tr><th align="left">Host IP</th><th align="left">Host Name</th><th align="left">Role</th><th>备注</th></tr></thead><tbody>
<tr><td align="left">192.168.5.141</td><td align="left">master1</td><td align="left">master, etcd</td><td>2C/8G/100G</td></tr>
<tr><td align="left">192.168.5.142</td><td align="left">master2</td><td align="left">master, etcd</td><td>2C/8G/100G</td></tr>
<tr><td align="left">192.168.5.143</td><td align="left">master3</td><td align="left">master, etcd</td><td>2C/8G/100G</td></tr>
<tr><td align="left">192.168.5.145</td><td align="left">worker01</td><td align="left">worker</td><td>4C/16G/100G</td></tr>
<tr><td align="left">192.168.5.146</td><td align="left">worker02</td><td align="left">worker</td><td>4C/16G/100G</td></tr>
<tr><td align="left">192.168.5.147</td><td align="left">worker03</td><td align="left">worker</td><td>4C/16G/100G</td></tr>
<tr><td align="left">192.168.5.148</td><td align="left">vip</td><td align="left">vip</td><td></td></tr>
<tr><td align="left">192.168.6.156</td><td align="left">lb-0</td><td align="left">lb (Keepalived + HAProxy)</td><td></td></tr>
<tr><td align="left">192.168.6.159</td><td align="left">lb-1</td><td align="left">lb (Keepalived + HAProxy)</td><td></td></tr>
</tbody></table>
<h2><a class="header" href="#安装负载均衡器" id="安装负载均衡器">安装负载均衡器</a></h2>
<blockquote>
<p>以下使用<strong>Keepalived + HAProxy</strong>作为负载均衡器</p>
</blockquote>
<h3><a class="header" href="#yum安装" id="yum安装">yum安装</a></h3>
<pre><code class="language-shell">yum install keepalived haproxy psmisc -y
</code></pre>
<h3><a class="header" href="#配置haproxy" id="配置haproxy">配置HAProxy</a></h3>
<p>在lb-0和lb-1上做如下配置，注意backend的服务地址：</p>
<pre><code class="language-cfg"># HAProxy Configure /etc/haproxy/haproxy.cfg
global
    log         127.0.0.1 local2
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon
    # turn on stats unix socket
    stats socket /var/lib/haproxy/stats
#---------------------------------------------------------------------
# common defaults that all the 'listen' and 'backend' sections will
# use if not designated in their block
#---------------------------------------------------------------------
defaults
    log                     global
    option                  httplog
    option                  dontlognull
    timeout connect         5000
    timeout client          5000
    timeout server          5000
#---------------------------------------------------------------------
# main frontend which proxys to the backends
#---------------------------------------------------------------------
frontend  kube-apiserver
    bind *:6443
    mode tcp
    option tcplog
    default_backend kube-apiserver
#---------------------------------------------------------------------
# round robin balancing between the various backends
#---------------------------------------------------------------------
backend kube-apiserver
    mode tcp
    option tcplog
    balance     roundrobin
    default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
    server kube-apiserver-1 192.168.5.141:6443 check
    server kube-apiserver-2 192.168.5.142:6443 check
    server kube-apiserver-3 192.168.5.143:6443 check
</code></pre>
<h3><a class="header" href="#检查配置文件语法是否正确" id="检查配置文件语法是否正确">检查配置文件语法是否正确</a></h3>
<pre><code class="language-shell">haproxy -f /etc/haproxy/haproxy.cfg -c
</code></pre>
<h3><a class="header" href="#重启haproxy和enable-haproxy" id="重启haproxy和enable-haproxy">重启HAProxy和enable HAProxy</a></h3>
<pre><code class="language-shell">systemctl restart haproxy &amp;&amp; systemctl enable haproxy
</code></pre>
<p><strong>Stop HAProxy</strong></p>
<pre><code class="language-shell">systemctl stop haproxy
</code></pre>
<h3><a class="header" href="#配置keepalived" id="配置keepalived">配置Keepalived</a></h3>
<blockquote>
<p>配置文件在<code>/etc/keepalived/keepalived.conf</code></p>
</blockquote>
<!-- tabs:start -->
<h4><a class="header" href="#主haproxy" id="主haproxy"><strong>主HAProxy</strong></a></h4>
<blockquote>
<p>主HAProxy 192.168.6.156</p>
</blockquote>
<pre><code class="language-conf">global_defs {
  notification_email {
  }
  smtp_connect_timeout 30   
  router_id LVS_DEVEL01
  vrrp_skip_check_adv_addr
  vrrp_garp_interval 0
  vrrp_gna_interval 0
}
vrrp_script chk_haproxy {
  script &quot;killall -0 haproxy&quot;
  interval 2
  weight 2
}
vrrp_instance haproxy-vip {
  state MASTER  
  priority 100  
  interface ens192                       
  virtual_router_id 60
  advert_int 1
  authentication {
    auth_type PASS
    auth_pass 1111
  }
  unicast_src_ip 192.168.6.156     
  unicast_peer {
    192.168.6.159                      
  }
  virtual_ipaddress {
    #vip
    192.168.5.148/24
  }
  track_script {
    chk_haproxy
  }
}
</code></pre>
<h4><a class="header" href="#备haproxy" id="备haproxy"><strong>备HAProxy</strong></a></h4>
<blockquote>
<p>备HAProxy 192.168.6.159</p>
</blockquote>
<pre><code class="language-conf">global_defs {
  notification_email {
  }
  router_id LVS_DEVEL02
  vrrp_skip_check_adv_addr
  vrrp_garp_interval 0
  vrrp_gna_interval 0
}
vrrp_script chk_haproxy {
  script &quot;killall -0 haproxy&quot;
  interval 2
  weight 2
}
vrrp_instance haproxy-vip {
  state BACKUP
  priority 90
  interface ens192                        
  virtual_router_id 60
  advert_int 1
  authentication {
    auth_type PASS
    auth_pass 1111
  }
  unicast_src_ip 192.168.6.159      
  unicast_peer {
    192.168.6.156                        
  }
  virtual_ipaddress {
    192.168.5.148/24
  }
  track_script {
    chk_haproxy
  }
}
</code></pre>
<!-- tabs:end -->
<h3><a class="header" href="#启动keepalived并enable-keepalived" id="启动keepalived并enable-keepalived">启动keepalived并enable keepalived</a></h3>
<pre><code class="language-shell">systemctl restart keepalived &amp;&amp; systemctl enable keepalived 
</code></pre>
<h3><a class="header" href="#验证可用性" id="验证可用性">验证可用性</a></h3>
<p>用于查看每个磅节点的 vip 绑定状态：<code>ip a s</code></p>
<pre><code>ip a s
</code></pre>
<p>通过以下命令暂停 VIP 节点 HAProxy：</p>
<pre><code>systemctl stop haproxy
</code></pre>
<p>再次使用 检查每个 lb 节点的 vip 绑定，并检查 vip 是否漂移：<code>ip a s</code></p>
<pre><code>ip a s
</code></pre>
<p>或者，使用下面的命令：</p>
<pre><code>systemctl status -l keepalived
</code></pre>
<h2><a class="header" href="#创建集群" id="创建集群">创建集群</a></h2>
<p><a href="tech/project/kubesphere/./%E5%AE%B9%E5%99%A8%E5%92%8Ck8s/kubesphere/%E5%9F%BA%E4%BA%8ELinux%E5%AE%89%E8%A3%85kubesphere3%E5%A4%9A%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4?id=step-3-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E9%9B%86%E7%BE%A4"><strong>参考</strong></a></p>
<p><a href="tech/project/kubesphere/./%E5%AE%B9%E5%99%A8%E5%92%8Ck8s/kubesphere/%E5%9F%BA%E4%BA%8ELinux%E5%AE%89%E8%A3%85kubesphere3%E5%A4%9A%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4?id=%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEha"><strong>配置</strong></a></p>
<pre><code class="language-shell">./kk create cluster -f config-v1.18.6-v3-3m3w-ha.yaml
</code></pre>
<h1><a class="header" href="#构建实时湖仓" id="构建实时湖仓">构建实时湖仓</a></h1>
<blockquote>
<p>​	By <a href="tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/">Siu</a> 2021/7/24</p>
<p>​		最近一直在思考由数据采集为起始，一直到数据治理、数据服务链路的数据湖解决方案，同时也看到了业界、社区的一些新的思路如 Hudi、 Icebreg、NewSQL，结合目前公司的的大数据架构、数据服务业务做一些更深入的分析和思考。</p>
</blockquote>
<h2><a class="header" href="#1-大数据它解决了什么问题" id="1-大数据它解决了什么问题">1 大数据，它解决了什么问题？</a></h2>
<p>​		从数据管理技术的演进历程上看，从上世纪70年代第一个关系型数据库 System R 出现，到 80、90年代，涌现了大量商业关系型数据库，Oracle、IBM DB2、微软 SQL Server，以及现在比较流行的开源数据库 MySQL、PostgreSQL。</p>
<p>​		到了 2000 年初期，互联网时代到来，数据开始指数增长，<strong>传统</strong>关系型数据库无法存储、处理如此庞大的数据。2004 年，Google 的三大论文，GFS（分布文件存储）、MR（计算）、BigTable（数据架构），依此为指导 Hadoop 生态开始繁荣发展， 大家普遍认识到单一的数据库产品已经无法满足用户的需求，数据处理领域的技术方向开始分化：</p>
<ul>
<li>
<p><strong>OLTP</strong> 领域依然被<strong>传统关系型数据库</strong>占据（SQL）</p>
</li>
<li>
<p><strong>OLAP</strong> 领域则成为了<strong>大数据</strong>技术的主战场（NOSQL）</p>
</li>
</ul>
<p>​		2010s 早期，随着硬件的发展，内存、硬盘、带宽、网络延时等有了极大提升，数据库的架构迎来变革。
以 Google Spanner 代表的<strong>分布式数据库</strong>开始大规模投入生产。这时期 OLTP 和 OLAP 的概念逐渐开始模糊，HTAP 的概念应运而生，将 OLTP 和 OLAP 混合在一起，在同一个数据库上处理这两种负载，回到了数据库产品的初衷，<strong>NewSQL</strong> 时代即将到来。</p>
<p>​		现在我们再来看下这个问题”<strong>大数据，它解决了什么问题？</strong>“</p>
<ul>
<li>传统数据库可以<strong>有限的</strong>解决 OLTP 和 OLAP 负载，但当数据庞大时，AP 问题无法解决</li>
<li>大数据<strong>致力且擅长</strong>解决数据规模庞大的 OLAP 场景，特别是 Hadoop 的数仓架构逐渐成为主流（现在看，可称为<strong>传统数仓架构</strong>）</li>
</ul>
<p>这里我们关注到两个要点：</p>
<ul>
<li>
<p>**1、数仓 **</p>
</li>
<li>
<p><strong>2、NewSQL(HTAP)</strong></p>
<p><em>下面先看下传统数仓架构的演进。</em></p>
</li>
</ul>
<h2><a class="header" href="#2-传统数仓架构的演进" id="2-传统数仓架构的演进">2 传统数仓架构的演进</a></h2>
<p>​		数据仓库的概念早在上世纪90年代就已经被提出，但随着Hadoop生态的流行，数仓开始有了实际且有力的载体。下面用几个简单的架构表达各个阶段的演进。</p>
<h3><a class="header" href="#21-离线数仓t1" id="21-离线数仓t1">2.1 离线数仓（T+1）</a></h3>
<p><em><strong><code>图 2-1，数仓架构-离线数仓</code></strong></em></p>
<p><img src="tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/./assets/image-20210728112035505.png" alt="image-20210728112035505" /></p>
<h3><a class="header" href="#22-lambda-实时数仓tnm" id="22-lambda-实时数仓tnm">2.2 Lambda 实时数仓(T+nm)</a></h3>
<p><em><strong><code>图 2-2，数仓架构-lambda实时数仓</code></strong></em></p>
<p><img src="tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/./assets/image-20210728112209284.png" alt="image-20210728112209284" /></p>
<h3><a class="header" href="#23-kappa-实时数仓t0" id="23-kappa-实时数仓t0">2.3 Kappa 实时数仓(T+0)</a></h3>
<p><em><strong><code>图 2-3，数仓架构-kappa实时数仓</code></strong></em></p>
<p><img src="tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/./assets/image-20210728112258610.png" alt="image-20210728112258610" /></p>
<p><strong>数据实时性</strong>，一直都是数仓架构演进的重要目标，也是用户的重要需求。</p>
<h2><a class="header" href="#3-数仓架构的关注点" id="3-数仓架构的关注点">3 数仓架构的关注点</a></h2>
<p><em><strong><code>图 3-1，数仓架构的关注点</code></strong></em></p>
<p><img src="tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/./assets/image-20210725123136305.png" alt="image-20210725123136305" /></p>
<h2><a class="header" href="#4-当前架构" id="4-当前架构">4 当前架构</a></h2>
<blockquote>
<p>在传统数仓构建演进的过程中，业界一直在围绕两大主要目标：</p>
<ul>
<li>数据实时性</li>
<li>海量数据处理能力</li>
</ul>
</blockquote>
<h3><a class="header" href="#41-当前架构" id="41-当前架构">4.1 当前架构</a></h3>
<p><em><strong><code>图 4-1，大数据架构</code></strong></em></p>
<p><img src="tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/./assets/image-20210727173002135.png" alt="image-20210727173002135" /></p>
<h3><a class="header" href="#42-当前架构解决的问题" id="42-当前架构解决的问题">4.2 当前架构解决的问题</a></h3>
<p><em><strong><code>表 4-1，大数据组件解决问题</code></strong></em></p>
<table><thead><tr><th>组件</th><th>解决的问题</th><th>备注</th><th>归类</th></tr></thead><tbody>
<tr><td>HDFS</td><td>分布式文件存储</td><td></td><td>存储</td></tr>
<tr><td>MapReduce</td><td>批处理计算</td><td></td><td>计算</td></tr>
<tr><td>Hive</td><td>类SQL 的计算（MR）</td><td></td><td>计算</td></tr>
<tr><td>Hbase</td><td>BigTable 的开源实现，提供快速随机访问的数据的能力</td><td>依赖 MR 的计算能力，依托 HDFS 作为存储</td><td>存储、数据库</td></tr>
<tr><td>Kudu</td><td>HDFS&lt;-Kudu-&gt;Hbase，拥有一些OLAP和OLTP的特性，低延迟随机访问、逐行插入、更新和快速分析，中间层、集市层</td><td>依赖 Spark 、Impala 计算</td><td>存储，数据库</td></tr>
<tr><td>Spark</td><td>处理数据（kudu），Spark Streaming 实时处理</td><td></td><td>计算</td></tr>
<tr><td>Impala</td><td>交互式查询，解决hive的查询时延问题（目前用于公司的查询检索产品），MPP 计算分析</td><td>采用 HDFS 和 HBase 存储数据</td><td>计算，MPP</td></tr>
<tr><td>ES</td><td>对外服务接口</td><td></td><td>计算、存储</td></tr>
</tbody></table>
<h3><a class="header" href="#43-当前架构存在的问题" id="43-当前架构存在的问题">4.3 当前架构存在的问题</a></h3>
<ul>
<li>
<p>目前并未演进到 lambda、kappa 架构，数据延时高</p>
</li>
<li>
<p>数仓分层经过 ETL 逻辑复杂，一份数据存储于多种介质，存储、时间成本过高</p>
</li>
<li>
<p>数据链路长</p>
</li>
<li>
<p>技术栈复杂</p>
</li>
<li>
<p>数据开发技术成本大：尤其是数据开发工程师、数据分析工程师</p>
</li>
</ul>
<h2><a class="header" href="#5-我们需要解决的几大问题" id="5-我们需要解决的几大问题">5 我们需要解决的几大问题</a></h2>
<p>我们要解决的几大问题：</p>
<p>1、业务在线层：</p>
<ul>
<li>数据汇聚：在线业务的数据CDC或批量采集同步（医院的交易型系统数据）、海量存储、高并发写、行更新</li>
<li>数据服务：OLTP、海量存储（PB）</li>
</ul>
<p>2、离线数仓层（数据湖）：海量存储（10PB+）、计算（批处理）</p>
<p>3、实时数仓层：OLAP、MPP、海量存储（PB）、计算（流处理）</p>
<p>下面我们看下，上文关注的第二个重点 <strong>NewSQL(HTAP)</strong> 会给数仓建设带来什么样的解决思路。</p>
<h2><a class="header" href="#6-newsql-的实时数仓架构" id="6-newsql-的实时数仓架构">6 NewSQL 的实时数仓架构</a></h2>
<h3><a class="header" href="#61-mysql-作为数仓有什么问题" id="61-mysql-作为数仓有什么问题">6.1 MySQL 作为数仓有什么问题？</a></h3>
<blockquote>
<p>​		上面提到传统数据库具备<strong>有限的</strong>解决 OLTP 和 OLAP 的负载，但并没有深入讨论，传统关系型数据库的不足；这里假设一下用 MySQL 作为我们的数据仓库架构核心会面临哪些问题（ODS、DWD、DWS、ADS）。</p>
</blockquote>
<ul>
<li>无法满足海量数据的存储（ODS、DWD、DWS）</li>
<li>无法满足海量数据的分析需求（DWD、DWS）</li>
<li>无法满足<strong>大规模并行计算</strong>的需求（ODS、DWD）</li>
<li>无法满足<strong>横向扩展</strong>的需求（ODS、DWD、DWS）</li>
</ul>
<h3><a class="header" href="#62-tidb-能力对比" id="62-tidb-能力对比">6.2 TiDB 能力对比</a></h3>
<blockquote>
<p>​		<strong>TiDB</strong> 是一个开源的 NewSQL 数据库，支持混合交易和分析处理 （HTAP） 工作负载。它兼容 MySQL，可水平扩展、具有强一致性、分布式和高可用性的特点。</p>
</blockquote>
<p><em><strong><code>表 6-1，TiDB 能力对比</code></strong></em></p>
<table><thead><tr><th>能力</th><th>现有方案</th><th>TiDB</th></tr></thead><tbody>
<tr><td>随机访问的数据库（二级索引）</td><td>是，hbase + phoenix</td><td>是</td></tr>
<tr><td>随机访问、更新</td><td>是，kudu</td><td>是</td></tr>
<tr><td>海量存储</td><td>是，hdfs</td><td>是 + hdfs</td></tr>
<tr><td>MPP 能力</td><td>是，impala</td><td>是，Tiflash</td></tr>
<tr><td>交互查询</td><td>是，impala</td><td>是</td></tr>
<tr><td>类 sql 查询</td><td>是，impala、hive</td><td>是</td></tr>
<tr><td>批处理计算能力</td><td>是，MR、Spark</td><td>是，TiSpark</td></tr>
<tr><td>数据应用层点查能力</td><td>是，ES + hbase</td><td>是</td></tr>
<tr><td>通用的数据访问协议</td><td>否</td><td>是，兼容 MySQL 5.7</td></tr>
<tr><td>高级数据库的权限模型</td><td>否</td><td>是，mysql 的权限模型</td></tr>
<tr><td>标准SQL 查询能力</td><td>否</td><td>是，SQL</td></tr>
<tr><td>实时数仓</td><td>否，未来可演进</td><td>是</td></tr>
<tr><td>AP、TP 负载隔离</td><td>否</td><td>是，TiFlash</td></tr>
</tbody></table>
<h3><a class="header" href="#63-newsql-产品对比" id="63-newsql-产品对比">6.3 NewSQL 产品对比</a></h3>
<blockquote>
<p>待补充，StarRocks 为不同的产品类型。</p>
</blockquote>
<p><em><strong><code>表 6-2，NewSQL 产品横向对比</code></strong></em></p>
<table><thead><tr><th></th><th><a href="https://github.com/cockroachdb/cockroach">cockroachdb</a></th><th><a href="https://github.com/oceanbase/oceanbase">OceanBase</a></th><th><a href="https://github.com/pingcap/tidb">TiDB</a></th><th>StarRocks（略）</th></tr></thead><tbody>
<tr><td>类型</td><td>分布式/NewSQL/HTAP</td><td>分布式/NewSQL/HTAP</td><td>分布式/NewSQL/HTAP</td><td>分布式/MPP</td></tr>
<tr><td>定位</td><td>The most highly evolved database on the planet. Born in the Cloud. Architected to Scale and Survive.</td><td>分布式关系数据库</td><td>实时 HTAP 数据库</td><td>极速MPP数据库</td></tr>
<tr><td>开源</td><td>2014，MIT<br>Star 21.1k<br>Contributions 512</td><td>2021，MulanPubL-2.0<br>Star 3.3k<br>Contributions 70</td><td>2014，Apache License 2.0<br>Star 29.1k<br> Contributions 626</td><td>2021，Elastic License 2.0<br>Star 1.2k<br>Contributions 35</td></tr>
<tr><td>文档</td><td>[英文](CockroachDB Docs)</td><td><a href="https://www.oceanbase.com/docs/oceanbase-database/oceanbase-database/V3.1.2/features">中文</a></td><td><a href="https://docs.pingcap.com/zh/tidb/stable">中/英文</a></td><td>https://docs.starrocks.com/zh-cn/main/introduction/StarRocks_intro</td></tr>
<tr><td>数据量级</td><td>PB</td><td>PB，单表万亿，1500 节点</td><td>PB，单表千亿，500 节点</td><td>10PB</td></tr>
<tr><td>ACID</td><td>是</td><td>是</td><td>是</td><td>部分</td></tr>
<tr><td>SQL</td><td>兼容 postgresql</td><td>兼容 mysql 5.6，兼容 oracle（企业版）</td><td>兼容 mysql 5.7</td><td>兼容 mysql</td></tr>
<tr><td>安全</td><td>RBAC；LDAP</td><td>RBAC</td><td>RBAC，表级</td><td>RBAC，表级；LDAP</td></tr>
<tr><td>多租户</td><td></td><td>是，资源隔离</td><td></td><td></td></tr>
<tr><td>分布式事务</td><td>乐观事务模型</td><td></td><td>乐观事务模型</td><td></td></tr>
<tr><td>KV存储引擎</td><td>RocksDB</td><td></td><td>RocksDB</td><td></td></tr>
<tr><td>数据一致性/共识算法</td><td>Raft</td><td>Paxos</td><td>Raft</td><td>Paxos</td></tr>
<tr><td>部署</td><td></td><td></td><td>tiup</td><td>企业版有部署管理工具</td></tr>
<tr><td>监控</td><td></td><td></td><td>tidb dashboard,grafana</td><td></td></tr>
<tr><td>数据迁移</td><td></td><td></td><td></td><td></td></tr>
<tr><td>总结</td><td></td><td></td><td>AP 在 Tiflash 加持下会比 oceanbase 性能好，</td><td></td></tr>
</tbody></table>
<ul>
<li>TP：ob&gt;tidb/cr&gt;sr</li>
<li>AP：sr&gt;tidb&gt;ob/cr</li>
<li>开源和生态：tidb&gt;cr/sr/ob</li>
</ul>
<h3><a class="header" href="#64-tidb--的应用场景" id="64-tidb--的应用场景">6.4 TiDB  的应用场景</a></h3>
<blockquote>
<p>​		TiDB 的应用案例很多，有很多互联网、金融行业的成功实践案例：</p>
<p>丰巢、美团、北京银行、光大银行、中国平安、小红书，360、陆金所、中通、58、汽车之家、中国电信、国家电网</p>
</blockquote>
<ul>
<li>
<p>替换 Mysql 作为 TP库，带来 AP 能力，交易分析一体化</p>
<ul>
<li>[丰巢](<a href="https://asktug.com/t/topic/1570">[精选实践]TiDB 在丰巢核心支付平台百亿级数据的深度实践 - 技术文章 / 用户实践 - AskTUG</a>)：核心支付系统，百亿规模数据</li>
<li>[美团](<a href="https://pingcap.com/cases-cn/user-case-meituandianping">客户案例 | PingCAP</a>)：数百个 TiDB 集群，1700 多个物理节点。单集群最大 40 多个节点，单表记录最大上<strong>千亿</strong>条；</li>
<li>中国银行：支撑域、监控系统</li>
<li>[光大银行](<a href="https://pingcap.com/cases-cn/user-case-china-everbright-bank">客户案例 | PingCAP</a>)：理财业务、2000万笔/小时、5000万笔/日，40TB</li>
<li>北京银行：支付清算平台、银联无卡快捷支付平台、金融服务互联平台、网贷业务平台核心金融业务场景</li>
<li>中国平安、陆金所</li>
</ul>
</li>
<li>
<p>实时数仓方案</p>
<ul>
<li>浙商银行：实时数仓、数据量等未知</li>
<li>[小红书](<a href="https://pingcap.com/cases-cn/user-case-xiaohongshu-2">客户案例 | PingCAP</a>)：实时数据服务，数据产生的速率峰值 QPS 达到三四万，单表一天写入 5 亿左右的数据</li>
<li>[中通](<a href="https://pingcap.com/cases-cn/user-case-zto-express">客户案例 | PingCAP</a>):双十一大促中，TiDB 同时支撑线上 OLTP 和 OLAP 的业务， QPS 峰值在 12 万+，支持百亿级的插入和更新。</li>
</ul>
</li>
<li>
<p>作为组件的替代方案</p>
<ul>
<li>hbase 用 TiKV</li>
<li>MPP 场景应用</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#65--构建数据湖和实时数仓" id="65--构建数据湖和实时数仓">6.5  构建数据湖和实时数仓</a></h3>
<h4><a class="header" href="#651-总体架构" id="651-总体架构">6.5.1 总体架构</a></h4>
<p><em><strong><code>图 6-1，整体架构</code></strong></em></p>
<p><img src="tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/./assets/image-20210727173050831.png" alt="image-20210727173050831" /></p>
<p>​		用户的数据可以通过各种各样的方式写进 TiDB，在 TiDB 里面在进行一些 ETL 之类的操作然后写入到离线计算中，最后再将结果反馈到 TiDB。TiDB 可以直接对外提供实时数据分析的服务，这也是非常流行的架构之一。</p>
<h4><a class="header" href="#652-技术架构" id="652-技术架构">6.5.2 技术架构</a></h4>
<p><em><strong><code>图 6-2，技术架构</code></strong></em></p>
<p><img src="tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/./assets/arch-%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84V4.drawio.svg" alt="image-20210803104125135" /></p>
<ul>
<li>四个场景
<ul>
<li>数据汇聚
<ul>
<li>CDC</li>
<li>批流一体（Flink SQL + UDF），入湖入仓</li>
<li>异构数据海量存储</li>
<li><del>治理系统数据、标化系统维表数据</del></li>
<li><del>hive metadata（调度监控、资源监控的场景）</del></li>
</ul>
</li>
<li>数据服务
<ul>
<li>接口点查</li>
<li><del>事务型交易</del></li>
<li>数据导入/导出</li>
</ul>
</li>
<li>数据分析
<ul>
<li>数仓多维分析、关联分析（MPP/TiFlash）</li>
<li>湖仓数据关联分析（TiSpark/Spark）</li>
<li>Ad-hoc ，大数据交互查询（Trino+Iceberg，MPP/TiFlash）</li>
<li>跨源级联查询（Trino）</li>
</ul>
</li>
<li>数据共享交换
<ul>
<li>湖仓数据交换（TiSpark/Spark）</li>
<li><del>跨域的数据交换（ADS，TiBinlog）</del></li>
<li><del>跨域的数据发布/订阅（ADS，TiCDC+MQ+多租户）</del></li>
</ul>
</li>
</ul>
</li>
<li>三层架构
<ul>
<li>业务层
<ul>
<li>CDC + MQ + 批流一体（Flink SQL/UDF），实时处理入湖入仓</li>
<li>标准服务接入方式 SQL/JDBC，可负载交易系统</li>
<li>提供数据服务、数据分析、数据共享交换标准的接口/服务</li>
</ul>
</li>
<li>实时数仓
<ul>
<li>分析和点查（HTAP）</li>
<li>HTAP 负载隔离，按需扩展</li>
<li>PB 级数据负载能力</li>
<li>数据权限/访问控制（RBAC）</li>
</ul>
</li>
<li>数据湖
<ul>
<li>统一存储、异构海量存储（结构/半结构/非结构化数据）</li>
<li><del>具备湖仓一体的能力</del></li>
</ul>
</li>
</ul>
</li>
<li>主要技术栈：
<ul>
<li>存储：HDFS、TiKV/TiFlash(RocksDB)</li>
<li>计算：Flink、Spark、MR/Tez
<ul>
<li>SQL/MPP 引擎：Trino</li>
</ul>
</li>
<li>其它：
<ul>
<li>iceberg（表格式）、Ranger（权限）、ShardingSphere（脱敏加密）</li>
</ul>
</li>
</ul>
</li>
<li>降本方案
<ul>
<li><del>AIT（all-in-tidb，or in NewSQL）</del></li>
<li><del>AISR （all-in-starrocks）</del></li>
</ul>
</li>
</ul>
<h4><a class="header" href="#653-业务架构待更新" id="653-业务架构待更新">6.5.3 业务架构（待更新）</a></h4>
<p><em><strong><code>图 6-3，业务架构</code></strong></em></p>
<h4><a class="header" href="#654-收益" id="654-收益">6.5.4 收益</a></h4>
<table><thead><tr><th>序号</th><th>收益</th></tr></thead><tbody>
<tr><td>1</td><td><strong>数据实时性高</strong></td></tr>
<tr><td>2</td><td>技术栈统一，可扩展性强</td></tr>
<tr><td>3</td><td>数据业务线清晰：<br/>    - 数据开发：采集（CDC）、实时处理（Flink）、批处理（Spark）<br/>    - 数仓建设：围绕 TiDB 构建数据服务<br/>    - 数据分析： MPP 引擎、TiSpark/Spark 构建分析能力</td></tr>
<tr><td>4</td><td>数据内治理：统一的数据仓库，hive meta+治理交易数据/标化维表数据，一定程度达到”数据内治理“<br/>		- 库、表、字段元信息<br/>	    - 表：表行数、表大小、行平均大小、创建时间、更新时间</td></tr>
<tr><td>5</td><td>数据安全<br/>	- 数仓：<a href="https://docs.pingcap.com/zh/tidb/dev/security-compatibility-with-mysql">数据权限控制（RBAC，库、表）</a><br/>	- 数仓：数据脱敏、数据加密（中间件提供支持）<br/>    - <del>数据湖：iceberg +ranger</del></td></tr>
<tr><td>6</td><td>开发体验：<br/>	- 数据访问方式 SQL，Mysql 协议<br/>	- 基于 SQL 数据分析 <br/>	- 丰富的 SQL Client</td></tr>
<tr><td>7</td><td>节约成本：覆盖大部分场景，OLTP（100%）、OLAP（&gt;80%）；节约存储、计算、带宽</td></tr>
<tr><td>8</td><td>运维和管理：<br/>  -  Ambari <br/>  -  扩容工具 TiUP<br/>  -  备份与恢复工具 BR<br/>  -  监控：TiDB Dashboard 集群关键指标：SQL 分析/慢日志，实例、主机、Region 监控等</td></tr>
</tbody></table>
<h3><a class="header" href="#65-poc-计划" id="65-poc-计划">6.5 POC 计划</a></h3>
<blockquote>
<p>待补充</p>
</blockquote>
<h4><a class="header" href="#651-整体目标" id="651-整体目标">6.5.1 整体目标</a></h4>
<ul>
<li>数据实时：10 mins</li>
<li>数据仓库：分层统一存储，提供大部分数据服务能力（现有100%，未来80% 场景）</li>
<li>数据内治理：满足基础元数据治理的需求（数据仓库）</li>
<li>数据安全
<ul>
<li>数据仓库中实现基于角色的权限控制（库、表）</li>
<li>数据仓库中实现数据脱敏、加密（透明中间件）</li>
</ul>
</li>
<li>数据湖：海量存储数据（结构化、半结构化、非结构化）和数仓模型类数据、离线分析、湖仓数据交换</li>
</ul>
<p>问题：</p>
<ul>
<li>批量写的性能问题是否存在？如果存在如何规避</li>
<li>大字段的存储限制（6M-120M）</li>
<li><del>宽表限制：默认为 1017，最大可调至 4096</del></li>
<li><del>技术的掌握能力</del></li>
</ul>
<h2><a class="header" href="#ref-2" id="ref-2">REF</a></h2>
<ul>
<li>
<p>Kudu</p>
<ul>
<li>kudu现在拥有一些OLAP和OLTP的特性，但是缺少对跨行的原子性、一致性、隔离性、持久性事务的支持</li>
<li><strong>kudu仅仅是一个存储层，因此它并不处理数据，而是依赖于外部的处理引擎比如Imapala、Spark等来处理。kudu把数据按照自己的列存储格式存储在底层的Linux文件系统，不像HBase那样，Kudu不以任何方式使用HDFS。</strong></li>
</ul>
</li>
<li>
<p><a href="https://db-engines.com/en/system/Impala%3BTiDB">Impala vs. TiDB Comparison (db-engines.com)</a></p>
</li>
<li>
<p>Impala 大数据生态的MPP</p>
</li>
<li>
<p>TiDB</p>
<ul>
<li>
<p>真正意义上的 HTAP 数据库；</p>
</li>
<li>
<p>互相隔离的 OLAP 和 OLTP 负载；</p>
</li>
<li>
<p>分析友好，强实时性、强一致性的列存；</p>
</li>
</ul>
</li>
<li>
<p>DW数据分层，由下到上为DWD，DWB，DWS。</p>
<ul>
<li>
<p>DWD：data warehouse details 细节数据层，是业务层与数据仓库的隔离层。主要对ODS数据层做一些</p>
<p>数据清洗和规范化</p>
<p>的操作。</p>
<ul>
<li>数据清洗：去除空值、脏数据、超过极限范围的</li>
</ul>
</li>
<li>
<p>DWB：data warehouse base 数据基础层，存储的是客观数据，一般用作中间层，可以认为是大量指标的数据层。</p>
</li>
<li>
<p>DWS：data warehouse service 数据服务层，基于DWB上的基础数据，整合汇总成分析某一个主题域的服务数据层，一般是宽表。用于提供后续的业务查询，OLAP分析，数据分发等。</p>
<ul>
<li>用户行为，轻度聚合</li>
<li>主要对ODS/DWD层数据做一些轻度的汇总。</li>
</ul>
</li>
<li>
<p>ADS： application data store ，数据应用层</p>
</li>
</ul>
</li>
<li>
<p><a href="https://pingcap.com/blog-cn/when-tidb-and-flink-are-combined">当 TiDB 与 Flink 相结合：高效、易用的实时数仓 | PingCAP</a></p>
</li>
<li>
<p><a href="https://docs.pingcap.com/zh/tidb/stable/backup-and-restore-use-cases">BR 备份与恢复场景示例 | PingCAP Docs</a></p>
</li>
<li>
<p><a href="https://docs.pingcap.com/zh/tidb/stable/dumpling-overview">Dumpling 使用文档 | PingCAP Docs</a></p>
</li>
<li>
<p><a href="https://docs.pingcap.com/zh/tidb/stable/high-concurrency-best-practices">TiDB 高并发写入场景最佳实践 | PingCAP Docs</a></p>
</li>
<li>
<p><a href="https://docs.pingcap.com/zh/tidb/stable/benchmark-tpch">TiDB TPC-H 50G 性能测试报告 | PingCAP Docs</a></p>
</li>
<li>
<p><a href="https://pingcap.com/blog-cn/tidb-5.0-ga-is-now">迈向企业级核心场景的 TiDB 5.0 | PingCAP</a></p>
</li>
<li>
<p><a href="https://pingcap.com/blog-cn/tidb-5.0-htap-architecture-design-and-become-scenario-analysis">成为一栈式数据服务生态： TiDB 5.0 HTAP 架构设计与场景解析（混合负载） | PingCAP</a></p>
</li>
<li>
<p><a href="https://pingcap.com/solution-detail/tidb-realtime-warehouse-solution">TiDB 企业级解决方案 ：实时数仓解决方案| PingCAP</a></p>
</li>
<li>
<p><a href="https://zrj.me/archives/1969">再谈 SQL 引擎 | ZRJ</a></p>
</li>
<li>
<p><a href="https://docs.pingcap.com/zh/tidb/stable/tidb-configuration-file#txn-entry-size-limit-%E4%BB%8E-v50-%E7%89%88%E6%9C%AC%E5%BC%80%E5%A7%8B%E5%BC%95%E5%85%A5">TiDB 配置文件描述：列大小配置 6M-120M| PingCAP Docs</a></p>
</li>
<li>
<p><a href="https://pingcap.com/blog-cn/tidb-syncer">解析 TiDB 在线数据同步工具 Syncer | PingCAP</a></p>
</li>
<li>
<p><a href="https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/encrypt/">数据脱敏 :: ShardingSphere (apache.org)</a></p>
</li>
<li>
<p><a href="https://docs.pingcap.com/zh/tidb/stable/tidb-lightning-overview">TiDB Lightning 简介：全量数据高速导入到 TiDB 集群 | PingCAP Docs</a></p>
</li>
<li>
<p><a href="https://asktug.com/t/topic/1570">【精选实践】TiDB 在丰巢核心支付平台百亿级数据的深度实践 - 技术文章 / 用户实践 - AskTUG</a></p>
</li>
<li>
<p><a href="https://pingcap.com/case/">客户案例 | PingCAP</a></p>
</li>
<li>
<p><a href="https://blog.csdn.net/john1337/article/details/118887581">基于Flink+Iceberg构建企业级实时数据湖_johnhuster的专栏-CSDN博客</a></p>
</li>
<li>
<p><a href="https://blog.csdn.net/weixin_44904816/article/details/117677783">汽车之家：基于 Flink + Iceberg 的湖仓一体架构实践_Ververica的博客-CSDN博客</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/WCygv5L--w8I-ibbeiU-Rw">亚马逊云科技：我们的智能湖仓是架构，而非产品，更非湖仓一体 (qq.com)</a></p>
</li>
<li>
<p><a href="http://doris.apache.org/master/zh-CN/administrator-guide/materialized_view.html">物化视图 | Apache Doris</a></p>
</li>
<li>
<p><a href="https://iceberg.apache.org/evolution/">Table/Partition evolution - Apache Iceberg</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/298125721">zeppelin在云音乐的实践 - 知乎 (zhihu.com)</a></p>
</li>
<li>
<p><a href="https://docs.google.com/presentation/d/1RBe8HUtGqzlyruEyCbzKh8dxOk6D7Zd5dSz1mPXvPoc/edit#slide=id.gb53c29cf3a_0_56">TiDB 2020 Hackathon - D - TiGraph - Google 幻灯片</a></p>
</li>
<li>
<p><a href="https://asktug.com/t/topic/2026">PD的时钟服务——TSO - 技术文章 / 原理解读 - AskTUG</a></p>
</li>
<li>
<p><a href="https://ipotato.me/article/67">iPotato | PD 授时服务 TSO 设计简析</a></p>
</li>
<li>
<p><a href="https://docs.pingcap.com/zh/tidb/stable/tispark-overview">TiSpark 用户指南 | PingCAP Docs</a></p>
</li>
<li>
<p><a href="https://www.infoq.cn/article/yfxkhjdask0eme2gaqnz">滴滴大数据安全权限实践-InfoQ</a></p>
</li>
<li>
<p><a href="https://docs.pingcap.com/zh/tidb/stable/bidirectional-replication-between-tidb-clusters#%E9%9B%86%E7%BE%A4%E9%97%B4%E5%8F%8C%E5%90%91%E5%90%8C%E6%AD%A5">集群间双向同步 | PingCAP Docs</a></p>
</li>
<li>
<p><a href="https://docs.pingcap.com/zh/tidb/stable/manage-ticdc#sink-uri-%E9%85%8D%E7%BD%AE-pulsar">TiCDC 运维操作及任务管理 :sink-uri 配置 pulsar| PingCAP Docs</a></p>
</li>
<li>
<p><a href="https://github.com/pingcap/ticdc/pull/751/files">support pulsar's sink. by cocotyty · Pull Request #751 · pingcap/ticdc (github.com)</a></p>
</li>
<li>
<p><a href="https://www.modb.pro/db/70554">OceanBase开源版与TiDB对比测试报告 - 墨天轮 (modb.pro)</a></p>
</li>
</ul>
<p><strong>本页编辑</strong>      <strong><a href="http://192.168.1.23/gongshiwen">@gongshiwen</a></strong> <img src="http://192.168.1.23/uploads/-/system/user/avatar/10/avatar.png?width=100" style="zoom:10%;" /> </p>
<p>        为什么会开始思考设计 <a href="http://192.168.1.23/cecdat/framework/devops/jpl">jpl</a>  和构建 CI/CD 平台？</p>
<p>        项目越来越多，项目的构建方式各不相同， 在不同的项目团队CI 的能力水平不同，策略和模型方法也不同；整体上项目的CI 能处于较低水平（<em>按照<code>表-1</code>评估处于1-2之间的能力阶段</em>），需要系统性、自动化地提高整体的 CI 能力，提高研发效能。</p>
<p><em><code>表-1：CI 能力阶段</code></em></p>
<table><thead><tr><th>阶段</th><th>CI 能力</th></tr></thead><tbody>
<tr><td>1 初始阶段</td><td>用<strong>手工</strong>的方式或者<strong>部分自动化</strong>方式进行构建，构建环境<strong>不能保证稳定和一致性</strong>，各<br/>种工具分散管理，对源码进行了版本控制</td></tr>
<tr><td>2 基础阶段</td><td>通过持续集成服务器进行定期的自动构建，按需手动构建，或者在代码提交之后触<br/>发自动构建，基本可以保证<strong>构建是稳定的</strong>和<strong>可重复的</strong>，源码及构建所需的设定文件<br/>和脚本都纳入了版本控制</td></tr>
<tr><td><strong>3 可靠阶段</strong></td><td><strong>结合版本管理模型（分支模型）和开发方式，提供进一步的持续集成能力，不仅对<br/>代码和构建所需脚本进行了版本管理，而且能够对进行标准化构建所需的一切都进<br/>行版本管理，保证不会因为构建服务器的损坏而丧失稳定的构建能力</strong></td></tr>
<tr><td><em><strong>4 成熟阶段</strong></em></td><td><strong>具有每日数次部署或按需部署所需要的能力，使用基于主干的版本管理，构建过程<br/>实时可视</strong>，结合版本管理、需求管理、缺陷管理、运维监控进行一定程度的集成管<br/>理，能实现代码和需求的关联，缺陷和需求、故障和需求等局部关联，并可以进行<br/>相关数据的展示和分析</td></tr>
<tr><td>5 优化阶段</td><td>依据持续集成的统计反馈信息进行不断改善和优化，形成需求、缺陷、运维、监控<br/>统一的管理平台，以促进各个团队之间更好地进行协作和沟通</td></tr>
</tbody></table>
<p>        那 <code>jpl</code> 又是什么？</p>
<p>        <a href="http://192.168.1.23/cecdat/framework/devops/jpl">jpl</a> 是一个内部公共的 Jenkins Pipeline Library ，基于 Jenkins 扩展共享库（<em><strong>Shared Library</strong></em>）的能力，用 groovy 代码定义和编排 CI/CD 流水线<strong>阶段</strong>和<strong>步骤</strong>，用于简化项目的 CI/CD 配置，提升项目的 CI/CD 能力：使项目保持<strong>频繁部署</strong>，快速生成可部署的软件，提高项目的<strong>能见度</strong>；快速发布，能够应对业务需求，并更快地实现软件价值；编码-&gt;测试-&gt;上线-&gt;交付的<strong>迭代周期缩短</strong>，同时获得迅速反馈。</p>
<p>        <code>jpl</code> 基于 Jenkins 作为 CI/CD 的执行引擎，并结合<strong>当前公司业务特性</strong>和<strong>规范</strong>设计的多分支流水线，实现了包括：代码检出、前置检查（仓库规范、分支模型规范、<code>Semver</code> 规范）、编译和打包、Sonar 扫描、提交分析、自动归档制品、部署、触发自动化接口测试、自动合并代码、归档已发布代码、邮件通知等流水线步骤；借助 <code>Jenkins BlueOcean</code> 的功能使构建过程<strong>实时可视</strong>，并设计实现了一些常用的<strong>图形化操作</strong>：启停服务、从制品库发布、手动部署所有服务、刷新<code>Jenkinsfile</code>、跳过阶段、暂停进入调试。</p>
<p>        <code>jpl</code> 实现了 <em><strong><code>Pipeline as Code</code></strong></em>，为 CI/CD 实践过程中的“最后一公里”保驾护航。</p>
<h3><a class="header" href="#ref-3" id="ref-3">Ref</a></h3>
<ul>
<li>
<p><em>表-1 来自《企业级 DevOps 实战》</em></p>
</li>
<li>
<p><a href="https://insights.thoughtworks.cn/pipeline-as-code/">流水线即代码(Pipeline as Code)：通过编码而非配置持续集成/持续交付(CI/CD)运行工具的方式定义部署流水线</a></p>
</li>
<li>
<p>持续集成（continuous integration）</p>
</li>
</ul>
<blockquote>
<p>​  持续集成是一种软件开发实践，要求团队成员经常集成他们的工作。开发人员每次代码合并都会触发持续集成服务器进行自动构建，这个过程包括了编译、单元测试、集成测试、质量分析等步骤，通过自动化的过程进行验证，以尽快检测集成错误。这种方法会使得集成问题大幅减少，更快地实现有凝聚力的软件开发。</p>
<p>​                                                                                                                                                    Martin Fowler</p>
</blockquote>
<h1><a class="header" href="#cicd-架构" id="cicd-架构">CI/CD 架构</a></h1>
<p><img src="tech/project/cicd/design/assets/image-20210524093913685.png" alt="image-20210524093913685" /></p>
<ul>
<li>规范：定义流水线、分支模型和开发方式</li>
<li>分布式代码版本管理（Gitlab）</li>
<li>强大的、可扩展能力的 CI/CD 引擎（Jenkins）</li>
<li>Piepline Library： <code>cec-jpl</code> 定义和编排了 CI/CD 流水线(<em><strong><code>Pipeline as Code</code></strong></em>)</li>
<li>标准的软件系统依赖管理、制品管理（Nexus）</li>
</ul>
<h1><a class="header" href="#a-hrefhttp192168514949000jenkins-clustera" id="a-hrefhttp192168514949000jenkins-clustera"><a href="http://192.168.5.149:49000/">Jenkins Cluster</a></a></h1>
<p><img src="tech/project/cicd/design/./assets/image-20210629134336610.png" alt="image-20210629134336610" /></p>
<p>        <code>Jenkins</code> 作为 CI/CD 的执行引擎，构建一个可快速故障恢复、迁移，动态伸缩的 Jenkins 集群是设计阶段的主要目标。为此在设计之初，投入了大量时间调研、测试，最终选用 Docker 来动态构建我们的 Jenkins 集群：</p>
<ul>
<li>
<p>服务可快速恢复：当 Jenkins Master 出现故障时，通过docker可快速恢；</p>
</li>
<li>
<p>构建环境稳定和一致：通过docker容器，保障每个流水线运行环境一致；</p>
</li>
<li>
<p>动态伸缩，合理使用资源：每次运行 Job 时，会创建一个 Jenkins Slave，Job 完成后，Slave 自动注销并删除容器，资源自动释放。</p>
</li>
<li>
<p>扩展性好：当资源严重不足而导致 Job 排队等待时，可以很容易调整slave的数量，从而实现扩展。</p>
</li>
</ul>
<p><a href="tech/project/cicd/design/./pages/jenkins%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/Docker%E5%8A%A8%E6%80%81%E6%9E%84%E5%BB%BAJenkins_Slave">参见: Docker 动态构建 Jenkins Slave</a></p>
<h1><a class="header" href="#多分支流水线设计" id="多分支流水线设计">多分支流水线设计</a></h1>
<h4><a class="header" href="#流水线阶段" id="流水线阶段">流水线阶段</a></h4>
<p><img src="tech/project/cicd/design/./assets/pipeline_stage.png" alt="" /></p>
<h4><a class="header" href="#分支模型和多分支流水线" id="分支模型和多分支流水线">分支模型和多分支流水线</a></h4>
<!-- tabs:start -->
<h4><a class="header" href="#-v2-" id="-v2-">** v2 **</a></h4>
<p><img src="tech/project/cicd/design/./assets/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E8%AE%BE%E8%AE%A1-%E5%88%86%E6%94%AF%E6%A8%A1%E5%9E%8B%E5%92%8CCI_V2.png" alt="" /></p>
<p><em><code>表-2-1：多分支流水线（V2）</code></em></p>
<table><thead><tr><th>流水线名称</th><th>分支</th><th>分支类型</th><th>分支保护</th><th>是否归档制品</th><th>buildId 起始</th><th>部署环境</th><th>成功后影响</th></tr></thead><tbody>
<tr><td>开发预发验证</td><td>feature-*</td><td>临时</td><td>否</td><td>否</td><td>100</td><td>DEV</td><td>/</td></tr>
<tr><td>开发集成</td><td>develop</td><td><strong>永久</strong></td><td><strong>是</strong></td><td><strong>是</strong></td><td>1000</td><td>DEV</td><td>/</td></tr>
<tr><td>测试集成</td><td>release-*</td><td>临时</td><td><strong>是</strong></td><td><strong>是</strong></td><td>300</td><td>TEST</td><td>/</td></tr>
<tr><td>测试集成  (BUG）</td><td>fix-*</td><td>临时</td><td>否</td><td>否</td><td>500</td><td>/</td><td>PR &amp; Merge 到 develop，触发开发集成</td></tr>
<tr><td>预生产集成</td><td>pre-*</td><td>临时</td><td>否</td><td>否</td><td>700</td><td>PROD</td><td>PR 到 master</td></tr>
<tr><td>预生产集成（BUG）</td><td>prefix-*</td><td>临时</td><td>否</td><td>否</td><td>800</td><td>/</td><td>PR 到 pre-*</td></tr>
<tr><td>生产预发</td><td>master</td><td><strong>永久</strong></td><td><strong>是</strong></td><td><strong>是</strong></td><td>5000</td><td>PROD</td><td>PR &amp; Merge 到 develop，触发开发集成</td></tr>
<tr><td>生产预发（BUG）</td><td>hotfix-*</td><td>临时</td><td>否</td><td>否</td><td>900</td><td>/</td><td>PR 到 master</td></tr>
</tbody></table>
<h4><a class="header" href="#-v3-" id="-v3-">** v3 **</a></h4>
<p><img src="tech/project/cicd/design/./assets/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E8%AE%BE%E8%AE%A1-%E5%88%86%E6%94%AF%E6%A8%A1%E5%9E%8B%E5%92%8CCI_V3.png" alt="" /></p>
<p><em><code>表-2-2：多分支流水线（V3）</code></em></p>
<table><thead><tr><th>流水线名称</th><th>分支</th><th>分支类型</th><th>分支保护</th><th>是否归档制品</th><th>部署环境</th><th>成功后影响</th></tr></thead><tbody>
<tr><td>开发预发验证</td><td>feature-*</td><td>临时</td><td>否</td><td>否</td><td>DEV</td><td>/</td></tr>
<tr><td>开发集成</td><td>develop</td><td><strong>永久</strong></td><td><strong>是</strong></td><td>否</td><td>DEV</td><td>/</td></tr>
<tr><td>测试集成</td><td>release-*</td><td>临时</td><td><strong>是</strong></td><td><strong>是</strong></td><td>TEST</td><td>/</td></tr>
<tr><td>测试集成  (BUG）</td><td>fix-*</td><td>临时</td><td>否</td><td>否</td><td>/</td><td>PR &amp; Merge 到 develop，触发开发集成</td></tr>
<tr><td>生产预发</td><td>master</td><td><strong>永久</strong></td><td><strong>是</strong></td><td>否</td><td>PROD</td><td>PR &amp; Merge 到 develop，触发开发集成</td></tr>
<tr><td>Hotfix</td><td>hotfix-*</td><td>临时</td><td>否</td><td>否</td><td>/</td><td>创建 release-* 分支</td></tr>
</tbody></table>
<!-- tabs:end -->
<h1><a class="header" href="#jpl-设计" id="jpl-设计">jpl 设计</a></h1>
<h4><a class="header" href="#源码结构" id="源码结构">源码结构</a></h4>
<p><strong>Shared Library 的标准源码结构：</strong></p>
<pre><code class="language-txt">.
├── pom.xml 项目依赖配置
├── resources 配置和资源文件
├── src 主要存放 groovy 类，执行流水线时，Jenkins 会将这些类加载到 classpath
├── test 单元测试
└── vars 流水线入口、流水线阶段和步骤的脚本，也是由 groovy 编写的，这些脚本会作为流水线的变量公开
</code></pre>
<h4><a class="header" href="#约定优于配置" id="约定优于配置">约定优于配置</a></h4>
<p>整体上 <code>jpl</code> 采用 “约定优于配置”，让80%的项目接入几乎做到“0”配置，<code>jpl</code> 中“约定“：</p>
<ul>
<li>打包描述文件 <code>pom.xml</code> 或 <code>package.json</code> 放在项目的根目录</li>
<li>默认部署路径为：<code>/app/ecdat/[web/server/jar]/{artifactId}</code></li>
<li>后端项目的启停脚本打包后存在于 <code>./bin</code> 下，<code>startup.sh ${env}、shutdown.sh</code> 或 <code>app.sh start、app.sh stop</code></li>
<li>项目遵循<a href="tech/project/cicd/design/./pages/%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3/%E5%88%B6%E5%93%81%E8%A7%84%E8%8C%83">《制品规范》</a>、<a href="tech/project/cicd/design/./pages/%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3/%E8%AF%AD%E4%B9%89%E5%8C%96%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E8%A7%84%E8%8C%83">《语义版本规范》</a>、<a href="tech/project/cicd/design/./pages/%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3/%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E7%BB%84%E7%BB%87%E8%A7%84%E8%8C%83">《代码仓库规范》</a>、分支模型规范</li>
</ul>
<h5><a class="header" href="#配置采用-yml-格式" id="配置采用-yml-格式">配置采用 yml 格式</a></h5>
<blockquote>
<p>​  最早的版本，出于处理简单，数据容易解析处理（groovy），<code>jpl</code>的配置文件采用 <code>json</code> 结构，但考虑到可读性、扩展性等，最终采用更流行的 <code>yml</code> 格式。</p>
</blockquote>
<ul>
<li>YAML的可读性好</li>
<li>YAML和脚本语言的交互性好</li>
<li>YAML使用实现语言的数据类型</li>
<li>YAML表达能力强，扩展性好</li>
</ul>
<h4><a class="header" href="#执行流程" id="执行流程">执行流程</a></h4>
<p><img src="tech/project/cicd/design/./assets/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E8%AE%BE%E8%AE%A1-cecjpl-%E8%AE%BE%E8%AE%A1.png" alt="" /></p>
<p><img src="tech/project/cicd/design/./assets/image-20210524094827233.png" alt="image-20210524094827233" /></p>
<h1><a class="header" href="#数据库自动化-1" id="数据库自动化-1">数据库自动化</a></h1>
<p>        <strong>数据库自动化</strong>是构建 CI/CD 时被忽略的最重要的技术领域之一。不依赖数据库的应用程序可以快速构建起CI/CD 的能力；但是，对于依赖数据库的应用程序的部署却不那么容易。</p>
<p>        没有有效的数据库自动化，各自环境中的数据快照会应无法及时的版本迭代而趋于不可用。CI/CD 强调不断、频繁的集成和代码交付，但未能实现数据库自动化，即可能越频繁的集成反而越无法追踪数据库数据的迭代更新，需要花费更多的时间处理环境的数据问题。</p>
<p>        实现数据库自动化，尤其是对于以数据为中心的应用程序，有着至关重要的意义。</p>
<p><img src="tech/project/cicd/design/./assets/image-20210529124550140.png" alt="image-20210529124550140" /></p>
<p><a href="tech/project/cicd/design/./pages/%E8%A7%84%E8%8C%83%E6%96%87%E6%A1%A3/Flyway%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83"><strong><code>详见:《Flyway 使用规范》</code></strong></a></p>
<blockquote>
<p>​		目前大部分的应用已引入数据库自动化，但现有的方案只是针对主流的关系型数据库有效，如：</p>
<p><a href="https://flywaydb.org/documentation/database/oracle">Oracle</a>, <a href="https://flywaydb.org/documentation/database/sqlserver">SQL Server</a>, <a href="https://flywaydb.org/documentation/database/azuresynapse">Azure Synapse</a>, <a href="https://flywaydb.org/documentation/database/db2">DB2</a>, <a href="https://flywaydb.org/documentation/database/mysql">MySQL</a>, <a href="https://flywaydb.org/documentation/database/aurora-mysql">Aurora MySQL</a>, <a href="https://flywaydb.org/documentation/database/mariadb">MariaDB</a>, <a href="https://flywaydb.org/documentation/database/xtradb">Percona XtraDB Cluster</a>, <a href="https://flywaydb.org/documentation/database/testcontainers">TestContainers</a>, <a href="https://flywaydb.org/documentation/database/postgresql">PostgreSQL</a> , <a href="https://flywaydb.org/documentation/database/aurora-postgresql">Aurora PostgreSQL</a>, <a href="https://flywaydb.org/documentation/database/redshift">Redshift</a>, <a href="https://flywaydb.org/documentation/database/cockroachdb">CockroachDB</a>, <a href="https://flywaydb.org/documentation/database/saphana">SAP HANA</a>, <a href="https://flywaydb.org/documentation/database/sybasease">Sybase ASE</a>, <a href="https://flywaydb.org/documentation/database/informix">Informix</a>, <a href="https://flywaydb.org/documentation/database/h2">H2</a>, <a href="https://flywaydb.org/documentation/database/hsqldb">HSQLDB</a>, <a href="https://flywaydb.org/documentation/database/derby">Derby</a>, <a href="https://flywaydb.org/documentation/database/snowflake">Snowflake</a>, <a href="https://flywaydb.org/documentation/database/sqlite">SQLite</a> ,<a href="https://flywaydb.org/documentation/database/firebird">Firebird</a>。</p>
</blockquote>
<h1><a class="header" href="#jenkins-账号体系" id="jenkins-账号体系">Jenkins 账号体系</a></h1>
<blockquote>
<p>​			为了方便开发人员登录Jenkins，我们采用 Gitlab账号用做 Jenkins的用户权限管理；利用 OAuth ，把权限认证托管给 Gitlab ，这样只要维护现有的账户体系就可以控制 Jenkins 的用户的访问权限，避免不必要的权限扩散。</p>
</blockquote>
<p><strong>访问 <a href="http://192.168.x.xx:49000/">Jenkins 登录页</a>，会跳转到 <a href="http://192.168.x.xx/users/sign_in">Gitlab</a> 进行认证，认证成功自动跳转到 Jenkins 。</strong></p>
<h1><a class="header" href="#doris-uniq-模型分析场景下保证-key-的唯一性" id="doris-uniq-模型分析场景下保证-key-的唯一性">Doris Uniq 模型：分析场景下保证 Key 的唯一性</a></h1>
<blockquote>
<p>By <a href="tech/db/doris/doris-uniq-model/">Siu</a> 2022/4/15</p>
</blockquote>
<h2><a class="header" href="#背景" id="背景">背景</a></h2>
<p>最近了解到数据治理人员在处理数据时有一个需求：希望一张表在导入数据时能保证 key 的唯一性（全表唯一）</p>
<p>这里有两个问题要解决：</p>
<ul>
<li>Q1：保证 key 唯一，全局唯一，不仅是分区内唯一；</li>
<li>Q2：Uniq 模型在有分区情况下，只能保证分区内 key 的唯一性，如何高效处理全局重复的 key；</li>
</ul>
<h2><a class="header" href="#验证" id="验证">验证</a></h2>
<h3><a class="header" href="#创建表" id="创建表">创建表</a></h3>
<pre><code class="language-sql">drop table example_db.t_uniq_model_test;
CREATE TABLE IF NOT EXISTS example_db.t_uniq_model_test
(
    `user_id` BIGINT NOT NULL COMMENT &quot;用户id&quot;,
    `date` DATE NOT NULL COMMENT &quot;日期&quot;,
    `group_id` BIGINT COMMENT &quot;组id&quot;,
    `modify_date` DATE COMMENT &quot;修改日期&quot;,
    `keyword` VARCHAR(128) COMMENT &quot;关键字&quot;
)
UNIQUE KEY(`user_id`, `date`, `group_id`)
PARTITION BY RANGE(`date`)
(
    PARTITION `p201701` VALUES LESS THAN (&quot;2017-02-01&quot;),
    PARTITION `p201702` VALUES LESS THAN (&quot;2017-03-01&quot;),
    PARTITION `p201703` VALUES LESS THAN (&quot;2017-04-01&quot;)
)
DISTRIBUTED BY HASH(`user_id`) BUCKETS 10
PROPERTIES (
&quot;replication_allocation&quot; = &quot;tag.location.default: 3&quot;,
&quot;in_memory&quot; = &quot;false&quot;,
&quot;storage_format&quot; = &quot;V2&quot;
);

-- 开启 BATCH_DELETE 特性（默认fe已开启这个配置就不需要显示添加）
-- ALTER TABLE example_db.t_uniq_model_test ENABLE FEATURE &quot;BATCH_DELETE&quot;;
-- 隐藏 
SET show_hidden_columns=true;
desc example_db.t_uniq_model_test;
</code></pre>
<h4><a class="header" href="#导入数据" id="导入数据">导入数据</a></h4>
<pre><code class="language-sql">-- 导入3条 user_id、group_id 一样的数据，分布于 3个分区
insert into example_db.t_uniq_model_test(user_id,date,group_id,modify_date,keyword) values(4,'2017-01-02',1,'2022-01-01','k1');
insert into example_db.t_uniq_model_test(user_id,date,group_id,modify_date,keyword) values(4,'2017-02-02',1,'2022-01-02','k2');
insert into example_db.t_uniq_model_test(user_id,date,group_id,modify_date,keyword) values(4,'2017-03-03',1,'2022-01-03','k3');

select * from example_db.t_uniq_model_test order by `date` desc;
</code></pre>
<p><img src="tech/db/doris/doris-uniq-model/assets/image-20220415150109587.png" alt="image-20220415150109587" /></p>
<h3><a class="header" href="#验证分区内-key-唯一性" id="验证分区内-key-唯一性">验证分区内 key 唯一性</a></h3>
<p>在分区 p201703 中插入一行 user_id = 4、group_id = 1，keyword = ‘k3-1’</p>
<pre><code class="language-sql">insert into example_db.t_uniq_model_test(user_id,date,group_id,modify_date,keyword) values(4,'2017-03-03',1,'2022-04-15','k3-1');
select * from example_db.t_uniq_model_test order by `date` desc;
</code></pre>
<p><img src="tech/db/doris/doris-uniq-model/assets/image-20220415151023036.png" alt="image-20220415151023036" /></p>
<p>表中还是只有 3 条数据，分区内 key 相同的数据被更新了。</p>
<h3><a class="header" href="#使用-batch_delete" id="使用-batch_delete">使用 BATCH_DELETE</a></h3>
<blockquote>
<p>使用 BATCH_DELETE 来实现全表内 key 唯一性。</p>
<p>相比于直接使用 delete ，BATCH_DELETE 是一个标记删除，实际只有 insert，但是做到了 upsert 的语意。</p>
<ul>
<li>性能上更优；</li>
<li>“删除时”不会阻塞读取；</li>
</ul>
</blockquote>
<pre><code class="language-sql">insert
	into
	example_db.t_uniq_model_test (user_id,
	date,
	group_id,
	modify_date,
	keyword,
	__DORIS_DELETE_SIGN__)

	-- 根据 modify_date 找到重复的旧数据
	select
		t1.*,
		1 -- 标记为删除
	from
		example_db.t_uniq_model_test t1
	where
		EXISTS (
		select
			1
		from
			example_db.t_uniq_model_test t2
		WHERE
      -- key: user_id + group_id
			t1.user_id = t2.user_id
			and t1.group_id = t2.group_id
      -- 最新数据
			and t1.modify_date &lt;t2.modify_date );
SET show_hidden_columns=false;
select * from example_db.t_uniq_model_test order by `date` desc;

SET show_hidden_columns=true;
select * from example_db.t_uniq_model_test order by `date` desc;
</code></pre>
<p><img src="tech/db/doris/doris-uniq-model/assets/image-20220415154626995.png" alt="image-20220415154626995" /></p>
<p><img src="tech/db/doris/doris-uniq-model/assets/image-20220415155133218.png" alt="image-20220415155133218" /></p>
<h4><a class="header" href="#性能测试todo" id="性能测试todo">性能测试（todo）</a></h4>
<h1><a class="header" href="#ref-4" id="ref-4">ref</a></h1>
<p>https://doris.apache.org/branch-0.15/zh-CN/getting-started/data-model-rollup.html#uniq-%E6%A8%A1%E5%9E%8B</p>
<p>https://doris.apache.org/branch-0.15/zh-CN/getting-started/data-partition.html#%E6%95%B0%E6%8D%AE%E5%88%92%E5%88%86-2</p>
<p>https://doris.apache.org/branch-0.15/zh-CN/administrator-guide/load-data/batch-delete-manual.html#%E8%AF%AD%E6%B3%95</p>
<h1><a class="header" href="#siu-的笔记本-2" id="siu-的笔记本-2">Siu 的笔记本</a></h1>
<ul>
<li>
<p><a href="./SUMMARY.html">思考和总结🤔</a></p>
<ul>
<li><a href="./mgmt/srcwd/index.html">团队人员定义模型</a></li>
<li><a href="./tech/backend/java-mem-mgmt/java-memory-management.html">谈谈 Java 的内存管理（doing）</a></li>
</ul>
</li>
<li>
<p><a href="./SUMMARY.html">架构和设计</a></p>
<ul>
<li><a href="./tech/project/AAA/README.html">DDD 实践：应用架构原型（doing）</a></li>
<li><a href="./tech/backend/Java-Backend-Framework-Selection-Guide.html">Java 后端框架选型指南（doing）</a></li>
<li><a href="./tech/project/PGHA/pg-ha-solution.html">PG HA 方案</a></li>
<li><a href="./tech/project/kubesphere/%E5%9F%BA%E4%BA%8ELinux%E5%AE%89%E8%A3%85kubesphere3%E5%A4%9A%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4(prod).html">KuberSphere 生产部署方案</a></li>
<li><a href="./tech/project/lwpoc/lwpoc/%E6%9E%B6%E6%9E%84/%E6%9E%84%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%B9%96%E4%BB%93.html">构建实时湖仓</a></li>
<li><a href="./tech/project/cicd/README.html">CICD 设计</a>
<ul>
<li><a href="./tech/project/cicd/design/CICD%E6%9E%B6%E6%9E%84.html">CI/CD 架构</a></li>
<li><a href="./tech/project/cicd/design/Jenkins_Cluster.html">Jenkins 集群</a></li>
<li><a href="./tech/project/cicd/design/%E5%A4%9A%E5%88%86%E6%94%AF%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%AE%BE%E8%AE%A1.html">多分支流水线设计</a></li>
<li><a href="./tech/project/cicd/design/cec-jpl%E8%AE%BE%E8%AE%A1.html">cec-jpl 设计</a></li>
<li><a href="./tech/project/cicd/design/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%87%AA%E5%8A%A8%E5%8C%96.html">数据库自动化</a></li>
<li><a href="./tech/project/cicd/design/%E8%B4%A6%E5%8F%B7%E4%BD%93%E7%B3%BB.html">账号体系</a></li>
</ul>
</li>
<li><a href="./tech/db/doris/doris-uniq-model/index.html">Doris Uniq 模型：分析场景下保证 Key 的唯一性</a></li>
</ul>
</li>
<li>
<p><a href="./SUMMARY.html">最佳实践</a></p>
<ul>
<li><a href="./tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/index.html">怎样写一个技术方案的大纲</a>
<ul>
<li><a href="./tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/template.html">《技术解决方案》模版</a></li>
</ul>
</li>
<li><a href="./tech/bestpractices/my-toolchain.html">分享一下我的工具清单</a></li>
<li><a href="./tech/bestpractices/sql%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E7%9A%84%E8%AE%BE%E8%AE%A1.html">sql 性能测试工具的设计</a></li>
<li><a href="./tech/project/jrudf/README.html">Doris Remote UDF 的开发和测试</a></li>
<li><a href="./tech/bestpractices/%E7%A6%85%E9%81%93%E5%B7%A5%E4%BD%9C%E6%B5%81.html">禅道工作流</a></li>
<li><a href="./tech/bestpractices/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E8%A7%84%E8%8C%83.html">单元测试规范</a></li>
<li><a href="./tech/bestpractices/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%87%AA%E5%8A%A8%E5%8C%96-Flyway%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83.html">数据库自动化：Flyway</a></li>
<li><a href="./tech/bestpractices/%E8%AF%AD%E4%B9%89%E5%8C%96%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E8%A7%84%E8%8C%83.html">语义化版本</a></li>
<li><a href="./tech/bestpractices/API%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83.html">API设计规范</a></li>
<li><a href="./tech/bestpractices/git-collaborative-development-tutorials/git%E5%8D%8F%E5%90%8C%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.html">git 协同开发指南</a></li>
<li><a href="./tech/bestpractices/code-review-guide-baseon-gitlab.html">Gitlab Code Review 指南</a></li>
<li><a href="./tech/bestpractices/gitlab-issue-workflow.html">Gitlab Issue 工作流</a></li>
<li><a href="./tech/bestpractices/Python%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83.html">Python 编码规范</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#怎样写一个技术方案的大纲" id="怎样写一个技术方案的大纲">怎样写一个技术方案的大纲</a></h1>
<blockquote>
<p>By <a href="tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/">Siu</a> 2022/3/28</p>
</blockquote>
<h2><a class="header" href="#前言-2" id="前言-2">前言</a></h2>
<p>首先问题来源于工作上需要将最近做的一些 POC 整理成一个解决方案提供给应用平台。所以从以往的写作经验来看，首先需要能梳理出一个“大纲”，去合理规划整个解决方案的内容架构，同时这个大纲必须带上“技术”、“方案”这两个命题去思考总结。</p>
<h2><a class="header" href="#要思考哪些问题" id="要思考哪些问题">要思考哪些问题</a></h2>
<h3><a class="header" href="#写给谁" id="写给谁">写给谁</a></h3>
<p>给谁看，读者和受众是要放在第一位去思考的。</p>
<p>首先回答一下几个问题：</p>
<p><strong>为什么要写技术方案</strong>：首先我的理解解决方案是对技术、工程、产品、运营的一个体系的阐述说明；它是一个有效的载体，有利于构建方案的人更深层次的理解所做的输出是服务于什么、有利于开发人员去理解技术原理和架构、有利于产品人员去利用解决方案提供的能力实现更好的产品迭代、有利于运营人员去做好系统的维护和升级。</p>
<p><strong>技术方案的内容写给谁的</strong>：开发人员、产品经理、架构师，运维等，技术相关的人员是最大的读者。</p>
<p>由此，大纲标题必须有几个鲜明的特征：严谨、准确、简练、措词是经过业界广泛使用的（不要发明概念）。</p>
<p><strong>方案解决了什么问题</strong>：这个也是是很重要的，不仅在内容中需要体现，也需要在大纲中体现——比如有一些章节描述背景、业务需求、目标等。</p>
<p><strong><code>为什么要写 -〉写给谁看 -〉解决了什么问题</code></strong>，思考清楚再去考虑怎么写大纲的内容。</p>
<h3><a class="header" href="#怎么写" id="怎么写">怎么写</a></h3>
<p>写给谁，已经讨论完了，那怎么写？</p>
<p>还是要回到读者，读者最关心《技术方案》有哪些内容？</p>
<ul>
<li>开发：怎么使用，怎么对接，API 接口？访问协议？架构原理？文档？。。。</li>
<li>产品：亮点，解决什么问题，哪些能有效提高产品的能力。。。</li>
<li>架构师：方案所用的技术架构是否合理，安全、稳定性、扩展。。。</li>
<li>运维：有没有友好 dashboard，Grafana 指标如何获取，故障备份，运维文档，自动化部署。。。</li>
<li>...</li>
</ul>
<p>关注和收集“读者”的关注点，作为大纲内容的重要输入参考。</p>
<p>定义好“文章”的层次：技术方案是一个解决方案，会去完整的构建一个系统/框架。所以不能偏离中心——<strong><code>问题是什么&amp;用了什么技术方案解决</code></strong>。</p>
<p>层次定义好能有效指导最终的大纲框架，相当是一个中心主题。</p>
<p>层次确定了，方案名就可以定下来了。</p>
<p>定义好”逻辑“：<code>开篇〉背景〉业务需求〉技术方案〉测试论证〉总结</code>；这是一个举例，重点在于需要需求考虑怎么串联整体的逻辑，每一部分有内在的逻辑，但也要有整体和上下的联系。</p>
<h3><a class="header" href="#tips" id="tips">Tips</a></h3>
<p>还有哪些需要注意的：</p>
<ul>
<li>不要忘了开篇和总结</li>
<li>大纲标题一定要仔细定义</li>
<li>可以高屋建瓴，但要注重实践（脚本、代码、测试数据放在合适的位置，索引或附录）</li>
</ul>
<h2><a class="header" href="#大纲的内容示例" id="大纲的内容示例">大纲的内容示例</a></h2>
<p><img src="tech/bestpractices/How-to-write-an-outline-for-a-technical-solution/assets/image-20220328151253737.png" alt="image-20220328151253737" /></p>
<h2><a class="header" href="#ref-5" id="ref-5">ref</a></h2>
<p><a href="https://jiamaoxiang.top/2021/05/04/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%AF%A5%E5%A6%82%E4%BD%95%E5%86%99%E4%B8%80%E7%AF%87%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/">程序员该如何写一篇高质量的技术文章</a></p>
<p><strong>文档编号：</strong></p>
<p><strong>xxx有限公司</strong></p>
<p><strong>内部资料注意保密</strong></p>
<p><strong>文档修订记录：</strong></p>
<table><thead><tr><th><strong>版本号</strong></th><th><strong>修订日期</strong></th><th><strong>修订说明</strong></th><th><strong>修订人</strong></th><th><strong>审核人</strong></th><th><strong>批准人</strong></th></tr></thead><tbody>
<tr><td>1.0</td><td>2021/11/12</td><td>初版</td><td>xxxxxx</td><td></td><td></td></tr>
<tr><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td></td><td></td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<h1><a class="header" href="#xxx-方案" id="xxx-方案">XXX 方案</a></h1>
<h2><a class="header" href="#一总述" id="一总述">一、总述</a></h2>
<h3><a class="header" href="#11-背景" id="11-背景">1.1 背景</a></h3>
<h3><a class="header" href="#12-现状和需求分析" id="12-现状和需求分析">1.2 现状和需求分析</a></h3>
<h3><a class="header" href="#13-总体目标" id="13-总体目标">1.3 总体目标</a></h3>
<h3><a class="header" href="#14-术语缩略语" id="14-术语缩略语">1.4 术语/缩略语</a></h3>
<h3><a class="header" href="#15-参考资料" id="15-参考资料">1.5 参考资料</a></h3>
<h2><a class="header" href="#二架构设计" id="二架构设计">二、架构设计</a></h2>
<h3><a class="header" href="#21-总体思路" id="21-总体思路">2.1 总体思路</a></h3>
<h3><a class="header" href="#22-整体架构设计" id="22-整体架构设计">2.2 整体架构设计</a></h3>
<h3><a class="header" href="#23-业务架构设计" id="23-业务架构设计">2.3 业务架构设计</a></h3>
<h3><a class="header" href="#24-部署实施架构" id="24-部署实施架构">2.4 部署实施架构</a></h3>
<h4><a class="header" href="#241-硬件要求" id="241-硬件要求">2.4.1 硬件要求</a></h4>
<h4><a class="header" href="#242-部署架构" id="242-部署架构">2.4.2 部署架构</a></h4>
<h2><a class="header" href="#三方案验证" id="三方案验证">三、方案验证</a></h2>
<h3><a class="header" href="#31-部署和功能验证" id="31-部署和功能验证">3.1 部署和功能验证</a></h3>
<h4><a class="header" href="#311-部署环境" id="311-部署环境">3.1.1 部署环境</a></h4>
<h5><a class="header" href="#3111-环境要求" id="3111-环境要求">3.1.1.1 环境要求</a></h5>
<h5><a class="header" href="#3112-部署操作" id="3112-部署操作">3.1.1.2 部署操作</a></h5>
<h4><a class="header" href="#312-数据库功能验证" id="312-数据库功能验证">3.1.2 数据库功能验证</a></h4>
<h5><a class="header" href="#3121-功能验证标准" id="3121-功能验证标准">3.1.2.1 功能验证标准</a></h5>
<h5><a class="header" href="#3122-功能验证环境" id="3122-功能验证环境">3.1.2.2 功能验证环境</a></h5>
<h5><a class="header" href="#3123-功能验证过程" id="3123-功能验证过程">3.1.2.3 功能验证过程</a></h5>
<h5><a class="header" href="#3124-功能验证报告" id="3124-功能验证报告">3.1.2.4 功能验证报告</a></h5>
<h5><a class="header" href="#3125-功能验证结论" id="3125-功能验证结论">3.1.2.5 功能验证结论</a></h5>
<h4><a class="header" href="#313-配套功能方案验证" id="313-配套功能方案验证">3.1.3 配套功能方案验证</a></h4>
<h5><a class="header" href="#3131-负载均衡方案" id="3131-负载均衡方案">3.1.3.1 负载均衡方案</a></h5>
<h5><a class="header" href="#3132-监控方案" id="3132-监控方案">3.1.3.2 监控方案</a></h5>
<h5><a class="header" href="#3133-扩容方案" id="3133-扩容方案">3.1.3.3 扩容方案</a></h5>
<h5><a class="header" href="#3134-备份和恢复方案" id="3134-备份和恢复方案">3.1.3.4 备份和恢复方案</a></h5>
<h3><a class="header" href="#32-基准测试" id="32-基准测试">3.2 基准测试</a></h3>
<h4><a class="header" href="#321-基准测试模型" id="321-基准测试模型">3.2.1 基准测试模型</a></h4>
<h4><a class="header" href="#322-基准测试工具" id="322-基准测试工具">3.2.2 基准测试工具</a></h4>
<h4><a class="header" href="#323-基准测试环境" id="323-基准测试环境">3.2.3 基准测试环境</a></h4>
<h4><a class="header" href="#324-基准测试过程" id="324-基准测试过程">3.2.4 基准测试过程</a></h4>
<h4><a class="header" href="#325-基准测试报告" id="325-基准测试报告">3.2.5 基准测试报告</a></h4>
<h4><a class="header" href="#326-基准测试结论" id="326-基准测试结论">3.2.6 基准测试结论</a></h4>
<h3><a class="header" href="#33-场景验证" id="33-场景验证">3.3 场景验证</a></h3>
<h4><a class="header" href="#321-场景验证模型" id="321-场景验证模型">3.2.1 场景验证模型</a></h4>
<h4><a class="header" href="#322-场景验证工具" id="322-场景验证工具">3.2.2 场景验证工具</a></h4>
<h4><a class="header" href="#323-场景验证环境" id="323-场景验证环境">3.2.3 场景验证环境</a></h4>
<h4><a class="header" href="#324-场景验证过程" id="324-场景验证过程">3.2.4 场景验证过程</a></h4>
<h4><a class="header" href="#325-场景验证报告" id="325-场景验证报告">3.2.5 场景验证报告</a></h4>
<h4><a class="header" href="#325-场景验证结论" id="325-场景验证结论">3.2.5 场景验证结论</a></h4>
<h3><a class="header" href="#四总结" id="四总结">四、总结</a></h3>
<h3><a class="header" href="#41-方案适用场景分析和总结" id="41-方案适用场景分析和总结">4.1 方案适用场景分析和总结</a></h3>
<h3><a class="header" href="#42-方案硬件配置推荐和总结" id="42-方案硬件配置推荐和总结">4.2 方案硬件配置推荐和总结</a></h3>
<h3><a class="header" href="#43-方案总结" id="43-方案总结">4.3 方案总结</a></h3>
<h2><a class="header" href="#附录-1" id="附录-1">附录</a></h2>
<h1><a class="header" href="#我的工具清单" id="我的工具清单">我的工具清单</a></h1>
<blockquote>
<p>By <a href="tech/bestpractices/">Siu</a> 2021/3/26</p>
</blockquote>
<p>最近比较关注个人的 EDC 和日常工作流的优化，这里先分享一下我日常工作中主要的工具；关于工作流部分，再开一个主题去总结一下。</p>
<table><thead><tr><th>大类</th><th>分类</th><th>工具</th><th>备注</th></tr></thead><tbody>
<tr><td>包管理</td><td>包管理</td><td>brew</td><td>mac 包管理</td></tr>
<tr><td>包管理</td><td>包管理</td><td>Cakebrew</td><td>brew UI 管理</td></tr>
<tr><td>终端</td><td>终端</td><td>iTerm2</td><td>老牌产品了</td></tr>
<tr><td>终端</td><td>终端</td><td>Tabby</td><td>最近在使用这个</td></tr>
<tr><td>终端</td><td>终端</td><td>Warp</td><td>这个 Rust 写的，所以最近也关注了一下</td></tr>
<tr><td>终端</td><td>命令行提示</td><td>fig</td><td>推荐</td></tr>
<tr><td>终端</td><td>git 客户端</td><td>git</td><td></td></tr>
<tr><td>终端</td><td>文件目录展示</td><td>tree</td><td></td></tr>
<tr><td>开发工具</td><td>IDE</td><td>Intellij IDEA</td><td>工作主力 IDE，功能齐全、稳定；最佳的效率；</td></tr>
<tr><td>开发工具</td><td>IDE</td><td>CLion</td><td>主要用于写 Rust，其实 IDEA 装 Rust 插件也有一致的体验</td></tr>
<tr><td>开发工具</td><td>IDE</td><td>GoLand</td><td>主要用于写 Go</td></tr>
<tr><td>开发工具</td><td>IDE</td><td>PyCharm</td><td>主要用于写 Python，使用的不多</td></tr>
<tr><td>开发工具</td><td>IDE</td><td>VSCode</td><td>当作全功能编辑器来使用，也用来写 md</td></tr>
<tr><td>开发工具</td><td>抓包</td><td>Fiddler</td><td>mac 上不推荐，windows 上还是很好用的</td></tr>
<tr><td>开发工具</td><td>抓包</td><td>Proxyman</td><td>推荐；比花瓶好多了</td></tr>
<tr><td>开发工具</td><td>API</td><td>Postman</td><td></td></tr>
<tr><td>开发工具</td><td>API</td><td>BloomRPC</td><td></td></tr>
<tr><td>开发工具</td><td>API</td><td>Evans</td><td>推荐</td></tr>
<tr><td>开发工具</td><td>开发常用工具包</td><td>DevToys</td><td></td></tr>
<tr><td>开发工具</td><td>数据库客户端</td><td>DBeaver</td><td>可以替代 Navicat</td></tr>
<tr><td>开发工具</td><td>数据库客户端</td><td>Postico</td><td>PostgreSQL 客户端</td></tr>
<tr><td>开发工具</td><td>数据建模</td><td>CHINER</td><td>推荐；多端开源的产品，建模部分的 数据类型、数据域、数据字典功能还是不错的</td></tr>
<tr><td>开发工具</td><td>hosts 管理</td><td>iHosts</td><td>hosts 管理</td></tr>
<tr><td>浏览器</td><td>浏览器</td><td>Vivaldi</td><td>是一个工作站，集成了工作流中的很多场景；推荐</td></tr>
<tr><td>通信</td><td>开源社区</td><td>Slack</td><td></td></tr>
<tr><td>通信</td><td>日常</td><td>微信</td><td></td></tr>
<tr><td>通信</td><td>日常</td><td>腾讯会议</td><td></td></tr>
<tr><td>效率</td><td>Gihub 客户端</td><td>Github Desktop</td><td>主要用于管理开源的项目</td></tr>
<tr><td>效率</td><td>GTD</td><td>MacOS 日历</td><td></td></tr>
<tr><td>效率</td><td>GTD</td><td>Itsycal</td><td>推荐；试了很多 GTD 的工具，最后还是回到了学生时代的“谷歌日历”的方式，系统日历 + Itsycal 足够管理达到 GTD</td></tr>
<tr><td>效率</td><td>分屏</td><td>Rectabgle</td><td>胜在免费，功能足够</td></tr>
<tr><td>效率</td><td>粘贴板</td><td>Paste</td><td></td></tr>
<tr><td>效率</td><td>解压缩</td><td>Keka</td><td></td></tr>
<tr><td>效率</td><td>系统菜单</td><td>超级右键</td><td></td></tr>
<tr><td>效率</td><td>远程桌面</td><td>RustDesk</td><td>推荐；Rust 写的，功能还是很不错，支持多端</td></tr>
<tr><td>效率</td><td>翻墙代理</td><td>MonoProxy</td><td></td></tr>
<tr><td>效率</td><td>应用切换</td><td>AltTab</td><td>与系统tab 切换的区别是可以预览</td></tr>
<tr><td>效率</td><td>系统清理</td><td>CleanMyMac X</td><td>乌克兰一个团队的产品，收费；整体还行</td></tr>
<tr><td>创作</td><td>画图</td><td>draw.io</td><td>推荐；几乎所有的设计图都是用 draw.io画的，架构、流程、部署图，UML，时序图等等</td></tr>
<tr><td>创作</td><td>Markdown Editor</td><td>Typora</td><td>1.0 版本的价格也不是很贵，旧版免费的也可以下载</td></tr>
<tr><td>创作</td><td>笔记</td><td>MacOS 备忘录</td><td></td></tr>
<tr><td>创作</td><td>云笔记</td><td>Github + Markdown</td><td></td></tr>
<tr><td>创作</td><td>脑图</td><td>Xmind</td><td></td></tr>
<tr><td>创作</td><td>Office</td><td>Excel/Word</td><td></td></tr>
<tr><td>创作</td><td>markdown site</td><td>mdbook</td><td>适合笔记、电子书；目前我的笔记都是mdbook 构建的</td></tr>
<tr><td>创作</td><td>markdown site</td><td>Docsify</td><td>适合项目或产品的文档，还有 hugo，vuepress 也是同类</td></tr>
<tr><td>创作</td><td>markdown site</td><td>zine</td><td>可以生成杂志的版式</td></tr>
<tr><td>娱乐</td><td>音乐</td><td>网易云音乐</td><td></td></tr>
<tr><td>娱乐</td><td>下载</td><td>Motrix</td><td></td></tr>
<tr><td>娱乐</td><td>视频</td><td>WebTorrent</td><td></td></tr>
<tr><td>阅读</td><td>RSS</td><td>NetNewsWire</td><td>信息流产品用了很多，最后还是回到了学生时代的 “Google Reader”；当然 GR 已死，但 RSS 希望是永生的</td></tr>
<tr><td>阅读</td><td>RSS</td><td>RSSHub</td><td>推荐</td></tr>
</tbody></table>
<h1><a class="header" href="#sql-性能测试工具的设计" id="sql-性能测试工具的设计">sql 性能测试工具的设计</a></h1>
<blockquote>
<p>By <a href="tech/bestpractices/">Siu</a> 2022/3/17</p>
</blockquote>
<h2><a class="header" href="#前言-3" id="前言-3">前言</a></h2>
<p>当前的团队的工作比较多的会在关注和执行 sql 性能相关的测试，对于标准的测试模型，如 TPC 范围内的工具有比较好的实践方式，对于自定义和具体的场景目前团队还没有去总结一个比较好的”工具方案“，这里主要围绕这个问题去做一些分享。</p>
<h2><a class="header" href="#先看看有哪些现有工具" id="先看看有哪些现有工具">先看看有哪些现有工具？</a></h2>
<ul>
<li>Tidb bench ：C ；集成在 TiDB 中，用于 TPC-C/H 的测试，不适用于其它数据库</li>
<li>BenchMarkSQL 5.0： Java；适用于 TPC-C ，主流的 RDBMS 都支持，Mysql/PostgreSQL/Oracle 等</li>
<li>Sysbench：C；适用于 TPC-C ，主流的 RDBMS 都支持，Mysql/PostgreSQL/Oracle 等</li>
<li>mysqlslap：C；用于msyql 的性能测试</li>
<li>sqlbench：go；支持 PostgreSQL 的性能测试</li>
<li>其它的开源的库针对非传统数据库/组件：这些通常是依据标准模型 TPC-H/DS、SSB 等的实现，这部分较复杂，可以到官方和社区去找一些方案和工具（ClickHouse、Flink、Trino）</li>
</ul>
<p>简单总结：</p>
<ul>
<li>以上这些工具都是比较优秀的，大多是开源的；整体我都使用过，值得去深入了解各自的场景和特点；</li>
<li>BenchMarkSQL、Sysbench 比较合适标准模型的基准测试（mysqlslap 也比较适合，但不主流）；</li>
<li>mysqlslap、sqlbench：适用于自定义的 sql 场景的测试；</li>
</ul>
<h2><a class="header" href="#这些工具的设计" id="这些工具的设计">这些工具的“设计“</a></h2>
<blockquote>
<p>&quot;设计”，主要讨论这些工具的内部设计大体是怎么样的，哪些可以借鉴和指导我们去设计/开发我们的自定义 sql 性能测试工具/脚本。</p>
<p>当然这些我总结的”范式“可能不是真正的标准，但是已经经过了具体的借鉴和实践。</p>
</blockquote>
<h3><a class="header" href="#编程范式" id="编程范式">编程范式</a></h3>
<p>当然设计会受语言的编程范式影响，受语言特性影响，但这里忽略这部分，不做讨论。</p>
<p>实际实现的时候要考虑这部分。</p>
<h3><a class="header" href="#工具设计的拆解" id="工具设计的拆解">工具设计的拆解</a></h3>
<p>分析比较了 BenchMarkSQL 5.0、sqlbench、mysqlslap 等的功能和代码，等到如下总结：</p>
<ul>
<li>环境/全局配置：通过 CMD 参数或配置文件加载到程序
<ul>
<li>环境：系统、依赖工具、数据库信息</li>
<li>全局：工具运行时的参数，线程数、执行数等</li>
</ul>
</li>
<li>sql 任务配置：定义 sql 执行的单位</li>
<li>其它：主要是功能，造数、执行日志（参数、环境、上下文，IO，网络等）、执行结果/绘图、终端动态展示运行等</li>
</ul>
<p>用一个命令行描述：</p>
<pre><code class="language-shell">sh myApp --config=./config/env.conf --sql=./sql/* --func xxx
</code></pre>
<p>特别说下 BenchMarkSQL TPC-C 测试流程：</p>
<ul>
<li>配置数据库信息、测试的全局信息</li>
<li>启动造数据程序：元数据、数据</li>
<li>执行测试：实时输出测试指标和日志、归档日志/结果等到测试目录</li>
<li>执行绘图程序，输出图表测试结果</li>
<li>清理数据</li>
</ul>
<h2><a class="header" href="#设计一个简单的-sql-性能测试程序" id="设计一个简单的-sql-性能测试程序">设计一个简单的 sql 性能测试程序</a></h2>
<blockquote>
<p>这里以 mysqlslap + shell 去设计一个 sql 性能测试脚本。</p>
<p><em><strong>比较好的路线是基于一些标准库用某个语言去实现，这样可定制的功能比较好控制。</strong></em></p>
</blockquote>
<h3><a class="header" href="#选型-1" id="选型-1">选型</a></h3>
<ul>
<li>语言 shell：读写文件、option、函数</li>
<li>库/工具：mysqlslap</li>
</ul>
<h3><a class="header" href="#设计" id="设计">设计</a></h3>
<pre><code class="language-shell">.
├── config
│   ├── conf # 主配置：环境、全局
│   └── jobs # sql 配置
├── output # 测试输出
│   ├── test-1 # 测试1输出
│   └── test-2 # 测试2输出
└── run.sh # 入口：加载配置/日志、归档测试结果、执行：获取jobs/执行mysqlslap、option（暂未实现）
</code></pre>
<p><strong>配置部分：</strong></p>
<img src="tech/bestpractices/assets/image-20220317111645274.png" alt="image-20220317111645274" style="zoom:80%;" />
<p><em><strong>conf 文件：</strong></em></p>
<p><em><strong><code>任何格式，按照需求去设计</code></strong></em></p>
<pre><code class="language-shell"># 一些全局参数
db_schema='ssb'
db_user='root'
db_port='9030'
...
</code></pre>
<p><em><strong>jobs/ :</strong></em></p>
<p><em><strong><code>任何格式，按照需求去设计，JSON、YML、TOML 都行</code></strong></em></p>
<pre><code class="language-shell"># test 1: build-in functions
test_name='build-in'
query_sql=&quot;select length(c_address) from ssb.customer;&quot;
pre_query=&quot;set global enable_vectorized_engine=true;set global batch_size=1024;&quot;
...
</code></pre>
<h3><a class="header" href="#实现" id="实现">实现</a></h3>
<p>逻辑描述：</p>
<p><code>启动</code>  =&gt; <code>加载配置/optioin传入 </code>  =&gt; <code>加载jobs</code>  =&gt; <code>LOOP：构建job &gt; 执行job &gt; 记录job日志&amp;结果</code>  =&gt; <code>归档&amp;展示测试结果</code></p>
<p><em><strong>待实现：从 option 传入配置</strong></em></p>
<h4><a class="header" href="#运行" id="运行">运行</a></h4>
<pre><code class="language-shell">[root@test-fe-1 test]# sh run.sh 
=====================================================================================================================================
test-fe-1 2022-03-16 21:29:17.249 执行测试：build-in 
test-fe-1 2022-03-16 21:29:17.256 执行预处理：set global enable_vectorized_engine=true;set global batch_size=1024;
test-fe-1 2022-03-16 21:29:17.264 执行测试 SQL：select length(c_address) from ssb.customer;
test-fe-1 2022-03-16 21:29:25.877 build-in 执行完成： build-in,mixed,1.698,1.298,1.872,10,1
=====================================================================================================================================
test-fe-1 2022-03-16 21:29:25.883 执行测试：n-udf-f 
test-fe-1 2022-03-16 21:29:25.890 执行预处理：set global enable_vectorized_engine=false;
test-fe-1 2022-03-16 21:29:25.895 执行测试 SQL：select ssb.get_string_length(c_address) from ssb.customer;
test-fe-1 2022-03-16 21:29:34.986 n-udf-f 执行完成： n-udf-f,mixed,1.798,1.740,1.879,10,1
=====================================================================================================================================
test-fe-1 2022-03-16 21:29:34.995 执行测试：rudf2-t-1024 
test-fe-1 2022-03-16 21:29:35.001 执行预处理：set global enable_vectorized_engine=true;set global batch_size=1024;
test-fe-1 2022-03-16 21:29:35.008 执行测试 SQL：select ssb.str_length(c_address) from ssb.customer;
test-fe-1 2022-03-16 21:29:44.929 rudf2-t-1024 执行完成： rudf2-t-1024,mixed,1.961,1.867,2.058,10,1
=====================================================================================================================================
test-fe-1 2022-03-16 21:29:44.936 执行测试：rudf3-t-2048 
test-fe-1 2022-03-16 21:29:44.942 执行预处理：set global enable_vectorized_engine=true;set global batch_size=2048;
test-fe-1 2022-03-16 21:29:44.948 执行测试 SQL：select ssb.str_length(c_address) from ssb.customer;
test-fe-1 2022-03-16 21:29:53.113 rudf3-t-2048 执行完成： rudf3-t-2048,mixed,1.612,1.494,1.782,10,1
=====================================================================================================================================
test-fe-1 2022-03-16 21:29:53.119 执行测试：rudf4-t-4096 
test-fe-1 2022-03-16 21:29:53.124 执行预处理：set global enable_vectorized_engine=true;set global batch_size=4096;
test-fe-1 2022-03-16 21:29:53.129 执行测试 SQL：select ssb.str_length(c_address) from ssb.customer;
test-fe-1 2022-03-16 21:30:00.478 rudf4-t-4096 执行完成： rudf4-t-4096,mixed,1.447,1.396,1.518,10,1
=====================================================================================================================================
test-fe-1 2022-03-16 21:30:00.485 执行测试：rudf2-5-8192 
test-fe-1 2022-03-16 21:30:00.492 执行预处理：set global enable_vectorized_engine=true;set global batch_size=8192;
test-fe-1 2022-03-16 21:30:00.497 执行测试 SQL：select ssb.str_length(c_address) from ssb.customer;
test-fe-1 2022-03-16 21:30:07.553 rudf2-5-8192 执行完成： rudf2-5-8192,mixed,1.388,1.352,1.488,10,1
=====================================================================================================================================
test-fe-1 2022-03-16 21:30:07.561 执行测试：rudf6-t-16384 
test-fe-1 2022-03-16 21:30:07.567 执行预处理：set global enable_vectorized_engine=true;set global batch_size=16384;
test-fe-1 2022-03-16 21:30:07.574 执行测试 SQL：select ssb.str_length(c_address) from ssb.customer;
test-fe-1 2022-03-16 21:30:11.685 rudf6-t-16384 执行完成： rudf6-t-16384
##########################################################################
全局参数：
client_num=10
queries_num=10
测试结果： test-20220316212917243/result.csv 
test_name      mode   avg    min    max    client_num  queries_per_client
build-in       mixed  1.698  1.298  1.872  10          1
n-udf-f        mixed  1.798  1.740  1.879  10          1
rudf2-5-8192   mixed  1.388  1.352  1.488  10          1
rudf2-t-1024   mixed  1.961  1.867  2.058  10          1
rudf3-t-2048   mixed  1.612  1.494  1.782  10          1
rudf4-t-4096   mixed  1.447  1.396  1.518  10          1
rudf6-t-16384
#########################################################################
</code></pre>
<h2><a class="header" href="#ref-6" id="ref-6">ref</a></h2>
<ul>
<li><a href="https://sourceforge.net/projects/benchmarksql/">测试工具：BenchMarkSQL 5.0</a> | <a href="https://support.huaweicloud.com/tstg-kunpengdbs/kunpengbenchmarksql_06_0002.html">使用方法</a></li>
<li><a href="https://tech.meituan.com/2017/07/14/sysbench-meituan.html">Sysbench 在美团点评中的应用</a></li>
</ul>
<h2><a class="header" href="#附录-2" id="附录-2">附录</a></h2>
<h3><a class="header" href="#实现的脚本" id="实现的脚本">实现的脚本</a></h3>
<pre><code class="language-shell">#!/bin/bash
#
# @CreationTime
#   2022/3/15 下午16:45:20
# @Function
#
# @Usage
# @author Siu

CURRENT_PATH=$(readlink -f &quot;$(dirname &quot;$0&quot;)&quot;)

##  region 全局参数：当有配置文件覆盖时这里的参数无效
db_ip=$(hostname -I | awk '{gsub(/^\s+|\s+$/, &quot;&quot;);print}')
# 总查询的次数 = min(client_queries_limit,client_num * run_times)
client_num=10
run_times=5
# 官方文档说明：Limit each client to approximately this number of queries，实际限制每个 client，而是限制总查询数
client_queries_limit=10
db_schema='ssb'
db_user='root'
db_port='9030'

# 配置文件
conf_file=&quot;${CURRENT_PATH}&quot;/config/conf
# jobs
jobs_path=&quot;${CURRENT_PATH}&quot;/config/jobs
cmd_input=&quot;&quot;
## endregion

## 记录日志
logFmt() {
	date_str=$(date &quot;+%Y-%m-%d %H:%M:%S.%3N&quot;)
	echo &quot;$(hostname -s)&quot; &quot;${date_str}&quot; &quot;$1&quot;
	# shellcheck disable=SC2086
	echo &quot;$(hostname -s)&quot; &quot;${date_str}&quot; $1 &gt;&gt;&quot;${archive_dir}&quot;/run.log
}

log() {
	echo &quot;$1&quot;
	# shellcheck disable=SC2086
	echo $1 &gt;&gt;&quot;${archive_dir}&quot;/run.log
}

runMss() {
	mysqlslap -u ${db_user} -P ${db_port} -h ${db_ip} \
	--concurrency=${client_num} --iterations=${run_times} --number-of-queries=${client_queries_limit} --create-schema=${db_schema} \
	--query=./&quot;${archive_dir}&quot;/&quot;$1&quot;.sql \
	--pre-query=./&quot;${archive_dir}&quot;/p_&quot;$1&quot;.sql \
	--csv=./&quot;${archive_dir}&quot;/&quot;$1&quot;.csv

	tmp=$(cat ./&quot;${archive_dir}&quot;/&quot;$1&quot;.csv)
	tmp1=$1${tmp}
	echo &quot;$tmp1&quot; &gt;./&quot;${archive_dir}&quot;/&quot;$1&quot;.csv

	res=$(cat ./&quot;${archive_dir}&quot;/&quot;$1&quot;.csv)

}

runJob() {
	test_name=$1
	query_sql=$2
	pre_query=$3
	echo &quot;${query_sql}&quot; &gt;./&quot;${archive_dir}&quot;/&quot;${test_name}&quot;.sql
	echo &quot;${pre_query}&quot; &gt;./&quot;${archive_dir}&quot;/p_&quot;${test_name}&quot;.sql

	log &quot;=====================================================================================================================================&quot;
	logFmt &quot;执行测试：${test_name} &quot;
	logFmt &quot;执行预处理：${pre_query}&quot;
	logFmt &quot;执行测试 SQL：${query_sql}&quot;
	runMss &quot;${test_name}&quot;
	logFmt &quot;$1 执行完成： ${res}&quot;
}

runJobs() {
	if [ ! -d &quot;${jobs_path}&quot; ]; then
		logFmt &quot;jobs 路径不存在：$jobs_path&quot;
		help
		exit 1
	else
		for file in &quot;${jobs_path}&quot;/*; do
			if test -f $file; then
				#log &quot;加载：$file&quot;
				# shellcheck disable=SC1090
				. &quot;$file&quot;
				test_name=$(basename &quot;$file&quot;)
				runJob &quot;${test_name}&quot; &quot;${query_sql}&quot; &quot;${pre_query}&quot;
			fi
			if test -d &quot;$file&quot;; then
				logFmt &quot;dir:$file&quot;
			fi
		done
	fi

}

archiveRes() {
	# 归档测试结果
	echo 'test_name,mode,avg,min,max,client_num,queries_per_client' &gt;&quot;${archive_dir}&quot;/0.csv
	cat &quot;${archive_dir}&quot;/*.csv &gt;&quot;${archive_dir}&quot;/result.csv
	rm -rf &quot;${archive_dir}&quot;/0.csv

	log &quot;##########################################################################&quot;
	log &quot;测试结果： ${archive_dir}/result.csv &quot;
	# shellcheck disable=SC2002
	resFmt=$(cat &quot;${archive_dir}&quot;/result.csv | column -t -s,)
	log &quot;${resFmt}&quot;
	log &quot;#########################################################################&quot;
}

main() {
  log &quot;@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ sql性能测试工具 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@&quot;
  logFmt &quot;Options 参数：${cmd_input}&quot;
	loadConf
	showArgs
	date_str=$(date &quot;+%Y%m%d%H%M%S%3N&quot;)
	archive_dir=./output/test-&quot;${date_str}&quot;
	# 创建归档目录
	mkdir -p &quot;${archive_dir}&quot;
	runJobs
	archiveRes
}

showInfo() {
	echo &quot;&quot;&quot;
  ================================================
  #                 sql 性能测试工具               #
  # 版本： 1.0.0                                 #
  # 作者： Siu                                   #
  # Support By： mysqlslap                      #
  ================================================

  &quot;&quot;&quot;

	help
}

loadConf() {
	# shellcheck source=src/
	# 加载配置全局文件
	if [ ! -f &quot;${conf_file}&quot; ]; then
		logFmt &quot;配置文件不存在将使用默认配置或命令行输入参数:${conf_file}&quot;
	else
		. &quot;${conf_file}&quot;
		# shellcheck disable=SC2027
		logFmt &quot;加载配置文件： ${conf_file}&quot;
	fi

}

showArgs() {
	log &quot;###############################################################################&quot;
	log &quot;测试参数：&quot;
	log &quot;db_ip=${db_ip}&quot;
	log &quot;db_port=${db_port}&quot;
	log &quot;db_schema=${db_schema}&quot;
	log &quot;db_user=${db_user}&quot;
	log &quot;client_num=${client_num}&quot;
	log &quot;queries_limit=${client_queries_limit}&quot;
	log &quot;###############################################################################&quot;

}

help() {
	echo &quot;&quot;&quot;
Usage: ./run.sh -f ./myconfig/conf.file
       ./run.sh -j ./jobs
       ./run.sh -h  192.168.1.1
       ./run.sh -p  9001
       ./run.sh -u  admin
       ./run.sh -P  P@ssw0rd

Options:
  -f      配置文件路径，默认：./config/conf
  -j      sql 任务路径，默认：./config/jobs
  -H      数据库IP，默认：本机 IP
  -p      数据库端口，默认：9030
  -s      数据库Schema，默认：ssb
  -u      数据库用户，默认：root
  -P      数据库密码，默认：空（当前未加入Option）
  -c      测试并发数，默认：10
  -q      总查询次数，默认：10
  -h      帮助信息
  -v      工具版本信息

  &quot;&quot;&quot;
}


#echo original parameters=[$@]

# https://www.jianshu.com/p/6393259f0a13
#-o或--options选项后面是可接受的短选项，如ab:c::，表示可接受的短选项为-a -b -c，
#其中-a选项不接参数，-b选项后必须接参数，-c选项的参数为可选的
#-l或--long选项后面是可接受的长选项，用逗号分开，冒号的意义同短选项。
#-n选项后接选项解析错误时提示的脚本名字
#ARGS=$(getopt -o ab:c:: --long along,blong:,clong:: -n &quot;$0&quot; -- &quot;$@&quot;)
ARGS=$(getopt -o vhf:j:H:p:u:c:q: -n &quot;$0&quot; -- &quot;$@&quot;)
if [ $? != 0 ]; then
	logFmt &quot;参数错误，退出...&quot;
	help
	exit 1
fi

#echo ARGS=[$ARGS]
#将规范化后的命令行参数分配至位置参数（$1,$2,...)
eval set -- &quot;${ARGS}&quot;
cmd_input=$(echo  formatted parameters=[$@])

while true; do
	case &quot;$1&quot; in
	-v)
		showInfo
		exit 0
		shift
		;;
	-h)
		help
		exit 0
		shift
		;;
	-f)
		conf_file=$2
		shift 2
		;;
	-j)
		jobs_path=$2
		shift 2
		;;
	-H)
		db_ip=$2
		shift 2
		;;
	-p)
		db_port=$2
		shift 2
		;;
	-s)
		db_schema=$2
		shift 2
		;;
	-u)
		db_user=$2
		shift 2
		;;
	-c)
		client_num=$2
		shift 2
		;;
	-q)
		#echo &quot;option q:$2&quot;
		client_queries_limit=$2
		shift 2
		;;
	--)
		main
		shift
		break
		;;
	*)
		help
		exit 1
		;;
	esac
done

</code></pre>
<h1><a class="header" href="#doris--remote-udf-的开发和测试" id="doris--remote-udf-的开发和测试">Doris  Remote UDF 的开发和测试</a></h1>
<blockquote>
<p>By <a href="tech/project/jrudf/">Siu</a> 2021/3/15</p>
</blockquote>
<h2><a class="header" href="#remote-udf-介绍" id="remote-udf-介绍">Remote UDF 介绍</a></h2>
<blockquote>
<p>以下参考官方的文档：</p>
<p>Remote UDF Service 支持通过 RPC 的方式访问用户提供的 UDF Service，以实现用户自定义函数的执行。相比于 Native 的 UDF 实现，Remote UDF Service 有如下优势和限制：</p>
<p>优势</p>
<ul>
<li>跨语言：可以用 Protobuf 支持的各类语言编写 UDF Service。</li>
<li>安全：UDF 执行失败或崩溃，仅会影响 UDF Service 自身，而不会导致 Doris 进程崩溃。</li>
<li>灵活：UDF Service 中可以调用任意其他服务或程序库类，以满足更多样的业务需求。</li>
</ul>
<p>使用限制</p>
<ul>
<li>性能：相比于 Native UDF，UDF Service 会带来额外的网络开销，因此性能会远低于 Native UDF。同时，UDF Service 自身的实现也会影响函数的执行效率，用户需要自行处理高并发、线程安全等问题。</li>
<li>单行模式和批处理模式：Doris 原先的的基于行存的查询执行框架会对每一行数据执行一次 UDF RPC 调用，因此执行效率非常差，而在新的向量化执行框架下，会对每一批数据（默认2048行）执行一次 UDF RPC 调用，因此性能有明显提升。实际测试中，基于向量化和批处理方式的 Remote UDF 性能和基于行存的 Native UDF 性能相当，可供参考</li>
</ul>
</blockquote>
<p><strong>所以， Doris Remote UDF 开发，其实就是开发一个 RPC 服务，以 RPC 访问的方式提供 UDF 服务。</strong></p>
<h2><a class="header" href="#remote-udf-开发" id="remote-udf-开发">Remote UDF 开发</a></h2>
<blockquote>
<p>主要是 RPC Server 部分的开发。</p>
</blockquote>
<h3><a class="header" href="#设计-1" id="设计-1">设计</a></h3>
<p><img src="tech/project/jrudf/assets/arch.svg" alt="" /></p>
<h3><a class="header" href="#开发coding" id="开发coding">开发（coding）</a></h3>
<h4><a class="header" href="#编译-proto" id="编译-proto">编译 proto</a></h4>
<p><em><strong>需要安装 protoc 环境</strong></em></p>
<p>从官方 proto file进行编译，当前已经编译放在 <code>libs/doris-rudf-grpclib.jar</code></p>
<h4><a class="header" href="#代码结构" id="代码结构">代码结构</a></h4>
<pre><code class="language-shell">.
├── libs
│   └── doris-rudf-grpclib.jar # proto 编译的包，作为 local lib
├── proto # 原始 proto 文件
│   ├── function_service.proto
│   └── types.proto
├── src
│   └── main
│       ├── java
│       │   ├── com
│       │   │   └── siu
│       │   │       └── udf
│       │   │           └── SubFunction.java # 实现 IFunction，会以 SPI 的方式注册到 Functions 
│       │   └── org
│       │       └── apache
│       │           └── doris
│       │               └── udf
│       │                   ├── Main.java # 入口
│       │                   ├── func
│       │                   │   ├── Functions.java # 单例，以SPI 方式加载 UDF
│       │                   │   └── IFunction.java # 函数接口定义，需要实现 call(),check(),getName()
│       │                   └── server
│       │                       ├── FunctionServiceImpl.java # Doris Remote UDF 定义的接口，这里需要实现 checkFn(), callFn(),handShake()
│       │                       └── RpcServer.java
│       └── resources
│           └── META-INF
│               └── services
│                   └── org.apache.doris.udf.func.IFunction # SPI 定义文件
└── target # target code
</code></pre>
<h4><a class="header" href="#编译和运行" id="编译和运行">编译和运行</a></h4>
<pre><code class="language-shell"># 编译
mvn package
</code></pre>
<pre><code class="language-shell"># 运行
java -jar jrudf-jar-with-dependencies.jar 9000
</code></pre>
<p><code>9000</code> 是默认端口，可以不传</p>
<h3><a class="header" href="#调试debug" id="调试debug">调试（debug）</a></h3>
<blockquote>
<p>推荐远程调试，在 Remote UDF 场景中远程调试是最有效的，因为整体上还要依赖一个 Doris 的调试环境，所以远程调试的方式是一个全流程的验证。如果用支持grpc proto file 的工具调试只有 rpc server 部分的调试，不能完整的测试功能。</p>
</blockquote>
<h4><a class="header" href="#proto-file-调试" id="proto-file-调试">proto file 调试</a></h4>
<ul>
<li>Postman ：最新版本支持 GRPC，可以通过界面去调试比较友好</li>
<li>BloomRPC ：很适合 GRPC 的界面调试工具</li>
<li>Evans ：一个 RPC 命令行调试工具</li>
</ul>
<h4><a class="header" href="#swagger-调试" id="swagger-调试">Swagger 调试</a></h4>
<ul>
<li>
<p>使用 <a href="https://github.com/grpc-swagger/grpc-swagger">grpc-swagger</a> 这个项目:</p>
<pre><code class="language-shell">java -jar grpc-swagger-web/target/grpc-swagger.jar --server.port=8888
</code></pre>
</li>
<li>
<p>在 RPC Server 中开启反射模式：</p>
<pre><code class="language-java">            server = ServerBuilder.forPort(port)
                    .addService(... some server)
                    .addService(ProtoReflectionService.newInstance()) // 反射模式，可以把这块代码用 debug 控制 
                    .build()
                    .start();
</code></pre>
</li>
<li>
<p>打开 Swagger</p>
<p><img src="tech/project/jrudf/./assets/grpc-swagger.png" alt="" /></p>
</li>
</ul>
<h4><a class="header" href="#idea-远程调试" id="idea-远程调试">IDEA 远程调试</a></h4>
<p>远程服务器上启动服务</p>
<pre><code class="language-shell">java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=[ip]:5005 -jar jrudf-jar-with-dependencies.jar
# 后台运行
nohup java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=[ip]:5005 -jar jrudf-jar-with-dependencies.jar &gt;jrudf.log 2&gt;&amp;1 &amp;
</code></pre>
<p>本地 IDEA 添加 Remote 配置:
<code>Edit Configurtions-&gt; Add New Configrution-&gt;Remote JVM Debug</code></p>
<img src="tech/project/jrudf/assets/idea-remote-debug.png" alt="idea-remote-debug" style="zoom:50%;" />
<h2><a class="header" href="#remote-udf-测试" id="remote-udf-测试">Remote UDF 测试</a></h2>
<blockquote>
<p>由于当前版本不支持 remote UDF ，所以采用主干分支的编译版本，编译方式参考附录中的文档《编译 Doris》。</p>
</blockquote>
<h3><a class="header" href="#功能测试" id="功能测试">功能测试</a></h3>
<h4><a class="header" href="#在-doris-上创建-udf" id="在-doris-上创建-udf">在 Doris 上创建 UDF</a></h4>
<p>目前暂不支持 UDAF 和 UDTF</p>
<pre><code class="language-sql">CREATE FUNCTION
name ([,...])
[RETURNS] rettype
PROPERTIES ([&quot;key&quot;=&quot;value&quot;][,...])
</code></pre>
<p>说明：</p>
<pre><code class="language-txt">PROPERTIES中symbol表示的是 rpc 调用传递的方法名，这个参数是必须设定的。
PROPERTIES中object_file表示的 rpc 服务地址，目前支持单个地址和 brpc 兼容格式的集群地址，集群连接方式 参考 格式说明 (opens new window)。
PROPERTIES中type表示的 UDF 调用类型，默认为 Native，使用 Rpc UDF时传 RPC。
name: 一个function是要归属于某个DB的，name的形式为dbName.funcName。当dbName没有明确指定的时候，就是使用当前session所在的db作为dbName。

</code></pre>
<p><em><strong>注：特别说明，PROPERTIES.symbol 和 name 强制一致，发现在 set enable_vectorized_engine=true 调用传的函数名是 name，false 时传 symbol</strong></em></p>
<p>示例：</p>
<pre><code class="language-sql">CREATE FUNCTION rpc_add(INT, INT) RETURNS INT PROPERTIES (
&quot;SYMBOL&quot;=&quot;add_int&quot;,
&quot;OBJECT_FILE&quot;=&quot;127.0.0.1:9000&quot;,
&quot;TYPE&quot;=&quot;RPC&quot;
);
</code></pre>
<h4><a class="header" href="#使用-udf" id="使用-udf">使用 UDF</a></h4>
<p>用户使用 UDF 必须拥有对应数据库的 SELECT 权限。</p>
<p>UDF 的使用与普通的函数方式一致，唯一的区别在于，内置函数的作用域是全局的，而 UDF 的作用域是 DB内部。当链接 session 位于数据内部时，直接使用 UDF 名字会在当前DB内部查找对应的 UDF。否则用户需要显示的指定 UDF 的数据库名字，例如 dbName.funcName。</p>
<h4><a class="header" href="#删除-udf" id="删除-udf">删除 UDF</a></h4>
<p>当你不再需要 UDF 函数时，你可以通过下述命令来删除一个 UDF 函数, 可以参考 DROP FUNCTION</p>
<p><em><strong>注：测试结论一并在性能测试部分说明</strong></em></p>
<h3><a class="header" href="#性能测试" id="性能测试">性能测试</a></h3>
<h4><a class="header" href="#测试模型" id="测试模型">测试模型</a></h4>
<blockquote>
<h4><a class="header" href="#说明" id="说明">说明</a></h4>
<p>Native UDF 在性能上有天然的优势，所以比较性能时，需要开启 Doris 的向量化引擎才有比较的意义，这里只是简单的设计几个对照组，每组执行10次查询，分别为：</p>
<ul>
<li>Build-in Function（<code>lenght()</code>）</li>
<li>Native UDF</li>
<li>Remote UDF 1 （enable_vectorized_engine = false） <em><strong>这一组测试无法完成</strong></em></li>
<li>Remote UDF 2（enable_vectorized_engine = true，batch_size = 1024）</li>
<li>Remote UDF 3（enable_vectorized_engine = true，batch_size = 2048）</li>
<li>Remote UDF 4（enable_vectorized_engine = true，batch_size = 4096）</li>
<li>Remote UDF 5（enable_vectorized_engine = true，batch_size = 8192）</li>
</ul>
<p><em><strong>函数逻辑：UDF 的实现逻辑 str.length()</strong></em>，内置函数选取 <code>length()</code> 进行比较</p>
<p>测试工具：mysqlslqp</p>
<p>测试数据：使用 Doris SSB 中的 Customer 表，150 万</p>
<p>测试环境：3 be 32G/8C，RPC Server JVM 默认</p>
<p>Doris 版本：
​	branch master
​	latest commit <a href="https://github.com/apache/incubator-doris/commit/f4663ad2eb3fc8ce929304ccdea09d87bb86ec8a"><code>f4663ad</code></a>
​	Compiled from the official docker image</p>
</blockquote>
<h4><a class="header" href="#测试结果" id="测试结果">测试结果</a></h4>
<p>单节点的 rpc server 下得出如下测试数据：</p>
<pre><code class="language-shell">##########################################################################
全局参数：
client_num=10
queries_num=10
测试结果： 
test_name        mode   avg    min    max    client_num  queries_per_client
build-in         mixed  1.784  1.669  1.856  10          1
n-udf-f          mixed  1.865  1.791  1.957  10          1
r-udf-2-t-1024   mixed  3.609  3.388  3.787  10          1
r-udf-3-t-2048   mixed  3.032  2.748  3.775  10          1
r-udf-4-t-4096   mixed  2.506  2.347  2.942  10          1
r-udf-5-t-8192   mixed  2.178  2.059  2.374  10          1
r-udf-6-t-16384  mixed  1.971  1.848  2.271  10          1
#########################################################################
</code></pre>
<p>在 3 个节点的 rpc server 下得出如下测试数据：</p>
<pre><code class="language-shell">##########################################################################
全局参数：
client_num=10
queries_num=10
测试结果： 
test_name        mode   avg    min    max    client_num  queries_per_client
build-in         mixed  1.683  1.252  1.923  10          1
n-udf-f          mixed  1.797  1.694  1.912  10          1
r-udf-2-t-1024   mixed  2.384  1.882  3.388  10          1
r-udf-3-t-2048   mixed  1.688  1.479  1.886  10          1
r-udf-4-t-4096   mixed  1.455  1.374  1.615  10          1
r-udf-5-t-8192   mixed  1.358  1.272  1.436  10          1
r-udf-6-t-16384  mixed  1.329  1.265  1.474  10          1
#########################################################################
</code></pre>
<h4><a class="header" href="#测试结论" id="测试结论">测试结论</a></h4>
<ol>
<li>Native UDF 与内置函数的<strong>性能基本一致</strong></li>
<li>在非向量化引擎的环境下（enable_vectorized_engine = false），Remote UDF 性能<strong>极差</strong></li>
<li>在向量化引擎的环境下（enable_vectorized_engine = true），Native UDF <strong>无法使用</strong></li>
<li><strong>推荐</strong>使用配置 enable_vectorized_engine = true，batch_size = 4096 （实际做了几十次验证，这个配置是最稳定的）</li>
<li>在 <strong>4</strong> 推荐配置下，单节点 rpc server 时，Remote UDF 与 Native UDF <strong>性能差距大概有 35%</strong></li>
<li>在 <strong>4</strong> 推荐配置下，3 节点 rpc server 时，Remote UDF 与 Native UDF <strong>性能领先大概有 36%</strong>（此时 Doris 没有明显瓶颈，目前没有准确的数据去描述节点数量对于Remote UDF 性能的线性影响有多大，不排除在更高规格下 Native UDF 可能表现更佳）
<ul>
<li>这个结论符合官方的描述<code>基于向量化和批处理方式的 Remote UDF 性能和基于行存的 Native UDF 性能相当</code></li>
</ul>
</li>
<li>不排除处理复杂的自定义函数时 Remote UDF 性能表现会下降，特别是有大量数据要通过网络传输时，推荐配置也会随场景不同有所不同</li>
</ol>
<h2><a class="header" href="#总结-1" id="总结-1">总结</a></h2>
<p><strong>从整体方案上做一下总结和对比：</strong></p>
<table><thead><tr><th></th><th>Native UDF</th><th>Remote UDF</th></tr></thead><tbody>
<tr><td>用户</td><td>使用方式上与内置函数一致的体验</td><td>使用方式上与内置函数一致的体验</td></tr>
<tr><td>社区</td><td>当前版本支持</td><td><strong>预计下一个版本支持；这个对稳定性、安全也有较大的影响，当前功能验证是基于主干版本编译的</strong></td></tr>
<tr><td>功能</td><td>满足</td><td>满足（<em><strong>当前版本不支持</strong></em>）</td></tr>
<tr><td>稳定性</td><td>需要代码来保证</td><td>需要代码来保证（<em><strong>当前版本不支持，编译版本可能会引入不稳定因素</strong></em>）</td></tr>
<tr><td>性能</td><td>多数情况下会好于 Remote UDF</td><td>在向量化和批处理模式下性能与 Native 相当；具备一定的伸缩能力</td></tr>
<tr><td>安全</td><td>不可靠的程序，会直接影响 Doris</td><td>相对更安全；特别是使用 VM 的语言</td></tr>
<tr><td>开发和维护</td><td>相对成本<strong>高</strong>：<br>1、C 系技术栈能力当前团队储备不足，长期来看无投入计划<br>2、C 系语言的程序编写、debug、优化、review 等心智成本较高<br>3、在处理复杂的自定义逻辑时，<strong>2</strong> 的挑战会放大（本身编码的经验；类库的缺乏， Java ，Python 对数据处理相对友好）</td><td>相对成本<strong>低</strong>：<br/>跨语言，类库多；一次性的投入，定义好开发范式，可以长期收益</td></tr>
</tbody></table>
<p>在不考虑团队技能情况下，选择 Native UDF 的方案是比较合适的，功能上满足，性能相对更稳定；Remote UDF 现阶段社区的版本不支持，是一个比较大的问题，编译是一个，主要还是非 release 版本的<strong>稳定性</strong>和<strong>安全</strong>是一个比较大的挑战。</p>
<p>所以所有方案到最后都不是讨论好不好的问题，而是合不合适的问题。</p>
<p>综合考虑功能、稳定性是我们迫切的需求，性能上都有基本同等级别的实现方式：现阶段使用 Native UDF 去支持需求；长期来看，待社区版本稳定支持 Remote UDF 时，定义好开发范式，用当前团队熟悉的技术栈来开发 UDF RPC Server 来迁移当前的需求。</p>
<h1><a class="header" href="#附录-3" id="附录-3">附录</a></h1>
<h2><a class="header" href="#编译-doris" id="编译-doris">编译 Doris</a></h2>
<p><em><strong>由于当前版本（0.15）不支持 Remote UDF，所以编译 Doris 最新版本进行功能验证</strong></em></p>
<h3><a class="header" href="#安装-docker-环境-略" id="安装-docker-环境-略">安装 Docker 环境 （略）</a></h3>
<p><em><strong>推荐使用 Docker 集成的编译环境去进行 Doris 编译</strong></em></p>
<h3><a class="header" href="#下载编译集成环境镜像" id="下载编译集成环境镜像">下载编译集成环境镜像</a></h3>
<pre><code class="language-shell">docker pull apache/incubator-doris:build-env-ldb-toolchain-latest
</code></pre>
<h3><a class="header" href="#下载-doris-源码" id="下载-doris-源码">下载 Doris 源码</a></h3>
<pre><code class="language-shell">mkdir -p /opt/doris &amp;&amp; cd /opt/doris
git clone https://github.com/apache/incubator-doris.git
</code></pre>
<h3><a class="header" href="#运行编译集成环境" id="运行编译集成环境">运行编译集成环境</a></h3>
<pre><code class="language-shell">docker run -it -v /root/.m2:/root/.m2 -v /opt/doris/incubator-doris/:/root/incubator-doris/ apache/incubator-doris:build-env-ldb-toolchain-latest
</code></pre>
<h3><a class="header" href="#编译" id="编译">编译</a></h3>
<pre><code class="language-shell">cd /root/incubator-doris/
sh build.sh --clean --be --fe --ui
</code></pre>
<h3><a class="header" href="#打包构建" id="打包构建">打包构建</a></h3>
<pre><code class="language-shell">tar zcvf apache-doris-latest-454b45b-incubating.tar.gz ./output
</code></pre>
<p><em><strong>454b45b 是源码的 commit hash id</strong></em></p>
<h2><a class="header" href="#问题" id="问题">问题</a></h2>
<ul>
<li>proto 编译要修改官方的 pom文件中 <code>protoc</code> 环境的位置</li>
</ul>
<pre><code class="language-xml">&lt;protocCommand&gt;${doris.thirdparty}/installed/bin/protoc&lt;/protocComm&gt; &lt;!-- 修改成 protoc 的安装位置 --&gt;
</code></pre>
<ul>
<li>
<p>Doris 源码编译时 gcc  找不到，版本不对</p>
<p>需要 which 一下看看 gcc 的位置，在 <code>env.sh</code> 中设置一下 <code>${DORIS_GCC_HOME}</code></p>
</li>
</ul>
<h2><a class="header" href="#ref-7" id="ref-7">ref</a></h2>
<ul>
<li><a href="https://doris.apache.org/zh-CN/extending-doris/udf/remote-user-defined-function.html">Doris Remote UDF</a></li>
<li><a href="https://doris.apache.org/zh-CN/installing/compilation.html#%E4%BD%BF%E7%94%A8-docker-%E5%BC%80%E5%8F%91%E9%95%9C%E5%83%8F%E7%BC%96%E8%AF%91-%E6%8E%A8%E8%8D%90">Doris 编译</a></li>
<li><a href="https://dev.mysql.com/doc/refman/8.0/en/mysqlslap.html">mysqlslap</a></li>
</ul>
<p><img src="tech/bestpractices/./%E7%A6%85%E9%81%93%E5%B7%A5%E4%BD%9C%E6%B5%81.drawio.svg" alt="禅道工作流.drawio" /><img src="tech/bestpractices/" alt="" />
<img src="tech/bestpractices/./assets/role_of_prd_in_project.drawio.svg" alt="" /></p>
<h1><a class="header" href="#单元测试规范" id="单元测试规范">单元测试规范</a></h1>
<h3><a class="header" href="#一可衡量单测的编写应该是可以用具体的指标衡量的" id="一可衡量单测的编写应该是可以用具体的指标衡量的">一.可衡量：单测的编写应该是可以用具体的指标衡量的</a></h3>
<blockquote>
<p>1、单测通过率要求100%，行覆盖率要求50%。</p>
</blockquote>
<p>解释：通过率100%没啥好多说的，如果单测跑不通过，那不是单测有问题就是代码逻辑有问题。覆盖率的话可以根据具体的工程进行微调，建议不应小于40%，越底层的代码覆盖率应该越高，越新的代码覆盖率也应该越高。</p>
<blockquote>
<p>2、老代码有逻辑变更时，单测也应该做相应的变更。</p>
</blockquote>
<p>解释：这点的目的也是为了保证单测通过率100%。同时，这部分功能应该也属于改次功能的测试回归范围内。</p>
<blockquote>
<p>3、新业务提测前，必须保证老单测的通过率也保持100%。</p>
</blockquote>
<p>解释：这点的目的是为了防止回溯问题的出现。</p>
<h3><a class="header" href="#二独立性单测应该是独立且相互隔离的" id="二独立性单测应该是独立且相互隔离的">二.独立性：单测应该是独立且相互隔离的</a></h3>
<blockquote>
<p>4、一个单测只测试一个方法。</p>
</blockquote>
<p>解释：保证了单测的独立性。当单测出错的时候也能够明确知道是哪个方法出了问题。但这并不是说一个方法只对应一个单测，因为为了覆盖方法内的不同分支，我们可以为一个方法创建多个单测。</p>
<blockquote>
<p>5、单测不应该依赖于别的单测。</p>
</blockquote>
<p>解释：保证了单测的独立性。每个单测应该都能独立运行。不应该有A单测跑完才能跑B单测的情况。</p>
<blockquote>
<p>6、单测如果涉及到数据变更，必须进行回滚。</p>
</blockquote>
<p>解释：保证了单测的隔离性。如果单测运行后在数据库中产生了数据，那这些脏数据可能干扰测试同学的测试工作，且也可能影响别的单测的运行结果。</p>
<blockquote>
<p>7、单测应该测试目标方法本身的逻辑，对于被测试的方法内部调用的非私有方法应进行mock，推荐使用Mockito进行mock。</p>
</blockquote>
<p>解释：目标方法存在内部调用情况，进行mock可以屏蔽其他方法对目标方法的影响。这样保证了单测的独立性，一个单测只保证它测试的目标方法的逻辑正确性，而不应该受其内部调用方法的逻辑的影响，这部分应该是这些内部调用的方法对应的单测的责任。但是真实情况中，这一点是最难被严格执行，因为这样做就意味着需要对所有的方法都设计单测，比如a调用b调用c的情况，需要至少设计三个单测，而不能只对a设计单测来覆盖整个调用链。不过，这不正是单测的含义吗？对最小的逻辑单元——方法进行测试，如果对于一个调用链进行测试，更像是集成测试的范畴了。而且如果不这么做，我们就会违反上面的第4条“一个单测只测试一个方法”。只有一种情况例外，方法内部调用的是私有方法，这样的话是可以通过调用方的单测一并测试的，见下面的第13条“私有方法通过调用类的单测进行测试”。我们可以试想一种情况，当一个项目由很多人协同开发时，我怎么才能放心使用另一个人开发的方法？至少得提供单测吧，如果这个方法的测试是在其调用方的单测中的，那就没有直接对应的单测了，这样也就无法保证该方法是否被妥当测试过了。</p>
<h3><a class="header" href="#三规范性单测的编写需要符合一定规范" id="三规范性单测的编写需要符合一定规范">三.规范性：单测的编写需要符合一定规范</a></h3>
<blockquote>
<p>8、对实现类进行测试而非接口。</p>
</blockquote>
<p>解释：面向接口编程，面向实现测试。</p>
<blockquote>
<p>9、单测应该是无状态的。</p>
</blockquote>
<p>解释：即单测应该可以重复执行，且无论跑几次都应该保证通过率。比如有些方法会对当前时间进行判断，对于这类方法的单测也需根据当前时间的不同而进行不同的测试。</p>
<blockquote>
<p>10、覆盖范围应包括所有提供了逻辑的类：service层、manager层、自定义mapper等，甚至还有部分提供业务逻辑的controller层代码。</p>
</blockquote>
<p>解释：只要是提供了逻辑的就应该测试，不过个人并不建议在controller层提供业务逻辑，具体原因参考<a href="https://www.jianshu.com/p/654f4589eb8e">《设计之道－controller层的设计》</a>。</p>
<blockquote>
<p>11、覆盖范围不应包括自动生成的类：如MyBatis Generator生成的Mapper类、Example类，不应包括各种POJO（DO，BO，DTO，VO...），也不应包括无业务逻辑的controller类。</p>
</blockquote>
<p>解释：自动生成的类有啥好测的？POJO的getter/setter有啥好测的？没有提供业务逻辑的controller类有啥好测的？这些被排除的类应该在覆盖率统计中被剔除。</p>
<blockquote>
<p>12、私有方法通过调用类的单测进行测试。</p>
</blockquote>
<p>解释：因为私有方法在测试类内没法直接调用，除非使用反射。</p>
<blockquote>
<p>13、单测要覆盖到正常分支和异常分支，使用专门的异常测试属性junit（expected）/testng（expectedExceptions）。禁止使用try-catch。</p>
</blockquote>
<p>解释：很多同学的单测覆盖率不达标，就是因为只覆盖了正常的分支而遗漏的异常的分支。异常的测试和正常的一样重要，也就是该报错的时候就应该报错。有些同学为了达到单测的覆盖率和通过率的指标，在单测中使用try-catch，这也是不允许的，应该使用专门的异常测试注解。</p>
<blockquote>
<p>14、如果被测试的方法的逻辑体现在方法返回或成员变量中，则使用Assert断言验证该返回或成员变量。</p>
</blockquote>
<p>解释：如果一个方法的内部组装了一个返回值，或变更了一个成员变量，那么应该使用Assert来验证该返回值或成员变量是否符合预期。</p>
<p>比如下面的三个方法，前两个的逻辑都是体现在返回值上，后一个的逻辑体现在成员变量中。</p>
<pre><code class="language-dart">    /**
     * 逻辑体现在返回值
     *
     * @return
     */
    public String displayName() {
        String name = &quot;HangzhouZoo&quot;;
        return &quot;Zhejiang &quot; + name;
    }

    /**
     * 逻辑体现在返回值
     *
     * @return
     */
    public String luxuryShow() {
        String show = dog.run();
        return &quot;luxury!! &quot; + show;
    }

    /**
     * 逻辑体现在成员变量
     */
    public void close() {
        this.open = false;
    }
</code></pre>
<p>那么我们就可以使用Assert断言来测试这些逻辑：</p>
<pre><code class="language-java">    //逻辑在方法返回体现
    @Test
    public void displayName() {
        Assert.assertEquals(&quot;Zhejiang HangzhouZoo&quot;, hangzhouZoo.displayName());
    }

    //逻辑在方法返回体现
    @Test
    public void luxuryShow() {
        when(dog.run()).thenReturn(&quot;dog show&quot;);
        Assert.assertEquals(&quot;luxury!! dog show&quot;, hangzhouZoo.luxuryShow());
    }

    //逻辑在成员变量中体现
    @Test
    public void close() {
        Assert.assertTrue(hangzhouZoo.isOpen());
        hangzhouZoo.close();
        Assert.assertFalse(hangzhouZoo.isOpen());
    }
</code></pre>
<blockquote>
<p>16、如果被测试的方法的逻辑体现在内部的方法调用行为本身，则使用Mockito的verify验证内部方法调用的情况。</p>
</blockquote>
<p>解释：有些方法的内部根据不同的条件会调用不同的方法，则应该验证该方法的调用是否符合预期。Mockito的verify可以验证被mock的方法是否调用了，甚至可以验证方法调用的次数。</p>
<p>比如下面这个方法有三分条件分支，分支一抛出异常，分支二调用内部方法，分支三组装返回值。</p>
<pre><code class="language-java">    /**
     * 逻辑体现在异常、方法调用行为和返回值
     *
     */
    @Override
    public String show(Animal animal) throws ZooException {
        if (animal instanceof Tiger) {
            throw new ZooException(&quot;tiger is not allowed&quot;);
        } else if (animal instanceof Dog) {
            return animal.run();
        } else {
            return &quot;only dogs here&quot;;
        }
    }
</code></pre>
<p>其中分支二的逻辑就体现在方法调用的行为上，我们可以通过verify来验证方法是否如预期一样调用，也可使用times验证方法调用的次数。</p>
<pre><code class="language-dart">    //被测试的方法的逻辑体现在内部方法的调用行为本身
    @Test
    public void show() throws Exception {
        when(dog.run()).thenReturn(&quot;dog run&quot;);
        hangzhouZoo.show(dog);
        //验证方法被调用过了
        verify(dog).run();
        //也可以通过times参数来验证方法具体被调用的次数
        verify(dog, times(1)).run();
        //验证另一个分支，逻辑体现在返回值
        Assert.assertEquals(&quot;only dogs here&quot;, hangzhouZoo.show(new Cat()));
    }
</code></pre>
<p>当然，还记得第13条“异常分支也需要测试么”，我们还需要写一个单测来覆盖异常分支：</p>
<pre><code class="language-dart">    //测试异常分支
    @Test(expected = ZooException.class)
    public void showForEx() throws Exception {
        hangzhouZoo.show(new Tiger());
    }
</code></pre>
<blockquote>
<ol>
<li>如果被测试的方法的逻辑体现在内部方法调用的参数中，即方法的逻辑用于构建内部调用方法的参数，则使用Mockito的verify验证内部方法调用的参数。</li>
</ol>
</blockquote>
<p>解释：有些方法的内部会组装一个对象，然后将这个对象作为参数传入另一个内部方法。使用Mockito的verify可以验证被mock的方法被调用的参数。如果是简单类型，可以直接验证，如果是复杂类，则需要扩展<code>ArgumentMatcher</code>类来做验证。</p>
<p>下面这个方法的逻辑体现在内部调用方法的参数构造上：</p>
<pre><code class="language-cpp">    /**
     * 逻辑体现在参数构造-基本类
     *
     * @param times
     */
    public void bark(int times) {
        int actualTimes = times * 10;
        dog.bark(actualTimes);
    }
</code></pre>
<p>由于参数类型是基本类，所以我们可以直接用verify来验证：</p>
<pre><code class="language-csharp">    //逻辑在参数体现-简单类型
    @Test
    public void bark() {
        doNothing().when(dog).bark(anyInt());
        hangzhouZoo.bark(3);
        verify(dog).bark(30);
        //与上面等价
        verify(dog).bark(eq(30));
    }
</code></pre>
<p>不过如果像下面这样的参数是复杂类的，就需要扩展一下：</p>
<pre><code class="language-dart">     /**
     * 逻辑体现在参数构造-复杂类
     *
     * @param
     * @return
     */
    public String feedVegetable() {
        Food tomato = Food.builder().name(&quot;tomato&quot;).build();
        return dog.eat(tomato);
    }
</code></pre>
<p>自定义参数匹配器：</p>
<pre><code class="language-kotlin">/**
 * @Author: Sawyer
 * @Description: 自定义参数匹配规则
 * @Date: Created in 2:02 PM 2019/10/15
 */

public class ObjectMatcher&lt;T&gt; extends ArgumentMatcher&lt;T&gt; {

    private Object expected;
    private Function&lt;T, Object&gt; getProperty;

    public ObjectMatcher(Object expected, Function&lt;T, Object&gt; getProperty) {
        this.expected = expected;
        this.getProperty = getProperty;
    }

    @SuppressWarnings(&quot;unchecked&quot;)
    @Override
    public boolean matches(Object actual) {
        return getProperty.apply((T) actual).equals(expected);
    }
}
</code></pre>
<p>测试的时候使用<code>argThat</code>校验方法参数：</p>
<pre><code class="language-java">    //逻辑在参数体现-复杂类
    @Test
    public void feedVegetable() {
        when(dog.eat(any())).thenReturn(&quot;dog eat&quot;);
        hangzhouZoo.feedVegetable();
        //验证参数
        verify(dog).eat(argThat(new ObjectMatcher&lt;&gt;(&quot;tomato&quot;, Food::getName)));
    }
</code></pre>
<blockquote>
<p>17、单测应在相应的目标方法开发完后立即编写，如能在开发前就开始编写则更好（TDD）。</p>
</blockquote>
<p>解释：这点可能会违背很多开发同学的认知，怎么可能先写单测再写代码呢？实际上，如果稍微了解下测试驱动开发（Test-Driven Development），就会发现这并非异想天开，反倒是顺理成章的事。我认为有两种场景下单测的习惯是很容易能够推动的，第一种是团队里没有测试人员，代码质量完全由开放人员把控；而第二种就是软件开发流程使用的是TDD的方式，这样天然的就保证了单测必须存在。</p>
<p><a href="https://www.jianshu.com/p/37ffeef5ee5b?spm=a2c6h.12873639.0.0.6dea79129hj1We">原文：设计之道－单元测试规范 - 简书 (jianshu.com)</a></p>
<h1><a class="header" href="#flyway-使用规范" id="flyway-使用规范">Flyway 使用规范</a></h1>
<blockquote>
<p>By <a href="tech/bestpractices/">Siu</a> 2021/02/07</p>
<p>​		Flyway是一款数据库迁移（migration）工具。在部署应用的时候，自动执行数据库脚本，实现<strong>数据库自动化</strong>。Flyway 支持 SQL 和 Java 两种类型的脚本，可以将脚本打包到应用程序中，在应用程序启动时，由 Flyway 来管理这些脚本的执行，这些脚本被 Flyway 称之为 migration。</p>
<p>就目前而言，我们部署应用的流程大概是这样的：</p>
<ul>
<li>开发人员将应用程序打包、按版本整理数据库升级脚本；</li>
<li>DBA 根据数据库升级脚本检查、备份、执行，以完成数据库升级；</li>
<li>运维人员拿到应用部署包，备份、替换，以完成应用程序升级；</li>
</ul>
<p>引入Flyway之后的应用部署流程：</p>
<ul>
<li>开发人员将应用程序打包（包括数据库脚本）；</li>
<li>应部署人员拿到应用部署包，备份、替换，即完成应用程序升；</li>
</ul>
</blockquote>
<h2><a class="header" href="#1-sql-脚本命名规范" id="1-sql-脚本命名规范">1 SQL 脚本命名规范</a></h2>
<p><img src="tech/bestpractices/./assets/Flyway_SQL%E6%96%87%E4%BB%B6%E5%91%BD%E5%90%8D%E8%A7%84%E5%88%99.svg" alt="" /></p>
<h3><a class="header" href="#11-格式" id="11-格式"><strong>1.1 格式</strong></a></h3>
<p><code>V{version}.{date}.{num}__{type}__{description}.sql</code></p>
<p><code>U{version}.{date}.{num}__{type}__{description}.sql</code></p>
<p><code>R__{description}.sql</code></p>
<blockquote>
<p><strong>例：</strong></p>
<ul>
<li><code>V5.1.0.210205.1__DDL__alter_table_user.sql</code></li>
<li><code>U5.1.0.210205.1__DDL__undo_alter_table_user.sql</code></li>
<li><code>R__alter_table_user.sql</code></li>
</ul>
</blockquote>
<h3><a class="header" href="#12-格式说明" id="12-格式说明">1.2 格式说明</a></h3>
<ul>
<li>
<p>前缀：</p>
<ul>
<li><strong>V</strong> 版本控制 ，每个文件只会被执行一次；</li>
<li><strong>U</strong> 撤销，与 V 前缀<strong>对应</strong>的回退脚本，版本号与V一致；</li>
<li><strong>R</strong> 可重复执行，当flyway检测有变化时会执行，执行顺序在所有V之后；</li>
</ul>
</li>
<li>
<p>Flyway 版本号</p>
<blockquote>
<p>​	版本号分为五段，前三段遵循<a href="tech/bestpractices/">《语义化版本控制规范》</a>（主版本号、子版本号、修订版本号），第四段是为<strong>提交日期</strong>，第五段是为了开发测试发布过程中有脚本修改时需要新建脚本。</p>
</blockquote>
<ul>
<li><code>version</code> : <a href="tech/bestpractices/">《语义化版本控制规范》</a>中的主版本号、子版本号、修订版本号</li>
<li><code>date</code>: 提交日期 210205</li>
<li><code>num</code>: 必须为非负整型数字，当版本和日期相同时依次递增</li>
<li><code>version、date、num</code>之间，分割符为  <code>.</code></li>
<li><code>前缀+Flyway版本号</code>必须<strong>全局唯一</strong></li>
</ul>
</li>
<li>
<p>SQL 类型（type）：</p>
<ul>
<li>DML：数据更新(插入、更新、删除)</li>
<li>DDL ：结构更新; </li>
<li>DCL： 权限控制；</li>
</ul>
</li>
<li>
<p>文件描述（description）: 使用小写字母，分割符为 <strong>下划线</strong> <code>_</code></p>
</li>
<li>
<p>连接符：<code>版本号、SQL类型、文件描述</code>之间连接符为<strong>双下划线</strong> <code>__</code></p>
</li>
<li>
<p>固定后缀 ：<code>.sql</code></p>
</li>
</ul>
<h2><a class="header" href="#2-使用规范" id="2-使用规范">2 使用规范</a></h2>
<ul>
<li>
<p><strong>禁止</strong>修改<strong>已执行</strong>的 SQL 文件；</p>
</li>
<li>
<p><strong>禁止</strong> DDL 与 DML 语句不能写在同一  SQL 文件；</p>
</li>
<li>
<p>增加 SQL 脚本后，<strong>必须</strong>先在本地进行启动应用验证；</p>
</li>
<li>
<p><strong>禁止</strong>提交执行失败的 SQL 文件；</p>
</li>
<li>
<p>SpringBoot 配置文件中必须配置 spring.flyway.table 避免同一个库不同项目的冲突；</p>
<ul>
<li>参考最佳实践中 flyway的配置文件</li>
</ul>
</li>
<li>
<p><strong>建议</strong> DDL 中  <code>DROP TABLE IF EXISTS</code> 改为 <code>CREATE TABLE IF NOT EXISTS</code></p>
<ul>
<li>使用数据库自动化时<strong>删表</strong>风险比较大</li>
</ul>
</li>
<li>
<p><strong>建议</strong>单库多模块的项目，把 flyway 脚本和配置放在一个基础模块统一管理</p>
</li>
<li>
<p>非项目初始时引入 Flyway <strong>必须</strong>配置：</p>
<pre><code class="language-yml">spring:
  flyway:
    baseline-version: 2.7.0 # 基线版本为项目开始使用 flyway 的版本号
    baseline-on-migrate: true #  针对非空数据库是否默认调用基线版本,为空的话默认会调用基线版本
</code></pre>
</li>
</ul>
<h2><a class="header" href="#3-最佳实践" id="3-最佳实践">3 最佳实践</a></h2>
<h3><a class="header" href="#31-flyway-配置" id="31-flyway-配置">3.1 Flyway 配置</a></h3>
<h3><a class="header" href="#311-yml-配置" id="311-yml-配置">3.1.1 yml 配置</a></h3>
<pre><code class="language-yml">spring:
  flyway:
    enabled: true # 正式环境才开启
    clean-disabled: true # 禁用数据库清理
    encoding: UTF-8
    locations: classpath:/db/migration # 指定sql 脚本的路径
    # flyway 会在库中创建此名称元数据表，用于记录所有版本演化和状态
    # 同一个库不同项目可能冲突，每个项目一张表来记录
    table: fsh_uac2 #后缀指定为当前项目名称
    baseline-version: 0 # 基线版本默认开始序号 默认为 1
    baseline-on-migrate: true #  针对非空数据库是否默认调用基线版本,为空的话默认会调用基线版本
</code></pre>
<h3><a class="header" href="#312-依赖库" id="312-依赖库">3.1.2 依赖库</a></h3>
<pre><code class="language-yml">		&lt;dependency&gt;
            &lt;groupId&gt;org.flywaydb&lt;/groupId&gt;
            &lt;artifactId&gt;flyway-core&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
<h3><a class="header" href="#32-旧项目改造非首次部署" id="32-旧项目改造非首次部署">3.2 旧项目改造（非首次部署）</a></h3>
<blockquote>
<p>​		假设一个旧项目 <code>old-app</code> 当前版本号为 2.6.0，需要改造引入flyway。</p>
</blockquote>
<ol>
<li>
<p>定义一个改造的需求版本，版本号为 <strong>2.7.0</strong> （这个版本没有其它实际需求）</p>
</li>
<li>
<p>将表结构DDL、DML、DCL 等 sql，按上述规范整理到相应文件中：</p>
<ul>
<li><code>V1.0.0.{num}__{type}__oldapp_init.sql</code></li>
</ul>
</li>
<li>
<p>在 {spring.flyway.locations} 下创建一个<code>V2.7.0__baseline.sql</code> 空文件，用于占位；</p>
</li>
<li>
<p>flyway 配置文件：</p>
<pre><code class="language-yml">spring:
  flyway:
    # 其它省略 ... 
    baseline-version: 2.7.0 # 基线版本为项目开始使用 flyway 的版本号
    baseline-on-migrate: true #  针对非空数据库是否默认调用基线版本
</code></pre>
</li>
<li>
<p>发布 2.7.0 </p>
<ul>
<li>
<p>升级发布：</p>
<ul>
<li>
<p>项目启动时 flyway 会生成 {spring.flyway.table}</p>
</li>
<li>
<p>并自动执行<code>V2.7.0__baseline.sql </code>（如果脚本非空，实际内容也不会执行）</p>
</li>
<li>
<p>在 {spring.flyway.table} 中标记基线版本</p>
<table><thead><tr><th>installed_rank</th><th>version</th><th>description</th><th>type</th><th>script</th><th>checksum</th><th>installed_by</th><th>installed_on</th><th>execution_time</th><th>success</th></tr></thead><tbody>
<tr><td>1</td><td>2.7.0</td><td>&lt;&lt; Flyway Baseline &gt;&gt;</td><td>BASELINE</td><td>&lt;&lt; Flyway Baseline &gt;&gt;</td><td></td><td>null</td><td>2021-02-24 16:05:50.632119</td><td>0</td><td>t</td></tr>
</tbody></table>
</li>
</ul>
</li>
<li>
<p>新环境首次部署：</p>
<ul>
<li>项目启动时 flyway 会生成 {spring.flyway.table}</li>
<li>并自动执行以下SQL脚本：
<ul>
<li><code>V1.0.0.{num}__{type}__oldapp_init.sql</code></li>
<li><code>V2.7.0__baseline.sql </code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>之后的版本迭代（如2.8.0）</p>
<ul>
<li>sql 整理：将2.8.0 版本的sql 文件按照规范整理到相应文件中：
<ul>
<li><code>V2.8.0.{date}.{num}__{type}__{description}.sql</code></li>
</ul>
</li>
<li>升级发布:
<ul>
<li>项目启动时自动执行 <code>V2.8.0.{date}.{num}__{type}__{description}.sql</code></li>
</ul>
</li>
<li>新环境首次部署：
<ul>
<li>项目启动时 flyway 会生成 {spring.flyway.table}</li>
<li>并自动执行以下SQL脚本：
<ul>
<li><code>V1.0.0.{num}__{type}__oldapp_init.sql</code></li>
<li><code>V2.7.0__baseline.sql </code></li>
<li><code>V2.8.0.{date}.{num}__{type}__{description}.sql</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2><a class="header" href="#附录-4" id="附录-4">附录</a></h2>
<h3><a class="header" href="#flyway-配置说明" id="flyway-配置说明">flyway 配置说明</a></h3>
<pre><code class="language-yaml">flyway.baseline-description对执行迁移时基准版本的描述.
flyway.baseline-on-migrate当迁移时发现目标schema非空，而且带有没有元数据的表时，是否自动执行基准迁移，默认false.
flyway.baseline-version开始执行基准迁移时对现有的schema的版本打标签，默认值为1.
flyway.check-location检查迁移脚本的位置是否存在，默认false.
flyway.clean-on-validation-error当发现校验错误时是否自动调用clean，默认false.
flyway.enabled是否开启flywary，默认true.
flyway.encoding设置迁移时的编码，默认UTF-8.
flyway.ignore-failed-future-migration当读取元数据表时是否忽略错误的迁移，默认false.
flyway.init-sqls当初始化好连接时要执行的SQL.
flyway.locations迁移脚本的位置，默认db/migration.
flyway.out-of-order是否允许无序的迁移，默认false.
flyway.password目标数据库的密码.
flyway.placeholder-prefix设置每个placeholder的前缀，默认${.
flyway.placeholder-replacementplaceholders是否要被替换，默认true.
flyway.placeholder-suffix设置每个placeholder的后缀，默认}.
flyway.placeholders.[placeholder name]设置placeholder的value
flyway.schemas设定需要flywary迁移的schema，大小写敏感，默认为连接默认的schema.
flyway.sql-migration-prefix迁移文件的前缀，默认为V.
flyway.sql-migration-separator迁移脚本的文件名分隔符，默认__
flyway.sql-migration-suffix迁移脚本的后缀，默认为.sql
flyway.tableflyway使用的元数据表名，默认为schema_version
flyway.target迁移时使用的目标版本，默认为latest version
flyway.url迁移时使用的JDBC URL，如果没有指定的话，将使用配置的主数据源
flyway.user迁移数据库的用户名
flyway.validate-on-migrate迁移时是否校验，默认为true.
</code></pre>
<h3><a class="header" href="#a-hrefhttpsflywaydborgdocumentationconceptsmigrationssql-based-migrationssql-based-migrationsa" id="a-hrefhttpsflywaydborgdocumentationconceptsmigrationssql-based-migrationssql-based-migrationsa"><a href="https://flywaydb.org/documentation/concepts/migrations#sql-based-migrations">sql-based-migrations</a></a></h3>
<h1><a class="header" href="#语义化版本控制规范" id="语义化版本控制规范">语义化版本控制规范</a></h1>
<blockquote>
<p>By <a href="tech/bestpractices/">Siu</a> 2021/02/22</p>
<p>​		随着系统规模越大，加入的依赖的包和关联系统越来越多，软件版本的管理就变为非常重要的工作；软件版本的管理问题有可能引发“依赖地狱”，让系统的发布和升级陷入绝望。</p>
<p>​		本规范引用业内常用的“语义化的版本控制”作为这个问题的解决方案。用一组简单的规则及条件来约束版本号的配置和增长。这些规则是根据已经被各种业内著名软件所广泛使用的惯例所设计。</p>
<p>​		在这套约定下，版本号及其更新方式包含了相邻版本间的底层代码和修改内容的信息。</p>
</blockquote>
<h2><a class="header" href="#1-版本号格式" id="1-版本号格式">1 版本号格式</a></h2>
<p><img src="tech/bestpractices/./assets/%E8%AF%AD%E4%B9%89%E5%8C%96%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E8%A7%84%E8%8C%83.svg" alt="" /></p>
<p><strong>版本格式 <code>X.Y.Z</code>（又称 <code>Major.Minor.Patch</code>），版本号递增规则如下：</strong></p>
<ul>
<li>主版本号（X）：当做了不兼容的 API 修改，X 需递增。</li>
<li>次版本号（Y）：当做了向下兼容的功能性新增，Y 需递增。</li>
<li>修订号（Z）：当做了向下兼容的 Bug 修正，Z 需递增。</li>
</ul>
<p>先行版本号及版本编译元数据可以加到“主版本号.次版本号.修订号”的后面，作为延伸。</p>
<p><strong>例：</strong></p>
<ul>
<li>2.6.0-rc.1+210205.2</li>
<li>2.6.1+210304.3</li>
</ul>
<h2><a class="header" href="#2-版本号控制规范" id="2-版本号控制规范">2 版本号控制规范</a></h2>
<ol>
<li>标准的版本号<strong>必须</strong>采用 X.Y.Z 的格式，其中 X、Y 和 Z 为非负的整数，且<strong>禁止</strong>在数字前方补零。X 是主版本号、Y 是次版本号、而 Z 为修订号。每个元素<strong>必须</strong>以数值来递增。例如：1.9.1 -&gt; 1.10.0 -&gt; 1.11.0。</li>
<li>版本号的软件发行后，<strong>禁止</strong>改变该版本软件的内容。任何修改都<strong>必须</strong>以新版本发行。</li>
<li>主版本号为<strong>从1开始</strong>（1.y.z）；通常0被用于软件开发初始阶段，这里定义软件开发初始阶段用开发版本号来标识，例如：1.0.0-alpha.1+210205.2</li>
<li>X 和 Y 由<strong>产品经理</strong>指定。</li>
<li>修订号 Z（x.y.Z ）<strong>必须</strong>在只做了向下兼容的修正时才递增。这里的修正指的是针对不正确结果而进行的内部修改。修订号由<strong>项目负责人</strong>制定。</li>
<li>次版本号 Y（x.Y.z ）<strong>必须</strong>在有向下兼容的新功能出现时递增。在任何公共 API 的功能被标记为弃用时也<strong>必须</strong>递增。也可以在<strong>内部</strong>程序有大量新功能或改进被加入时递增，其中<strong>可以</strong>包括修订级别的改变。每当次版本号递增时，<strong>修订号</strong>必须归零。</li>
<li>主版本号 X（X.y.z <code>|</code> X &gt; 0）<strong>必须</strong>在有任何不兼容的修改被加入公共 API 时递增。其中<strong>可以</strong>包括次版本号及修订级别的改变。每当主版本号递增时，次版本号和修订号<strong>必须</strong>归零。</li>
</ol>
<ul>
<li>**补充1：**不兼容修改也不允许下线已发布的API</li>
<li>**补充2：**关联系统间的依赖，必须等待被依赖版本发布之后，依赖版本才能发布。</li>
</ul>
<ol start="8">
<li>
<p>先行版本号<strong>可以</strong>被标注在修订号之后，先加上一个<strong>连接符</strong><code>-</code>，再加上一连串以句点分隔的标识符来修饰。标识符<strong>必须</strong>由 ASCII 小写字母、数字和连接符<code>-</code> 组成，且<strong>禁止</strong>留白。数字型的标识符<strong>禁止</strong>在前方补零。先行版的优先级低于相关联的标准版本。被标上先行版本号则表示这个版本并<strong>非稳定</strong>而且可能无法满足预期的兼容性需求。范例：1.0.0-alpha、1.0.0-alpha.1、1.0.0-0.3.7、1.0.0-x.7.z.92。</p>
</li>
<li>
<p>版本编译元数据<strong>可以</strong>被标注在修订版或先行版本号之后，先加上一个加号<code>+</code>再加上一连串以句点分隔的标识符来修饰。标识符<strong>必须</strong>由 ASCII 小写字母、数字和分隔符<code>.</code>组成，且<strong>禁止</strong>留白。当判断版本的优先层级时，版本编译元数据可被忽略。因此当两个版本只有在版本编译元数据有差别时，属于相同的优先层级。范例：1.0.0-rc.1+210205.2、1.0.0-alpha+210205.2、1.0.0+210205.2、1.0.0-beta+210205.2。</p>
<ul>
<li><strong>补充1：<strong>规定编译元数据第一段和第二段限制为：Build Date（编译日期，6位）和 Build ID（编译ID，非负整型数值）；其它元数据信息</strong>禁止</strong>添加。</li>
<li><strong>补充2：<strong>编译元数据</strong>必须</strong>由编译工具自动生成，一经发布<strong>禁止</strong>修改。</li>
</ul>
</li>
<li>
<p>版本的优先层级指的是不同版本在排序时如何比较。</p>
<ul>
<li>判断优先层级时，<strong>必须</strong>把版本依序拆分为主版本号、次版本号、修订号及先行版本号后进行比较（版本编译元数据不影响排序）。</li>
<li>由左到右依序比较每个标识符，第一个差异值用来决定优先层级：
<ul>
<li>主版本号、次版本号及修订号以数值比较，例如：1.0.0 &lt; 2.0.0 &lt; 2.1.0 &lt; 2.1.1。</li>
<li>当主版本号、次版本号及修订号都相同时，改以优先层级比较低的先行版本号决定。例如：1.0.0-alpha &lt; 1.0.0。</li>
<li>有相同主版本号、次版本号及修订号的两个先行版本号，其优先层级<strong>必须</strong>透过由左到右的每个被句点分隔的标识符来比较，直到找到一个差异值后决定：只有数字的标识符以数值高低比较，有字母或连接号时则逐字以 ASCII 的排序来比较。数字的标识符比非数字的标识符优先层级低。若开头的标识符都相同时，栏位比较多的先行版本号优先层级比较高。范例：1.0.0-alpha &lt; 1.0.0-alpha.1 &lt; 1.0.0-alpha.beta &lt; 1.0.0-beta &lt; 1.0.0-beta.2 &lt; 1.0.0-beta.11 &lt; 1.0.0-rc.1 &lt; 1.0.0。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>相关联前端和后端应用的版本号控制</p>
<ul>
<li>
<p>前端应用、后端应用独立管理版本号。</p>
</li>
<li>
<p>前端应用、后端应用主版本号、次版本号的迭代控制是统一的。</p>
</li>
<li>
<p>前后端应用主版本号、次版本号相同时，任意版本必须是兼容的。</p>
<ul>
<li>例如：demo-sys 2.6.Z 版本与它的前端应用 demo-sys-web 2.6.Z 是兼容的</li>
</ul>
</li>
<li>
<p>前端应用对应多个后端应用（后端每个应用又相对独立、代码位于各自的仓库中）：</p>
<ul>
<li>
<p>后端各应用设置一个统一的产品版本号（保存于一个公共仓库）与前端应用版本号对应</p>
</li>
<li>
<p>各后端应用按上述版本号规范，管理自己的内部版本号和统一的产品版本号</p>
</li>
<li>
<p>例：</p>
<blockquote>
<p>当前已发布 <code>前端 2.6.0 ；后端统一产品版本号 2.6.0 （内部版本号：后端 A 1.2.0 后端 B 2.3.0）</code></p>
<ul>
<li>修订版1（后端 A 兼容性修复bug）：<code>前端 2.6.0 ；后端统一产品版本号 2.6.1 （后端 A 1.2.1 后端 B 2.3.0）</code></li>
<li>修订版2（后端 B 兼容性修复bug）：<code>前端 2.6.0 ；后端统一产品版本号 2.6.2 （后端 A 1.2.1 后端 B 2.3.1）</code></li>
<li>修订版3（前端兼容性修复bug）：<code>前端 2.6.1 ；后端统一产品版本号 2.6.2 （后端 A 1.2.1 后端 B 2.3.1）</code></li>
</ul>
</blockquote>
</li>
<li>
<p>**补充1：**前后端多对多的情况也适用上述规则。</p>
</li>
<li>
<p>**补充2：**规范第6点提到的<code>内部程序有大量新功能或改进被加入时递增次版本号</code>，不需要传递到产品版本的次版本号，而是传递到产品版本号的修订号。</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>稳定版本的发布，各版本在试运行 bug 修复完成之后<strong>必须</strong>及时发布正式版。</p>
<ul>
<li><strong>补充1：<strong>稳定版的版本号即不包含先行版本标识的版本号，意味着这个版本进入</strong>稳定</strong>阶段。范例：2.6.1+210304.3</li>
</ul>
</li>
</ol>
<h1><a class="header" href="#参考" id="参考">参考</a></h1>
<p><a href="https://github.com/semver/semver/blob/master/semver.md">Semantic Versioning 2.0.0</a></p>
<h1><a class="header" href="#api-设计规范" id="api-设计规范">API 设计规范</a></h1>
<blockquote>
<p>By Siu 2020/06/10</p>
<p>以下内容遵循RESTful规范的基础上，做适当的补充。</p>
</blockquote>
<h2><a class="header" href="#1-基础规范" id="1-基础规范">1 基础规范</a></h2>
<ul>
<li>
<p><strong>1.1</strong> 【强制】URL 中只允许包含小写字母、下划线、“/”</p>
</li>
<li>
<p><strong>1.2</strong>  【强制】资源的表示统一为复数名词形式；如： users，articles</p>
</li>
<li>
<p><strong>1.3</strong> 【强制】使用HTTP方法来表达动作（增、删、改、查）</p>
<ul>
<li>
<p>正例：</p>
<table><thead><tr><th>动作</th><th>API</th><th>备注</th></tr></thead><tbody>
<tr><td><strong>GET</strong></td><td>/users</td><td>获取users资源集合的URL</td></tr>
<tr><td><strong>GET</strong></td><td>/users/:uid</td><td>获取某个user资源的URL</td></tr>
<tr><td><strong>POST</strong></td><td>/users</td><td>创建一个user资源的URL</td></tr>
<tr><td><strong>PUT</strong></td><td>/users/:uid</td><td>更新一个user资源的URL</td></tr>
<tr><td><strong>PUT</strong></td><td>/users?uid=1,3,5</td><td>更新user资源的URL（<strong>批量</strong>，要带上限定条件）</td></tr>
<tr><td><strong>DELETE</strong></td><td>/users/:uid</td><td>删除一个user资源的URL</td></tr>
<tr><td><strong>DELETE</strong></td><td>/users?uid=1,3,5</td><td>删除user资源的URL（<strong>批量</strong>，要带上限定条件）</td></tr>
</tbody></table>
</li>
</ul>
</li>
<li>
<p><strong>1.4</strong> 【强制】在URL中加入版本号： <code>/v1/users</code> 、<code>/v1/users/:uid</code></p>
<p>说明：</p>
<ul>
<li>如果有不兼容和破坏性的更改，版本号将让你能更容易的发布API。</li>
<li>不需要使用次级版本号（“v1.2”），因为不应该频繁的去发布API版本。</li>
</ul>
</li>
<li>
<p><strong>1.5</strong> 【强制】响应结构应包含：状态码、返回数据，返回信息（<strong>待补充状态码</strong>）</p>
<ul>
<li>
<p>格式统一，如下：</p>
<pre><code class="language-json">{
  &quot;code&quot;: 0,
  &quot;data&quot;: [],
  &quot;message&quot;: &quot;&quot;
}
</code></pre>
</li>
<li>
<p>返回数据（data），实际返回数据要放入<code>data</code>中包装。</p>
</li>
<li>
<p>状态码（code），参考 <strong><a href="tech/bestpractices/">附1-状态码</a></strong>；发生错误时，严禁返回 http 200 状态码。</p>
</li>
<li>
<p>返回信息（message），必须是有意义的，能表明具体的业务状态和信息（特别是业务发生错误时）。</p>
</li>
</ul>
</li>
<li>
<p><strong>1.6</strong> 【强制】列表查询的API必须分页</p>
<ul>
<li>
<p>请求参数：
| 参数名称 | 类型 | 必须 | 备注                               |
| :------- | ---- | :--- | :--------------------------------- |
| page  | int  | 否   | 当前页码，默认 1                   |
| limit    | int  | 否   | 每页条数，默认10，&lt;=200            |</p>
</li>
<li>
<p>返回数据：</p>
<table><thead><tr><th align="left">参数名称</th><th>类型</th><th align="left">必须</th><th align="left">备注</th></tr></thead><tbody>
<tr><td align="left">page</td><td>int</td><td align="left">是</td><td align="left">当前页码</td></tr>
<tr><td align="left">limit</td><td>int</td><td align="left">是</td><td align="left">每页条数</td></tr>
<tr><td align="left">total</td><td>int</td><td align="left">是</td><td align="left">总量</td></tr>
<tr><td align="left">items</td><td>object[]</td><td align="left">否</td><td align="left">分页数据对象列表</td></tr>
</tbody></table>
</li>
</ul>
</li>
<li>
<p><strong>1.7</strong> 【强制】使用小驼峰命名法作为属性标识符。</p>
<p>反例：</p>
<pre><code class="language-json">{ &quot;YearOfBirth&quot;: 1982 }
{ &quot;year_Of_Birth&quot;: 1982 }
</code></pre>
<p>正例：</p>
<pre><code class="language-json">{ &quot;yearOfBirth&quot;: 1982 }
</code></pre>
</li>
<li>
<p><strong>1.8</strong> 【强制】严禁下线已经发布的API，应该通过版本变更并保证客户端升级的情况下才能下线过时的API。</p>
<p>说明：API的过时不是由服务端决定的，如果不能保证所有客户端都启用了新的API，就必须保持旧API的兼容。</p>
</li>
<li>
<p><strong>1.9</strong> 【强制】排序参数使用<code>sort</code>标识，类型 string[]，使用&quot;-&quot;标记<strong>降序</strong>。:new:</p>
<p>正例：</p>
<table><thead><tr><th>API</th><th>说明</th></tr></thead><tbody>
<tr><td><strong>GET</strong> /v1/users?sort=-createTime</td><td>按照createTime降序</td></tr>
<tr><td><strong>GET</strong> /v1/users?sort=-createTime,updateTime</td><td>按照createTime降序,updateTime升序</td></tr>
</tbody></table>
</li>
</ul>
<h2><a class="header" href="#2-最佳实践" id="2-最佳实践">2 最佳实践</a></h2>
<ul>
<li>
<p>2.1【推荐】合理设计资源多级分类（只有一个资源主题）</p>
<p>例：获取某个作者的某一类文章 <code>GET /v1/authors/:aid/categories/:cid</code>。</p>
<p>说明：</p>
<ul>
<li>这种 API设计不利于扩展，语义也不明确，往往要想一会，才能明白含义。</li>
<li>多级资源使用时一定要划分清楚它们的关系，特别时还有<code>Query Parmas</code>时。</li>
</ul>
<blockquote>
<p>推荐：<strong>GET</strong> /v1/authors/:aid?categories=:cid</p>
<p>设计还要考虑具体的业务，设计是服务于业务的，具体碰到的场景可以单独讨论，这只是一般规则。</p>
</blockquote>
</li>
<li>
<p>2.2【推荐】特定资源搜索的API。</p>
<p>例：模糊查询一个“姓名”、出生在某个时间之后的用户 </p>
<blockquote>
<p><strong>GET</strong> /v1/users?query=李&amp;birth_after=1980</p>
</blockquote>
</li>
<li>
<p>2.3【推荐】跨资源的搜索或非资源请求，可以使用动词。</p>
<p>例：全局（多个资源中）搜索”siu“。</p>
<blockquote>
<p><strong>GET</strong> /v1/search?query=siu</p>
</blockquote>
<p>例：非资源请求，计算、翻译转换等。</p>
<blockquote>
<p><strong>GET</strong> /calculate?para2=23&amp;para2=432</p>
<p><strong>GET</strong> /translate?from=de_DE&amp;to=en_US&amp;text=Hallo </p>
</blockquote>
</li>
<li>
<p>2.4【推荐】将 id 放在 URL 中而不是 <code>Query Param</code></p>
<blockquote>
<p><strong>GET</strong> /v1/articles/:aid/comments ： 某篇文章的评论列表(<code>区别于2.1</code>)</p>
<p><strong>GET</strong> /v1/comments/:cid ： 获取</p>
<p><strong>POST</strong> /v1/articles/:aid/comments ： 在某篇文章中创建评论(<code>区别于2.1</code>)</p>
</blockquote>
</li>
</ul>
<blockquote>
<p><strong>PUT</strong> /v1/comments/:cid ： 修改评论</p>
<p><strong>DELETE</strong> /v1/comments/:cid ： 删除评论</p>
</blockquote>
<ul>
<li>
<p>2.5 【推荐】最短 URL 原则。</p>
<p>说明：URL 用于定位资源，如果短的那个设计满足，请避免冗余的设计。</p>
<blockquote>
<p><strong>GET</strong> /v1/comments/:cid 已经可以指向一条评论了</p>
<p>就不需要再用 <strong>GET</strong> /v1/articles/:aid/comments/:cid特意的指出所属文章了</p>
</blockquote>
</li>
<li>
<p>2.6 对于某些特定且复杂的业务逻辑，不要试图让客户端用复杂的查询参数表示，而是在 URL 使用别名(哪怕是动作)</p>
<p>例：通过excel批量导入用户 <code>POST /v1/users?actions=upload</code></p>
<blockquote>
<p>推荐 <strong>POST</strong> /v1/users/upload</p>
</blockquote>
</li>
<li>
<p>2.7 超出 HTTP Method 表达语义的API。</p>
<ul>
<li>把资源的操作变成属性。
<ul>
<li>例：把用户置为失效 <code>GET /v1/users/:uid?disabled=true</code></li>
</ul>
</li>
<li>将这个操作看成某个资源的附属资源。
<ul>
<li>例：Github Star gist 操作 <code>PUT /gists/:id/star</code> <code>DELETE /gists/:id/star</code> ` </li>
</ul>
</li>
</ul>
</li>
<li>
<p>2.7 保持向后兼容。只要客户端能接受就通过添加字段的方式演进API，配合版本控制变更。</p>
</li>
<li>
<p>2.8 如果发现通过版本变化发布API，对客户端变化改变过大（业务不允许），允许通过 <code>Query Parma</code> 控制版本。</p>
<p>说明：在实际场景中考虑业务优先的前提，允许使用通过添加参数控制版本。</p>
<blockquote>
<p>推荐： <strong>GET</strong> /v1/users?version=1</p>
</blockquote>
</li>
<li>
<p>2.9  查询部分属性，设计一个<strong>fields</strong>作为过滤。:new:</p>
<blockquote>
<p>推荐 ：<strong>GET</strong> /users?<strong>fields=id,name,address</strong>&amp;diabled=false</p>
</blockquote>
</li>
<li>
<p>2.10 单独为 API 设计一个 Query Parameter 专门用于搜索，<code>GET /v1/users?query=keyword</code> :new:</p>
</li>
<li>
<p>2.11 属性编辑的接口，需要进行增量更新时，无法判定前端传递参数中置空字段和不需要更新字段</p>
<blockquote>
<p>推荐：参数传递时增加一个clearField字段，字段类型为List<String>告知后端哪些字段要清空</p>
</blockquote>
</li>
</ul>
<h2><a class="header" href="#3-其他" id="3-其他">3 其他	</a></h2>
<ul>
<li>
<p>3.1 使用Swagger的项目 可以使用注解标记API设计者，没有使用Swagger也应该在API文档中标明。</p>
<p>说明：</p>
<ul>
<li>
<p>标记API的设计者，有助于API使用者快速反馈沟通；Swagger标记方便协同。</p>
</li>
<li>
<p>Swagger 注解标记</p>
<pre><code>@Api(tags = {&quot;标记莫格模块API作者：@作者&quot;})
@ApiOperation(value = &quot;标记单个API设计者：@作者&quot;, httpMethod = &quot;GET&quot;)
</code></pre>
</li>
</ul>
</li>
<li>
<p>3.2 不使用<code>PATCH</code>，PUT 和 PATCH 都可以用于修改操作，为了统一不做区分，直接使用PUT。</p>
</li>
<li>
<p>3.3 <strong>GET、PUT</strong> 使用 <code>Query Parma</code> 还是 <code>JSON</code> 由业务决定设计。</p>
</li>
</ul>
<h1><a class="header" href="#附录-5" id="附录-5">附录</a></h1>
<p>状态码</p>
<p><a href="https://developer.github.com/v3/">Github API Docs</a></p>
<p><a href="https://docs.gitlab.com/ee/api/issues.html">Gitlab API Docs</a></p>
<p><a href="https://juejin.im/entry/59e460c951882542f578f2f0">RESTful API 设计最佳实践</a></p>
<p><a href="https://www.jianshu.com/p/cf80d644727e">RESTful Service API 设计最佳工程实践和常见问题解决方案</a></p>
<h1><a class="header" href="#git-协同开发指南" id="git-协同开发指南">git 协同开发指南</a></h1>
<p>这份文档主要思想基于gitflow。</p>
<h2><a class="header" href="#1-概述" id="1-概述">1 概述</a></h2>
<p>这份指南会包含两大块内容：</p>
<ul>
<li>
<p>1、分支结构规范，【附录一】</p>
</li>
<li>
<p>2、commit message 规范，【附录二】</p>
</li>
</ul>
<h2><a class="header" href="#2-git-flow-的开发活动图" id="2-git-flow-的开发活动图">2 Git Flow 的开发活动图</a></h2>
<blockquote>
<p>开发者为中心的活动图</p>
</blockquote>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/dev_git_flow.png" alt="Git Workflows:UML" /></p>
<pre><code class="language-txt">上图简要描述了开发者如何进行开发代码，提交代码和发布代码，修复bug的过程。详图见Visio 文档
1、从develop分支checkout出自己的开发新功能的分支（B-E、C-D）
2、在自己的开发分支编码并提交（E-G、D-F）
3、把代码合并到develop分支（G/F-H）
4、发布develop分支的代码（H-I）
5、修复release分支的Bug（I-J-K）
6、master发布，生成tag 02（M）
7、热修复master分支Bug：Check出hotfix分支修复bug，hotfix合并到release，发布测试，合并到master，master发布，生成tag 03（M-N-O-P/Q） 

</code></pre>
<h2><a class="header" href="#3-quick-start" id="3-quick-start">3 Quick Start</a></h2>
<hr />
<blockquote>
<p>有疑问，Quick Start，实践一下！</p>
</blockquote>
<p>下面的示例演示本工作流如何用于管理单个发布循环。假设你已经创建了一个中央仓库。</p>
<ul>
<li>详细的分支工作方式参考【附录一】</li>
<li>注意提交代码时遵循commit mesage 规范【附录二】</li>
<li>在IntelliJ IDEA 中操作 请参考【附录三】</li>
</ul>
<h3><a class="header" href="#31-创建开发分支一般已创建可跳过" id="31-创建开发分支一般已创建可跳过">3.1 创建开发分支（一般已创建可跳过）</a></h3>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-release-cycle-5createdev.png" alt="" /></p>
<p>第一步为<code>master</code>分支配套一个<code>develop</code>分支。简单来做可以<a href="https://www.atlassian.com/git/tutorial/git-branches#!branch">本地创建一个空的<code>develop</code>分支</a>，<code>push</code>到服务器上：</p>
<pre><code class="language-bash">git branch develop
git push -u origin develop
</code></pre>
<p>以后这个分支将会包含了项目的全部历史，而<code>master</code>分支将只包含了部分历史。其它开发者这时应该<a href="https://www.atlassian.com/git/tutorial/git-basics#!clone">克隆中央仓库</a>，建好<code>develop</code>分支的跟踪分支：</p>
<pre><code class="language-bash">git clone ssh://user@host/path/to/repo.git
git checkout -b develop origin/develop

#【译注】当没有本地分支 develop 时，
# 最后一条命令，我使用更简单的 git checkout develop
# 会自动 把 远程分支origin/develop 检出成 本地分支 develop
</code></pre>
<p>现在每个开发都有了这些历史分支的本地拷贝。</p>
<h3><a class="header" href="#32-小红和小明开始开发新功能" id="32-小红和小明开始开发新功能">3.2 小红和小明开始开发新功能</a></h3>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-release-cycle-6maryjohnbeginnew.png" alt="" /></p>
<p>这个示例中，小红和小明开始各自的功能开发。他们需要为各自的功能创建相应的分支。新分支不是基于<code>master</code>分支，而是应该<a href="https://www.atlassian.com/git/tutorial/git-branches#!checkout">基于<code>develop</code>分支</a>：</p>
<pre><code class="language-bash">git checkout -b some-feature develop
</code></pre>
<p>他们用老套路添加提交到各自功能分支上：编辑、暂存、提交：</p>
<pre><code class="language-bash">git status
git add &lt;some-file&gt;
git commit
</code></pre>
<h3><a class="header" href="#33-小红完成功能开发" id="33-小红完成功能开发">3.3 小红完成功能开发</a></h3>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-release-cycle-7maryfinishes.png" alt="" /></p>
<p>添加了提交后，小红觉得她的功能OK了。如果团队使用<code>Pull Requests</code>，这时候可以发起一个用于合并到<code>develop</code>分支。
否则她可以直接合并到她本地的<code>develop</code>分支后<code>push</code>到中央仓库：</p>
<pre><code class="language-bash"># 拉取远程的develop分支，并且当前分支（本地分支some-feature）合并上远程分支develop
git pull origin develop
git checkout develop
# 本地分支some-feature合并上some-feature
#【注意】已经这个分支已经有远程的develop修改了，所以本地develop无需再做远程拉取的操作
git merge some-feature
git push
# 删除本地分支
git branch -d some-feature

#【译注】上面的命令注释为译者添加，以方便理解
# 更多说明参见 Issue #18
</code></pre>
<p>第一条命令在合并功能前确保<code>develop</code>分支是最新的。注意，功能决不应该直接合并到<code>master</code>分支。
冲突解决方法参考下面【冲突解决部分】。</p>
<h3><a class="header" href="#34-小红开始准备发布" id="34-小红开始准备发布">3.4 小红开始准备发布</a></h3>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-release-cycle-8maryprepsrelease.png" alt="" /></p>
<p>这个时候小明正在实现他的功能，小红开始准备她的第一个项目正式发布。
像功能开发一样，她用一个新的分支来做发布准备。这一步也确定了发布的版本号：</p>
<pre><code class="language-bash">git checkout -b release-0.1 develop
</code></pre>
<p>这个分支是清理发布、执行所有测试、更新文档和其它为下个发布做准备操作的地方，像是一个专门用于改善发布的功能分支。</p>
<p>只要小红创建这个分支并<code>push</code>到中央仓库，这个发布就是功能冻结的。任何不在<code>develop</code>分支中的新功能都推到下个发布循环中。</p>
<h3><a class="header" href="#35-小红完成发布" id="35-小红完成发布">3.5 小红完成发布</a></h3>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-release-cycle-9maryfinishes.png" alt="" /></p>
<p>一旦准备好了对外发布，小红合并修改到<code>master</code>分支和<code>develop</code>分支上，删除发布分支。合并回<code>develop</code>分支很重要，因为在发布分支中已经提交的更新需要在后面的新功能中也要是可用的。
另外，如果小红的团队要求<code>Code Review</code>，这是一个发起<code>Pull Request</code>的理想时机。</p>
<pre><code class="language-bash">git checkout master
git merge release-0.1
git push
git checkout develop
git merge release-0.1
git push
git branch -d release-0.1
</code></pre>
<p>发布分支是作为功能开发（<code>develop</code>分支）和对外发布（<code>master</code>分支）间的缓冲。只要有合并到<code>master</code>分支，就应该打好<code>Tag</code>以方便跟踪。</p>
<pre><code class="language-bash">git tag -a 0.1 -m &quot;Initial public release&quot; master
git push --tags
</code></pre>
<p><code>Git</code>有提供各种勾子（<code>hook</code>），即仓库有事件发生时触发执行的脚本。
可以配置一个勾子，在你<code>push</code>中央仓库的<code>master</code>分支时，自动构建好对外发布。</p>
<h3><a class="header" href="#36-最终用户发现bug" id="36-最终用户发现bug">3.6 最终用户发现Bug</a></h3>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-gitflow-enduserbug.png" alt="" /></p>
<p>对外发布后，小红回去和小明一起做下个发布的新功能开发，直到有最终用户开了一个<code>Ticket</code>抱怨当前版本的一个<code>Bug</code>。
为了处理<code>Bug</code>，小红（或小明）从<code>master</code>分支上拉出了一个维护分支，提交修改以解决问题，然后直接合并回<code>master</code>分支：</p>
<pre><code class="language-bash">git checkout -b issue-#001 master
# Fix the bug
git checkout master
git merge issue-#001
git push
</code></pre>
<p>就像发布分支，维护分支中新加这些重要修改需要包含到<code>develop</code>分支中，所以小红要执行一个合并操作。然后就可以安全地<a href="https://www.atlassian.com/git/tutorial/git-branches#!branch">删除这个分支</a>了：</p>
<pre><code class="language-bash">git checkout develop
git merge issue-#001
git push
git branch -d issue-#001
</code></pre>
<hr />
<hr />
<hr />
<h2><a class="header" href="#附录一-分支的工作方式" id="附录一-分支的工作方式">附录一: 分支的工作方式</a></h2>
<hr />
<p><code>Gitflow</code>工作流仍然用中央仓库作为所有开发者的交互中心。和其它的工作流一样，开发者在本地工作并<code>push</code>分支到要中央仓库中。</p>
<p>分支结构图：</p>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflows-gitflow.png" alt="Git Workflows: Gitflow Cycle" /></p>
<ul>
<li>
<p>绿色代表<code>历史分支 master</code></p>
</li>
<li>
<p>橘色代表<code>历史分支 develop</code></p>
</li>
<li>
<p>黄色代表<code>发布分支 release-X</code></p>
</li>
<li>
<p>蓝色代表<code>功能分支 feature-X</code></p>
</li>
<li>
<p>灰色代表<code>热修复分支 hotfix-X</code></p>
</li>
</ul>
<h3><a class="header" href="#历史分支" id="历史分支">历史分支</a></h3>
<p>相对使用仅有的一个<code>master</code>分支，<code>Gitflow</code>工作流使用2个分支来记录项目的历史。<code>master</code>分支存储了正式发布的历史，而<code>develop</code>分支作为功能的集成分支。
这样也方便<code>master</code>分支上的所有提交分配一个版本号。</p>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-release-cycle-1historical.png" alt="" /></p>
<p>剩下要说明的问题围绕着这2个分支的区别展开。</p>
<h3><a class="header" href="#功能分支" id="功能分支">功能分支</a></h3>
<p>每个新功能位于一个自己的分支，这样可以<a href="https://www.atlassian.com/git/tutorial/remote-repositories#!push"><code>push</code>到中央仓库以备份和协作</a>。
但功能分支不是从<code>master</code>分支上拉出新分支，而是使用<code>develop</code>分支作为父分支。当新功能完成时，<a href="https://www.atlassian.com/git/tutorial/git-branches#!merge">合并回<code>develop</code>分支</a>。
新功能提交应该从不直接与<code>master</code>分支交互。</p>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-release-cycle-2feature.png" alt="" /></p>
<p>注意，从各种含义和目的上来看，功能分支加上<code>develop</code>分支就是功能分支工作流的用法。但<code>Gitflow</code>工作流没有在这里止步。</p>
<h3><a class="header" href="#发布分支" id="发布分支">发布分支</a></h3>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-release-cycle-3release.png" alt="" /></p>
<p>一旦<code>develop</code>分支上有了做一次发布（或者说快到了既定的发布日）的足够功能，就从<code>develop</code>分支上<code>fork</code>一个发布分支。
新建的分支用于开始发布循环，所以从这个时间点开始之后新的功能不能再加到这个分支上——
这个分支只应该做<code>Bug</code>修复、文档生成和其它面向发布任务。
一旦对外发布的工作都完成了，发布分支合并到<code>master</code>分支并分配一个版本号打好<code>Tag</code>。
另外，这些从新建发布分支以来的做的修改要合并回<code>develop</code>分支。</p>
<p>使用一个用于发布准备的专门分支，使得一个团队可以在完善当前的发布版本的同时，另一个团队可以继续开发下个版本的功能。
这也打造定义良好的开发阶段（比如，可以很轻松地说，『这周我们要做准备发布版本4.0』，并且在仓库的目录结构中可以实际看到）。</p>
<p>常用的分支约定：</p>
<pre><code>用于新建发布分支的分支: develop
用于合并的分支: master
分支命名: release-* 或 release/*
</code></pre>
<h3><a class="header" href="#维护分支" id="维护分支">维护分支</a></h3>
<p><img src="tech/bestpractices/git-collaborative-development-tutorials/images/git-workflow-release-cycle-4maintenance.png" alt="" /></p>
<p>维护分支或说是热修复（<code>hotfix</code>）分支用于生成快速给产品发布版本（<code>production releases</code>）打补丁，这是唯一可以直接从<code>master</code>分支<code>fork</code>出来的分支。
修复完成，修改应该马上合并回<code>master</code>分支和<code>develop</code>分支（当前的发布分支），<code>master</code>分支应该用新的版本号打好<code>Tag</code>。</p>
<p>为<code>Bug</code>修复使用专门分支，让团队可以处理掉问题而不用打断其它工作或是等待下一个发布循环。
你可以把维护分支想成是一个直接在<code>master</code>分支上处理的临时发布。</p>
<h2><a class="header" href="#附录二-commit-message-规范" id="附录二-commit-message-规范">附录二: commit message 规范</a></h2>
<hr />
<p>每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。</p>
<blockquote>
<pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;
// 空一行
&lt;body&gt;
// 空一行
&lt;footer&gt;

</code></pre>
</blockquote>
<p>其中，Header 是必需的，Body 和 Footer 可以省略。</p>
<p>不管是哪一个部分，任何一行都不得超过72个字符。这是为了避免自动换行影响美观。</p>
<h3><a class="header" href="#header" id="header">Header</a></h3>
<p>Header部分只有一行，包括三个字段：<code>type</code>（必需）、<code>scope</code>（可选）和<code>subject</code>（必需）。</p>
<h4><a class="header" href="#type" id="type">type</a></h4>
<p><code>type</code>用于说明 commit 的类别，只允许使用下面7个标识。</p>
<blockquote>
<ul>
<li>feat：新功能（feature）</li>
<li>fix：修补bug</li>
<li>docs：文档（documentation）</li>
<li>style： 格式（不影响代码运行的变动）</li>
<li>refactor：重构（即不是新增功能，也不是修改bug的代码变动）</li>
<li>test：增加测试</li>
<li>chore：构建过程或辅助工具的变动</li>
</ul>
</blockquote>
<p>如果<code>type</code>为<code>feat</code>和<code>fix</code>，则该 commit 将肯定出现在 Change log 之中。其他情况（<code>docs</code>、<code>chore</code>、<code>style</code>、<code>refactor</code>、<code>test</code>）由你决定，要不要放入 Change log，建议是不要。</p>
<h4><a class="header" href="#scope" id="scope">scope</a></h4>
<p><code>scope</code>用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。</p>
<h4><a class="header" href="#subject" id="subject">subject</a></h4>
<p><code>subject</code>是 commit 目的的简短描述，不超过50个字符。</p>
<blockquote>
<ul>
<li>以动词开头，使用第一人称现在时，比如<code>change</code>，而不是<code>changed</code>或<code>changes</code></li>
<li>第一个字母小写</li>
<li>结尾不加句号（<code>.</code>）</li>
</ul>
</blockquote>
<h3><a class="header" href="#body" id="body">Body</a></h3>
<p>Body 部分是对本次 commit 的详细描述，可以分成多行。下面是一个范例。</p>
<blockquote>
<pre><code>More detailed explanatory text, if necessary.  Wrap it to 
about 72 characters or so. 

Further paragraphs come after blank lines.

- Bullet points are okay, too
- Use a hanging indent

</code></pre>
</blockquote>
<p>有两个注意点。</p>
<p>（1）使用第一人称现在时，比如使用<code>change</code>而不是<code>changed</code>或<code>changes</code>。</p>
<p>（2）应该说明代码变动的动机，以及与以前行为的对比。</p>
<h3><a class="header" href="#footer" id="footer">Footer</a></h3>
<p>Footer 部分只用于两种情况。</p>
<h4><a class="header" href="#不兼容变动" id="不兼容变动">不兼容变动</a></h4>
<p>如果当前代码与上一个版本不兼容，则 Footer 部分以<code>BREAKING CHANGE</code>开头，后面是对变动的描述、以及变动理由和迁移方法。</p>
<blockquote>
<pre><code>BREAKING CHANGE: isolate scope bindings definition has changed.

    To migrate the code follow the example below:

    Before:

    scope: {
      myAttr: 'attribute',
    }

    After:

    scope: {
      myAttr: '@',
    }

    The removed `inject` wasn't generaly useful for directives so there should be no code using it.

</code></pre>
</blockquote>
<h4><a class="header" href="#关闭-issue" id="关闭-issue">关闭 Issue</a></h4>
<p>如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue 。</p>
<blockquote>
<pre><code>Closes #234

</code></pre>
</blockquote>
<p>也可以一次关闭多个 issue 。</p>
<blockquote>
<pre><code>Closes #123, #245, #992

</code></pre>
</blockquote>
<h3><a class="header" href="#revert" id="revert">Revert</a></h3>
<p>还有一种特殊情况，如果当前 commit 用于撤销以前的 commit，则必须以<code>revert:</code>开头，后面跟着被撤销 Commit 的 Header。</p>
<blockquote>
<pre><code>revert: feat(pencil): add 'graphiteWidth' option

This reverts commit 667ecc1654a317a13331b17617d973392f415f02.

</code></pre>
</blockquote>
<p>Body部分的格式是固定的，必须写成<code>This reverts commit &lt;hash&gt;.</code>，其中的<code>hash</code>是被撤销 commit 的 SHA 标识符。</p>
<p>如果当前 commit 与被撤销的 commit，在同一个发布（release）里面，那么它们都不会出现在 Change log 里面。如果两者在不同的发布，那么当前 commit，会出现在 Change log 的<code>Reverts</code>小标题下面。</p>
<h1><a class="header" href="#code-review-规范" id="code-review-规范">Code Review 规范</a></h1>
<blockquote>
<p>By <a href="tech/bestpractices/">Siu</a> 2020/05/14</p>
</blockquote>
<p>以下采用gitflow + PR/MR模式，基于Gitlab 进行Code Review</p>
<h2><a class="header" href="#1-目标原则" id="1-目标原则">1 目标&amp;原则</a></h2>
<p>Why Code Review?</p>
<ul>
<li>
<p>提高代码质量，及早发现潜在缺陷，降低修改/弥补缺陷的成本</p>
</li>
<li>
<p>促进团队内部知识共享，提高团队整体水平</p>
</li>
<li>
<p>评审过程对于评审人员来说，也是一种思路重构的过程，帮助更多的人理解系统</p>
</li>
<li>
<p>是一个传递知识的手段，可以让其它并不熟悉代码的人知道作者的意图和想法，从而可以在以后轻松维护代码</p>
</li>
<li>
<p>可以被用来确认自己的设计和实现是一个清楚和简单的</p>
</li>
<li>
<p>是一种特殊的pair programing实践</p>
</li>
<li>
<p>鼓励相互学习对方的长处和优点</p>
</li>
<li>
<p>高效迅速完成Code Review</p>
</li>
</ul>
<h2><a class="header" href="#2-流程规则" id="2-流程规则">2 流程&amp;规则</a></h2>
<p>How To Code Review？</p>
<h3><a class="header" href="#21-git-flow" id="21-git-flow">2.1 Git Flow</a></h3>
<p><img src="tech/bestpractices/./assets/gitflow.webp" alt="" /></p>
<h3><a class="header" href="#22-pull-request" id="22-pull-request">2.2 Pull Request</a></h3>
<ol>
<li>任务完成才能提交PR</li>
<li>严禁一个PR里面有多个任务，除非它们是紧密关联的</li>
<li>PR提交之后只允许针对Review发现问题再次提交代码，除非有充足的理由，严禁在同一个PR中再次提交其它任务的代码</li>
<li><strong>PR的Title</strong>必须概括性表达提交的内容，如果无法概括，就应该考虑这些commit不应该给归为一个PR</li>
<li>提交PR时候有一个描述框，内容会自动根据Commit的message合并而成。切记，如果一次提交的内容包含很多Commit，请不要使用自动生成的描述。请用简短但是足够说明问题的语言（理想是控制在3句话之内）来描述： 你改动了什么，解决了什么问题，需要代码审查的人留意那些影响比较大的改动。特别需要留意，如果对基础、公共的组件进行了改动，一定要另起一行特别说明。</li>
<li>PR应该在1~2个工作日内被合并或者被拒绝</li>
<li><strong>发起Pull Request以后，请将Pull Request的链接通过Email发给代码审核者，以此通知对方及时进行审核。(BUG修复类当日必须完成合并或者拒绝，功能类或者觉得有重大调整需要会议Review必须在邮件中明确时间和会议人员)</strong></li>
<li>你可以分配这个 MR 给你自己，直到你完成你的工作，然后把它分配给其他人来做一次代码复审。如果有必要的话，这个 MR 可以被重新分配多次，直到覆盖你所需要的审查的代码。</li>
</ol>
<h3><a class="header" href="#23-rules--tips" id="23-rules--tips">2.3 Rules &amp; Tips</a></h3>
<ol>
<li>
<p><strong>保证必须</strong>以Merge的方式变更develop/release/master分支，需要对Push/Merge权限进行限制</p>
</li>
<li>
<p>中级审初级，高级审中级，高级互审（这是一般原则）；</p>
</li>
<li>
<p>确保每次代码合并前都有2个人review（实际允许，鼓励全员review）；</p>
</li>
<li>
<p>不必拘束于形式，不强调会议形式，不强调审核；</p>
</li>
<li>
<p>鼓励初级人员给高级人员提出代码意见（虽然流程上没有这样的形式，PR是自下而上的）；</p>
</li>
<li>
<p><strong>学会自己进行Code Review</strong>，在别人review之前你已经解决了很多疏忽的问题；</p>
</li>
<li>
<p><strong>尽可能的让不同的人Review你的代码</strong>，主动去PR给你的高级人员；</p>
</li>
<li>
<p>虚心接受意见，但不要羞涩表达自己的观点，大胆指出问题，<strong>鼓励积极的Disscussion</strong>（在gitlab）；</p>
</li>
<li>
<p>不要纠结拒绝PR是否太不计情面，写好拒绝的原有，<strong>拒绝是为了下一次更好</strong>；</p>
</li>
<li>
<p>忘记下面的<strong>Checklist</strong>，把Code Review 当成一种轻松的交流，太正式未必达成好的效果；</p>
</li>
<li>
<p>如果你是一个新人，那么<strong>Code Review 将是最快融入团队的方式</strong>；</p>
</li>
<li>
<p><strong>学会享受Code Review</strong>，这是最重要的。</p>
</li>
</ol>
<h2><a class="header" href="#3-code-review-checklist" id="3-code-review-checklist">3 Code Review Checklist</a></h2>
<p>Code Review主要检查代码中是否存在以下方面问题：</p>
<ul>
<li>完整性检查
<ul>
<li>代码是否完全实现了设计文档中提出的功能需求</li>
<li>代码是否已按照设计文档进行了集成和Debug</li>
<li>代码是否已创建了需要的数据库，包括正确的初始化数据</li>
<li>代码中是否存在任何没有定义或没有引用到的变量、常数或数据类型</li>
</ul>
</li>
<li>一致性检查
<ul>
<li>代码的逻辑是否符合设计文档</li>
<li>代码中使用的格式、符号、结构等风格是否保持一致</li>
</ul>
</li>
<li>正确性检查
<ul>
<li>代码是否符合制定的标准</li>
<li>所有的变量都被正确定义和使用</li>
<li>所有的注释都是准确的</li>
<li>所有的程序调用都使用了正确的参数个数</li>
</ul>
</li>
<li>可修改性检查
<ul>
<li>代码涉及到的常量是否易于修改(如使用配置、定义为类常量、使用专门的常量类等)</li>
<li>代码中是否包含了交叉说明或数据字典，以描述程序是如何对变量和常量进行访问的</li>
<li>代码是否只有一个出口和一个入口（严重的异常处理除外）</li>
</ul>
</li>
<li>可预测性检查
<ul>
<li>代码所用的开发语言是否具有定义良好的语法和语义</li>
<li>是否代码避免了依赖于开发语言缺省提供的功能</li>
<li>代码是否无意中陷入了死循环</li>
<li>代码是否是否避免了无穷递归</li>
</ul>
</li>
<li>健壮性检查
<ul>
<li>异常处理和清理（释放）资源</li>
<li>代码是否采取措施避免运行时错误（如数组边界溢出、被零除、值越界、堆栈溢出等）</li>
</ul>
</li>
<li>结构性检查
<ul>
<li>程序的每个功能是否都作为一个可辩识的代码块存在</li>
<li>循环是否只有一个入口</li>
</ul>
</li>
<li>可追溯性检查
<ul>
<li>代码是否对每个程序进行了唯一标识</li>
<li>是否有一个交叉引用的框架可以用来在代码和开发文档之间相互对应</li>
<li>代码是否包括一个修订历史记录，记录中对代码的修改和原因都有记录</li>
<li>是否所有的安全功能都有标识</li>
</ul>
</li>
<li>可理解性检查
<ul>
<li>注释是否足够清晰的描述每个子程序</li>
<li>是否使用到不明确或不必要的复杂代码，它们是否被清楚的注释</li>
<li>使用一些统一的格式化技巧（如缩进、空白等）用来增强代码的清晰度</li>
<li>是否在定义命名规则时采用了便于记忆，反映类型等方法</li>
<li>每个变量都定义了合法的取值范围</li>
<li>代码中的算法是否符合开发文档中描述的数学模型</li>
</ul>
</li>
<li>可验证性检查
<ul>
<li>代码中的实现技术是否便于测试</li>
</ul>
</li>
<li>可重用性
<ul>
<li>DRY（Do not Repeat Yourself）原则：同一代码不应该重复两次以上</li>
<li>考虑可重用的服务，功能和组件</li>
<li>考虑通用函数和类</li>
</ul>
</li>
<li>可扩展性
<ul>
<li>轻松添加功能，对现有代码进行最小的更改。一个组件可以被更好的组件替换</li>
</ul>
</li>
<li>安全性
<ul>
<li>进行身份验证，授权，输入数据验证，避免诸如SQL注入和跨站脚本（XSS）等安全威胁 ，加密敏感数据（密码，信用卡信息等）</li>
</ul>
</li>
<li>性能
<ul>
<li>使用合适的数据类型，例如StringBuilder，通用集合类</li>
<li>懒加载，异步和并行处理</li>
<li>缓存和会话/应用程序数据</li>
</ul>
</li>
</ul>
<p><strong>代码检查包括不局限于上述清单，提交人应在本地自我完成代码格式、架构设计、面向对象分析与设计等检查。</strong></p>
<p><strong>如果是Javaer，参考阿里的《Java开发手册》（最新泰山版）。</strong></p>
<h2><a class="header" href="#4-code-review的步骤" id="4-code-review的步骤">4 Code Review的步骤</a></h2>
<p>Code Review 服务于项目开发，按照以下步骤执行code review：</p>
<ol>
<li>需求功能开发完成（<strong>提测</strong>之前），开发leader统一组织code review。</li>
<li>代码编写者和代码审核者坐在一起，由代码编写者按照业务层次依次讲解自己负责的代码和相关逻辑。</li>
<li>代码审核者在此过程中可以随时提出自己的疑问，同时积极发现隐藏的bug；直接在gitlab上记录。</li>
<li>代码讲解完毕后，代码审核者给自己安排几个小时再对代码审核一遍。代码需要一行一行静下心看。同时代码又要全面的看，以确保代码整体上设计优良。</li>
<li>代码审核者将审核的意见记录在gitlab上，抄送给代码编写者&amp;其它审核人员，注明修改deadline。</li>
<li>代码编写者根据代码审核者给出的修改意见，修改代码并再次PR。</li>
<li>开发leader确认所有PR都进行明确的反馈（接受或拒绝，不接受没有理由的意见）。</li>
</ol>
<h2><a class="header" href="#5-code-review-base-on-gitlab" id="5-code-review-base-on-gitlab">5 Code Review Base On Gitlab</a></h2>
<h3><a class="header" href="#51-gitlab-protected-branches-配置" id="51-gitlab-protected-branches-配置">5.1 Gitlab Protected Branches 配置</a></h3>
<p>为了保证必须以Merge的方式变更develop分支、release分支、以及master分支，需要对Push以及Merge权限进行限制。</p>
<blockquote>
<p>菜单：Settings-&gt;Repository Settings然后展开Protected Branches选项</p>
</blockquote>
<p><img src="tech/bestpractices/./assets/image-20200513220757139.png" alt="image-20200513220757139" /></p>
<pre><code class="language-txt">对于通配符的分支保护release-*，我们需要给Maintainers（Masters）组的用户Push权限，不然无法新建对应格式的分支。
对于固定名称的分支：master、release，可以限制所有角色都没有Push权限。
</code></pre>
<h3><a class="header" href="#52-gitlab-code-review-约定" id="52-gitlab-code-review-约定">5.2 GitLab Code Review 约定</a></h3>
<blockquote>
<p>所有PR都应有明确的Milestone、Label，Tile、Description。Tile、Description 上文已经提到，下面对 Milestone、Label 做相应规范约束。</p>
</blockquote>
<h4><a class="header" href="#milestone" id="milestone">Milestone</a></h4>
<blockquote>
<p>里程碑，代指项目的版本阶段</p>
</blockquote>
<ul>
<li>Title 发布版本号，如：2.5.0.2004310_RC</li>
<li>Description （描述信息），需包含以下：
<ul>
<li>版本的概括信息</li>
<li>版本的计划功能列表</li>
</ul>
</li>
<li>必须指定<code>Start Date</code>  <code>Due Date</code></li>
</ul>
<h4><a class="header" href="#label" id="label">Label</a></h4>
<blockquote>
<p>标签，区分各MR的性质</p>
</blockquote>
<p>限定以下指定标签：</p>
<ul>
<li>
<p><strong>MR:DEV:DESIGN</strong> 提交物属性为设计类（接口设计、模型设计、流程图、设计文档、公共定义类代码）</p>
</li>
<li>
<p><strong>MR:DEV:DOCS</strong> 提交物属性为文档类（非设计文档，如部署，预研，项目总结PPT）</p>
</li>
<li>
<p><strong>MR:DEV:FEAT</strong> 提交物属性为新特性开发</p>
</li>
<li>
<p><strong>MR:DEV:FIXBUG</strong> 提交物属性为修复bug类</p>
</li>
<li>
<p><strong>MR:DEV:HOTFIX</strong> 提交物属性热修复代码类</p>
</li>
<li>
<p><strong>MR:DEV:OTHER</strong> 提交物属性为无法归类的其它产物</p>
</li>
<li>
<p><strong>MR:DEV:REFACTOR</strong> 提交物属性为重构代码类</p>
</li>
<li>
<p><strong>MR:DEV:TEMPLATE</strong> 提交物属性为模板类代码</p>
</li>
</ul>
<h3><a class="header" href="#53-wip-mr" id="53-wip-mr">5.3 WIP MR</a></h3>
<blockquote>
<p>WIP MR 含义是 <strong>在工作过程中的合并请求</strong>，是一个我们在 GitLab 中避免 MR 在准备就绪前被合并的技术。只需要添加 <code>WIP:</code> 在 MR 的标题开头，它将不会被合并，除非你把 <code>WIP:</code> 删除。</p>
</blockquote>
<p>当你改动已经准备好被合并，编辑工单来手动删除 <code>WIP:</code> ，或者使用就像如下 MR 描述下方的快捷方式。<img src="tech/bestpractices/./assets/image-20200523122646716.png" alt="image-20200523122646716" /></p>
<p><strong>新功能：</strong> <code>WIP</code> 模式可以通过<a href="https://docs.gitlab.com/ce/user/project/slash_commands.html">斜线命令</a> <code>/wip</code> <a href="https://about.gitlab.com/2016/10/22/gitlab-8-13-released/#wip-slash-command">快速添加到合并请求中</a>。只需要在评论或者 MR 描述中输入它并提交即可。</p>
<h3><a class="header" href="#54-closed-issues" id="54-closed-issues">5.4 Closed Issues</a></h3>
<blockquote>
<p>在一个MR中可以关联相应的工单，做到当MR被接受时，关闭Issues</p>
</blockquote>
<p>可以在Title，MR Description中按下面格式描述：</p>
<blockquote>
<h4><a class="header" href="#重构a接口修复12" id="重构a接口修复12">重构A接口，修复#1，#2</a></h4>
<p>这个 MR 重构了a接口，修复以下</p>
<p><code>Closes #[Issue No] and https://gitlab.com/issues/[Issue NO]</code></p>
<p>@Siu @Jack @John</p>
</blockquote>
<h3><a class="header" href="#55-other" id="55-other">5.5 Other</a></h3>
<p>在工单和 MR 的描述中:</p>
<ul>
<li>输入 <code>#</code> 来触发一个已有工单的下拉列表</li>
<li>输入 <code>!</code> 来触发一个已有 MR 的下拉列表</li>
<li>输入 <code>/</code> 来触发<a href="https://docs.gitlab.com/ce/user/project/slash_commands.html">斜线命令</a></li>
<li>输入 <code>:</code> 来出发 emoji 表情 (也支持行中评论)</li>
<li>输入 <code>@</code> 来提示项目成员</li>
</ul>
<h1><a class="header" href="#附录-6" id="附录-6">附录</a></h1>
<h3><a class="header" href="#gitlab-code-review-示例" id="gitlab-code-review-示例">GitLab Code Review 示例</a></h3>
<h4><a class="header" href="#create-merge-request" id="create-merge-request">Create Merge Request</a></h4>
<p><img src="tech/bestpractices/./assets/image-20200513222201895.png" alt="image-20200513222201895" /></p>
<p><img src="tech/bestpractices/./assets/image-20200513222742427.png" alt="image-20200513222742427" /></p>
<p><img src="tech/bestpractices/./assets/image-20200513222910167.png" alt="image-20200513222910167" /></p>
<p><img src="tech/bestpractices/./assets/image-20200513224420881.png" alt="image-20200513224420881" /></p>
<p><img src="tech/bestpractices/./assets/image-20200513224843374.png" alt="image-20200513224843374" /></p>
<h3><a class="header" href="#ide-review-code-示例" id="ide-review-code-示例">IDE Review Code 示例</a></h3>
<h4><a class="header" href="#install-plugin" id="install-plugin">Install Plugin</a></h4>
<ul>
<li>
<p>Gitlab Projects [2020]</p>
</li>
<li>
<p>Gitlab Integration</p>
</li>
</ul>
<h4><a class="header" href="#gitlab-access-token" id="gitlab-access-token">GitLab Access Token</a></h4>
<blockquote>
<p>菜单：User Settings&gt;Access Tokens 进入Access Token添加页面</p>
</blockquote>
<p><img src="tech/bestpractices/./assets/image-20200513225324186.png" alt="image-20200513225324186" /></p>
<h4><a class="header" href="#create-merge-request-1" id="create-merge-request-1">Create Merge Request</a></h4>
<p><img src="tech/bestpractices/./assets/image-20200513232420455.png" alt="image-20200513232420455" /></p>
<p><img src="tech/bestpractices/./assets/image-20200513232758013.png" alt="image-20200513232758013" /></p>
<h1><a class="header" href="#ref-8" id="ref-8">Ref</a></h1>
<p><a href="https://linux.cn/article-8503-1.html">GitLab 工作流概览</a></p>
<h1><a class="header" href="#gitlab-issue-规范指南" id="gitlab-issue-规范指南">Gitlab Issue 规范指南</a></h1>
<blockquote>
<p>By <a href="tech/bestpractices/">Siu</a> 2020/05/14</p>
</blockquote>
<h2><a class="header" href="#1-概念定义" id="1-概念定义">1 概念定义</a></h2>
<ul>
<li>工单（Issue）：可以是一个Bug、一个建议、一个任务单</li>
<li>列表（List）：代表Issue所处不同阶段</li>
<li>看板（Board）：所有Issue 列表</li>
<li>标签（Label）：区分Issue 的处理阶段、性质、优先级</li>
</ul>
<h2><a class="header" href="#2-issue-创建规范" id="2-issue-创建规范">2 Issue 创建规范</a></h2>
<ul>
<li>标题（Titile）足够准确，能概括描述Issue的主要内容</li>
<li>描述（Description）足够清晰，包含问题的所有信息，关联信息、历史信息（使用markdown语法）；
<ul>
<li>描述中话可以添加子任务<code>Add a task list</code></li>
</ul>
</li>
<li>指定接收人（Assignee），标明截止日期<code>Due date</code></li>
<li>指定3个Label，标明<code>Issue 处于哪个执行/处理阶段</code>、标明<code>Issue 是何种性质</code>、标明<code>Issue 紧急程度</code>（参照Label 规范）
<ul>
<li>优先级Label，通常由项目经理判断标明</li>
<li>默认新提交的Issue，处理阶段都标记到<code>Inbox</code>标签</li>
</ul>
</li>
<li>关联到具体的Milestone
<ul>
<li>参考CR规范里面的定义</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#3-看板列表规范list" id="3-看板列表规范list">3 看板列表规范（List）</a></h2>
<blockquote>
<p>同下Label规范，执行处理阶段定义。</p>
</blockquote>
<ul>
<li>Inbox，这个列表收集Issue，处于这个列表的Issue可以不指定 <code>Assignee</code>
<ul>
<li><strong>暂时只由有开发阶段的收集，需求和BUG暂未接入</strong></li>
<li>每周一，由项目负责人review一遍Inbox，并作相应的指派和操作</li>
</ul>
</li>
<li>Todo，这个列表的Issue处于已计划阶段，需要有明确的<code>Assignee</code> 和 <code>Due date</code>
<ul>
<li>由项目经理/开发负责人分配</li>
</ul>
</li>
<li>Doing，这个列表的Issue处于执行阶段，必须标明执行的状态<code>In-Progress Almost-Done  Stuck</code>
<ul>
<li>由<code>Assignee</code>更新状态标签</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#4-标签规范label" id="4-标签规范label">4 标签规范（Label）</a></h2>
<ul>
<li>
<p>执行处理阶段</p>
<ul>
<li>Inbox，收集阶段</li>
<li>Todo，计划阶段</li>
<li>Doing，执行阶段
<ul>
<li>In-Progress 进行中</li>
<li>Almost-Done 几近完成</li>
<li>Stuck 有阻碍、困难</li>
</ul>
</li>
</ul>
</li>
<li>
<p>性质</p>
<ul>
<li>
<p>BUG 类</p>
<ul>
<li>BUG-Blocker ,即系统无法执行、崩溃或严重资源不足、应用模块无法启动或异常退出、无法测试</li>
<li>BUG-Critical , 即影响系统功能或操作，主要功能存在严重缺陷，但不会影响到系统稳定性</li>
<li>BUG-Major ,即界面、性能缺陷、兼容性</li>
<li>BUG-Minor ,即易用性及建议性问题</li>
</ul>
</li>
<li>
<p>PR，产品需求类</p>
<ul>
<li>PR</li>
</ul>
</li>
<li>
<p>Suggestion，建议类</p>
<ul>
<li>SUGGESTION</li>
</ul>
</li>
<li>
<p>Task，工单任务类</p>
<ul>
<li>TASK</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Priority，优先级</p>
<ul>
<li>HIGH <strong>高优先级</strong>（High）：对系统有重大影响，只有解决它之后，才能去完成其他任务。</li>
<li>MEDIUM <strong>普通优先级</strong>（Medium）：对系统的某个部分有影响，用户的一部分操作会达不到预期效果。</li>
<li>LOW <strong>低优先级</strong>（Low）：对系统的某个部分有影响，用户几乎感知不到。</li>
<li>TRIVIAL <strong>微不足道</strong>（Trivial）：对系统的功能没有影响，通常是视觉效果不理想，比如字体和颜色不满意。</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#5-slack-通知集成" id="5-slack-通知集成">5 Slack 通知集成</a></h2>
<blockquote>
<p>在Slack 上创建相应的channel，接收Issue 流转通知</p>
</blockquote>
<p>ref <a href="https://hugo1030.github.io/tech/slack-connect-gitlab/">https://hugo1030.github.io/tech/slack-connect-gitlab/</a></p>
<h1><a class="header" href="#python-代码规范" id="python-代码规范">Python 代码规范</a></h1>
<h2><a class="header" href="#11-编码" id="11-编码">1.1 编码</a></h2>
<p>•   如无特殊情况, 文件一律使用 UTF-8 编码</p>
<p>•   如无特殊情况, 文件头部必须加入#-<em>-coding:utf-8-</em>-标识</p>
<h2><a class="header" href="#12-代码格式" id="12-代码格式">1.2 代码格式</a></h2>
<h3><a class="header" href="#121--缩进" id="121--缩进">1.2.1  缩进</a></h3>
<p>•   统一使用 4 个空格进行缩进</p>
<h3><a class="header" href="#122--行宽" id="122--行宽">1.2.2  行宽</a></h3>
<p>每行代码尽量不超过 80 个字符(在特殊情况下可以略微超过 80 ，但最长不得超过 120)</p>
<p>理由：</p>
<p>•   这在查看 side-by-side 的 diff 时很有帮助</p>
<p>•   方便在控制台下查看代码</p>
<p>•   太长可能是设计有缺陷</p>
<p>例外：</p>
<ol>
<li>长的导入模块语句</li>
<li>注释里的URL</li>
</ol>
<p>不要使用反斜杆连接行。</p>
<p>Python会将圆括号，中括号和花括号中的行隐形的连接起来，你可以利用这个特点。如果代码需要，可在表达式外围增加一堆额外的圆括号。</p>
<pre><code class="language-python"># 推荐
if (width == 0 and height == 0 and
    color == 'red'):

# 文本时
x = (u&quot;这是一串很长很长很长很长很长很长很长很长很长很长&quot;
     &quot;很长很长很长很长很长很长很长很长的文字&quot;)

</code></pre>
<h3><a class="header" href="#123--引号" id="123--引号">1.2.3  引号</a></h3>
<p>简单说，自然语言使用双引号，机器标示使用单引号，因此 <strong>代码里</strong> 多数应该使用 <strong>单引号</strong></p>
<p>•   <strong>自然语言</strong> <strong>使用双引号</strong> &quot;...&quot;
例如错误信息；很多情况还是 unicode，使用u&quot;你好世界&quot;</p>
<p>•   <strong>机器标识</strong> <strong>使用单引号</strong> '...' 例如 dict 里的 key</p>
<p>•   <strong>正则表达式</strong> <strong>使用原生的双引号</strong> r&quot;...&quot;</p>
<p>•   <strong>文档字符串 (docstring)</strong> <strong>使用三个双引号</strong> &quot;&quot;&quot;......&quot;&quot;&quot;</p>
<h3><a class="header" href="#124--空行" id="124--空行">1.2.4  空行</a></h3>
<p>•   模块级函数和类定义之间空两行；</p>
<p>•   类成员函数之间空一行；</p>
<pre><code class="language-python">class A:

    def __init__(self):
        pass

    def hello(self):
        pass


def main():
    pass   

</code></pre>
<p>•   可以使用多个空行分隔多组相关的函数</p>
<p>•   函数中可以使用空行分隔出逻辑相关的代码</p>
<h3><a class="header" href="#125--编码" id="125--编码">1.2.5  编码</a></h3>
<p>•   文件使用 UTF-8 编码</p>
<p>•   文件头部加入#-<em>-conding:utf-8-</em>-标识</p>
<h3><a class="header" href="#126--括号" id="126--括号">1.2.6  括号</a></h3>
<p>除非是用于实现行连接, 否则不要在返回语句或条件语句中使用括号. 不过在元组两边使用括号是可以的.</p>
<pre><code class="language-python"># 正确
 if foo:
   bar()
 while x:
   x = bar()
 if x and y:
   bar()
 if not x:
   bar()
 return foo
 for(x, y) in dict.items(): ...
 
 # 错误
 if (x):
   bar()
 if not(x):
   bar()
 return (foo)
 
 # 元组
 tup1 = ('physics', 'chemistry', 1997, 2000)
 tup2 = (1, 2, 3, 4, 5 )
 tup3 = &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;
</code></pre>
<h3><a class="header" href="#127--分号" id="127--分号">1.2.7  分号</a></h3>
<p>不要用行尾加分号，也不要用分号将两条语句放在同一行。</p>
<h2><a class="header" href="#13--import-语句" id="13--import-语句">1.3  import 语句</a></h2>
<p>•   import 语句应该分行书写</p>
<pre><code class="language-python"># 正确的写法
 import os
 import sys
 
 # 不推荐的写法
 import sys,os
 
 # 正确的写法
 from subprocess import Popen, PIPE
</code></pre>
<p>•   import语句应该使用 <strong>absolute</strong> import</p>
<pre><code class="language-python"># 正确的写法
 from foo.bar import Bar

 # 不推荐的写法
 from ..bar import Bar
</code></pre>
<p>•   import语句应该放在文件头部，置于模块说明及docstring之后，于全局变量之前；</p>
<p>•   import语句应该按照顺序排列，每组之间用一个空行分隔</p>
<pre><code class="language-python">import os
import sys
 
import msgpack
import zmq
 
import foo
</code></pre>
<p>•   导入其他模块的类定义时，可以使用相对导入</p>
<pre><code class="language-python">from myclass import MyClass
</code></pre>
<p>•   如果发生命名冲突，则可使用命名空间</p>
<pre><code class="language-python">import bar
import foo.bar
 
 bar.Bar()
 foo.bar.Bar()
</code></pre>
<h2><a class="header" href="#14--空格" id="14--空格">1.4  空格</a></h2>
<p>•   在二元运算符两边各空一格[=,-,+=,==,&gt;,in,is not, and]:</p>
<pre><code class="language-python"># 正确的写法
 i = i + 1
 submitted += 1
 x = x * 2 - 1
 hypot2 = x * x + y * y
 c = (a + b) * (a - b)
 
 # 不推荐的写法
 i=i+1
 submitted +=1
 x = x*2 - 1
 hypot2 = x*x + y*y
 c = (a+b) * (a-b)
</code></pre>
<p>•   函数的参数列表中，,之后要有空格</p>
<pre><code class="language-python"># 正确的写法
 def complex(real, imag):
   pass
 
 # 不推荐的写法
 def complex(real,imag):
   pass
</code></pre>
<p>•   函数的参数列表中，默认值等号两边不要添加空格</p>
<pre><code class="language-python"># 正确的写法
 def complex(real, imag=0.0):
   pass
 
 # 不推荐的写法
 def complex(real, imag = 0.0):
   pass
</code></pre>
<p>•   左括号之后，右括号之前不要加多余的空格</p>
<pre><code class="language-python"># 正确的写法
 spam(ham[1], {eggs: 2})
 
 # 不推荐的写法
 spam( ham[1], { eggs : 2 } )
</code></pre>
<p>•   字典对象的左括号之前不要多余的空格</p>
<pre><code class="language-python"># 正确的写法
 dict['key'] = list[index]
 
 # 不推荐的写法
 dict ['key'] = list [index]
</code></pre>
<p>•   不要为对齐赋值语句而使用的额外空格</p>
<pre><code class="language-python"># 正确的写法
 x = 1
 y = 2
 long_variable = 3
 
 # 不推荐的写法
 x       = 1
 y       = 2
 long_variable = 3
</code></pre>
<h2><a class="header" href="#15--换行" id="15--换行">1.5  换行</a></h2>
<p>Python 支持括号内的换行。这时有两种情况。</p>
<p>•   第二行缩进到括号的起始处</p>
<pre><code class="language-python">foo = long_function_name(var_one, var_two,
             var_three, var_four)
</code></pre>
<p>•   第二行缩进 4 个空格，适用于起始括号就换行的情形</p>
<pre><code class="language-python">def long_function_name(
     var_one, var_two, var_three,
     var_four):
   print(var_one)
</code></pre>
<p>•   使用反斜杠\换行，二元运算符+ .等应出现在行末；长字符串也可以用此法换行</p>
<pre><code class="language-python">session.query(MyTable).\
     filter_by(id=1).\
     one()
        
 # 下面这种换行，建议改成括号内换行
 print 'Hello, '\
    '%s %s!' %\
    ('Harry', 'Potter')
     
 # 括号内换行   
 print ('Hello, '
    '%s %s!' %
    ('Harry', 'Potter'))
</code></pre>
<p>禁止复合语句，即一行中包含多个语句：</p>
<pre><code class="language-python"># 正确的写法
 do_first()
 do_second()
 do_third()
 
 # 不推荐的写法
 do_first();do_second();do_third();

if/for/while一定要换行：

# 正确的写法
 if foo == 'blah':
   do_blah_thing()
 
 # 不推荐的写法
 if foo == 'blah': do_blash_thing()
</code></pre>
<h2><a class="header" href="#16--docstring" id="16--docstring">1.6  docstring</a></h2>
<p>docstring 的规范中最其本的两点：</p>
<ol>
<li>所有的公共模块、函数、类、方法，都应该写 docstring 。私有方法不一定需要，但应该在 def 后提供一个块注释来说明。</li>
<li>docstring 的结束&quot;&quot;&quot;应该独占一行，除非此 docstring 只有一行。</li>
</ol>
<pre><code class="language-python">&quot;&quot;&quot;Return a foobar
 Optional plotz says to frobnicate the bizbaz first.
 &quot;&quot;&quot;
 
 &quot;&quot;&quot;Oneline docstring&quot;&quot;&quot;
</code></pre>
<h1><a class="header" href="#2--注释" id="2--注释">2  注释</a></h1>
<h2><a class="header" href="#21--注释" id="21--注释">2.1  注释</a></h2>
<h3><a class="header" href="#211--块注释" id="211--块注释">2.1.1  块注释</a></h3>
<p>“#”号后空一格，段落件用空行分开（同样需要“#”号）</p>
<pre><code class="language-python"># 块注释
# 块注释
#
# 块注释
# 块注释
</code></pre>
<h3><a class="header" href="#212--行注释" id="212--行注释">2.1.2  行注释</a></h3>
<p>至少使用两个空格和语句分开，注意不要使用无意义的注释</p>
<pre><code class="language-python"> # 正确的写法
 x = x + 1 # 边框加粗一个像素
 
 # 不推荐的写法(无意义的注释)
 x = x + 1 # x加1
</code></pre>
<h3><a class="header" href="#213--建议" id="213--建议">2.1.3  建议</a></h3>
<p>•   在代码的关键部分(或比较复杂的地方), 能写注释的要尽量写注释</p>
<p>•   比较重要的注释段, 使用多个等号隔开, 可以更加醒目, 突出重要性</p>
<pre><code class="language-python">app = create_app(name, options)


# =====================================
# 请勿在此处添加 get post等app路由行为 !!!
# =====================================


if __name__ == '__main__':
    app.run()

</code></pre>
<h3><a class="header" href="#214--todo注释" id="214--todo注释">2.1.4  TODO注释</a></h3>
<p>在注释开头添加“TODO”字符串，紧跟着是用括号括起来的你的名字/邮箱地址/其他标识符，紧接一个冒号和一个空格后添加注释内容，写明要做什么。</p>
<pre><code class="language-python"># TODO(xxx@cecdat.com): 这里解释要做什么
</code></pre>
<h2><a class="header" href="#22--文档注释docstring" id="22--文档注释docstring">2.2  文档注释（Docstring）</a></h2>
<p>作为文档的Docstring一般出现在模块头部、函数和类的头部，这样在python中可以通过对象的<strong>doc</strong>对象获取文档. 编辑器和IDE也可以根据Docstring给出自动提示.</p>
<p>•   文档注释以 &quot;&quot;&quot; 开头和结尾, 首行不换行, 如有多行, 末行必需换行, 以下是Google的docstring风格示例</p>
<pre><code class="language-python"># -*- coding: utf-8 -*-
&quot;&quot;&quot;Example docstrings.

This module demonstrates documentation as specified by the `Google Python
Style Guide`_. Docstrings may extend over multiple lines. Sections are created
with a section header and a colon followed by a block of indented text.

Example:
    Examples can be given using either the ``Example`` or ``Examples``
    sections. Sections support any reStructuredText formatting, including
    literal blocks::

        $ python example_google.py

Section breaks are created by resuming unindented text. Section breaks
are also implicitly created anytime a new section starts.
&quot;&quot;&quot;

</code></pre>
<p>•   不要在文档注释复制函数定义原型, 而是具体描述其具体内容, 解释具体参数和返回值等</p>
<p># 不推荐的写法(不要写函数原型等废话)</p>
<pre><code class="language-python">#  不推荐的写法(不要写函数原型等废话)
def function(a, b):
    &quot;&quot;&quot;function(a, b) -&gt; list&quot;&quot;&quot;
    ... ...


#  正确的写法
def function(a, b):
    &quot;&quot;&quot;计算并返回a到b范围内数据的平均值&quot;&quot;&quot;
    ... ...

</code></pre>
<p>•   对函数参数、返回值等的说明采用numpy标准, 如下所示</p>
<pre><code class="language-python">def func(arg1, arg2):
    &quot;&quot;&quot;在这里写函数的一句话总结(如: 计算平均值).

    这里是具体描述.

    参数
    ----------
    arg1 : int
        arg1的具体描述
    arg2 : int
        arg2的具体描述

    返回值
    -------
    int
        返回值的具体描述

    参看
    --------
    otherfunc : 其它关联函数等...

    示例
    --------
    示例使用doctest格式, 在`&gt;&gt;&gt;`后的代码可以被文档测试工具作为测试用例自动运行

    &gt;&gt;&gt; a=[1,2,3]
    &gt;&gt;&gt; print [x + 3 for x in a]
    [4, 5, 6]
    &quot;&quot;&quot;

</code></pre>
<p>•   文档注释不限于中英文, 但不要中英文混用</p>
<p>•   文档注释不是越长越好, 通常一两句话能把情况说清楚即可</p>
<p>•   模块、公有类、公有方法, 能写文档注释的, 应该尽量写文档注释</p>
<h2><a class="header" href="#23--文件头注释" id="23--文件头注释">2.3  文件头注释</a></h2>
<h3><a class="header" href="#231--模板" id="231--模板">2.3.1  模板</a></h3>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : ${DATE} ${TIME}
# @author  : Siu
# @Project    : ${PROJECT_NAME}
# @Description    :
# @Copyright : xxx

</code></pre>
<h3><a class="header" href="#232--ide中设置模板" id="232--ide中设置模板">2.3.2  IDE中设置模板</a></h3>
<p>以Pycharm为例，选择菜单 File &gt; Settings &gt; File and Code Templates &gt; Python Script ，粘贴模板，保存</p>
<h1><a class="header" href="#3--命名规范" id="3--命名规范">3  命名规范</a></h1>
<h2><a class="header" href="#31-模块" id="31-模块">3.1 模块</a></h2>
<p>•   模块尽量使用小写命名，首字母保持小写，尽量不要用下划线(除非多个单词，且数量不多的情况)</p>
<pre><code class="language-python"># 正确的模块名
import decoder
import html_parser

# 不推荐的模块名
import Decoder

</code></pre>
<h2><a class="header" href="#32-类名" id="32-类名">3.2 类名</a></h2>
<p>•   类名使用驼峰(CamelCase)命名风格，首字母大写，私有类可用一个下划线开头</p>
<pre><code class="language-python">class Farm():
    pass

class AnimalFarm(Farm):
    pass

class _PrivateFarm(Farm):
    pass

</code></pre>
<p>•   将相关的类和顶级函数放在同一个模块里. 不像Java, 没必要限制一个类一个模块.</p>
<h2><a class="header" href="#33-函数" id="33-函数">3.3 函数</a></h2>
<p>•   函数名一律小写，如有多个单词，用下划线隔开</p>
<pre><code class="language-python">def run():
    pass

def run_with_env():
    pass

</code></pre>
<p>•   私有函数在函数前加一个下划线_</p>
<pre><code class="language-python">class Person():

    def _private_func():
        pass

</code></pre>
<h2><a class="header" href="#34-变量名" id="34-变量名">3.4 变量名</a></h2>
<p>•   变量名尽量小写, 如有多个单词，用下划线隔开</p>
<pre><code class="language-python">if __name__ == '__main__':
    count = 0
    school_name = ''
</code></pre>
<p>•   常量采用全大写，如有多个单词，使用下划线隔开</p>
<pre><code class="language-python">MAX_CLIENT = 100
MAX_CONNECTION = 1000
CONNECTION_TIMEOUT = 600
</code></pre>
<h2><a class="header" href="#35-常量" id="35-常量">3.5 常量</a></h2>
<p>•   常量使用以下划线分隔的大写命名</p>
<pre><code class="language-python">MAX_OVERFLOW = 100

Class FooBar:

    def foo_bar(self, print_):
        print(print_)

</code></pre>
<h1><a class="header" href="#4--主函数" id="4--主函数">4  主函数</a></h1>
<p>即使是一个打算被用作脚本的文件，也应该是可导入的。 并且简单的导入不应该导致这个脚本的主功能(main functionality)被执行。 主功能应该放在一个main()函数中，然后添加if <strong>name</strong> == '<strong>main</strong>'，防止当模块被导入时主程序被执行。</p>
<pre><code class="language-python">def main():
    ...
    
if __name__ == '__main__':
    main()

</code></pre>
<h1><a class="header" href="#5--其他" id="5--其他">5  其他</a></h1>
<h2><a class="header" href="#51-ide" id="51-ide">5.1 IDE</a></h2>
<p>推荐使用 <a href="https://www.jetbrains.com/pycharm/">PyCharm</a></p>
<h2><a class="header" href="#52-python-版本" id="52-python-版本">5.2 Python 版本</a></h2>
<p>待定。</p>
<p><strong>本页编辑</strong>      <strong><a href="http://192.168.1.23/gongshiwen">@gongshiwen</a></strong> <img src="http://192.168.1.23/uploads/-/system/user/avatar/10/avatar.png?width=100" style="zoom:10%;" /></p>

                        <div id="giscus-container"></div>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>
        <script type="text/javascript" charset="utf-8">
        var pagePath = "print.md"
        </script>


        <!-- Custom JS scripts -->
        
        <script type="text/javascript" src="assets/custom.js"></script>
        
        <script type="text/javascript" src="assets/showBigPicture.js"></script>
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>