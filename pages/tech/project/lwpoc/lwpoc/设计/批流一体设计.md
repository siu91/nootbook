# 批流一体设计

## 我们的场景

- 批量采集
- CDC增量采集
- 历史存量数据采集+CDC增量采集场景

## 批量采集场景设计

在很多时候，机构不会开放增量采集的通道，只能进行批量采集，其中批量采集场景中，我们分为分区增量数据和分区覆盖数据：

- 分区增量数据：当批量采集进行了重复数据过滤，或者根据增量标识进行增量采集时，该部分数据是无法识别新增和更新的，为此，该部分数据是可以直接追加到对应分区的，存在一定的脏数据。

- 分区覆盖数据：该场景是针对分区增量采集的一种补充，目的是为了解决分区增量采集存在脏数据场景，保证最终数据的一致性。其中入库需要根据整个分区进行覆盖。

#### 特点

- 定时窗口采集，瞬时采集的数据量大
- 数据是有边界的

#### 设计

当批量采集进行了重复数据过滤，或者根据增量标识进行增量采集时，该部分数据是无法识别新增和更新的，为此，该部分数据是可以直接追加到对应分区的，存在一定的脏数据。其中设计点如下：

- MQ topic设计：一个数据库共用一个topic，多个分区

- 生产端设计：

  - 数据格式：JSON Format

  - 边界标识：单个任务数据写入到单分区中，采集数据写入前先写入一条**开始标识**，采集数据写入完成写入一条**结束标识**

- 消费端设计：

  - 订阅模式：**共享**模式
  - 实时流处理JOB生命周期：
    - 定时窗口采集：JOB在采集开始启动，入库结束停止
    - 24小时微批采集：JOB在第一次采集启动，一直运行
  - 入库方式：
    - 分区增量数据：数据直接**追加**到对应的分区
    - 分区覆盖数据：数据写入到临时表分区，直到消费到**结束标识**时，再将整个临时表分区**覆盖写入**到正式表分区

## CDC增量采集场景设计

在某些业务场景中，只关注增量的数据，无需采集历史存量数据。

#### 特点

- 数据是有先后顺序的
- 根据机构端的业务特点，可能集中在某个时段内数据量大

#### 设计

- MQ topic设计：一个数据库共用一个topic，多个分区

- 生产端设计：

  - 数据格式：[Debezium Format](https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/table/formats/debezium/#debezium-format)

  - 保证顺序性：一张表数据写入到topic的**相同分区**中

- 消费端设计：

  - 订阅模式：**Key共享**模式，多个消费者可以同时订阅一个topic，消息在跨消费者的分布中传递，具有相同键或相同排序键的消息仅传递给一个消费者。无论消息被重新传递多少次，它都会传递给同一个消费者。从而**保证数据消费的顺序性**。
  - 实时流处理JOB生命周期：JOB在第一次采集启动，一直运行
  - 入库方式：根据消息内容中的表名，数据写入到对应的表中

## 历史存量数据采集+CDC增量采集场景设计

一张表在开启CDC采集时，大概率该表已经存在历史存量数据，为此需要先进行历史存量数据的采集，再进行CDC增量数据的采集。

#### 特点

- 存量和增量数据处理
  - **顺序性**：增量数据入库的数据更新操作依赖于存量数据，为此存量数据需要先入库
  - **边界处理**：历史存量数据和增量数据间存在边界问题，需要进行边界处理
- 增量数据需要保证顺序性

#### 设计

- MQ topic设计：

  - 历史存量数据：一个数据库历史存量数据共用一个历史存量topic，多个分区
  - 增量数据：一个数据库增量数据共用一个增量topic，多个分区

- 生产端设计：

  - 数据格式
    - 历史存量数据：JSON Format
    - 增量数据：[Debezium Format](https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/table/formats/debezium/#debezium-format)

  - 存量和增量数据**边界处理**和**顺序性处理**设计

    - 当表开启历史存量数据采集时，先获取此表当前的**边界码**
      - Oracle边界：SCN码粒度是到数据库，在数据库中全局唯一的
      - Sqlserver边界：LSN码粒度是到表，在表中唯一

    - 一个库优先一张表历史存量采集完成再采集下一张表
    - 一张表开启历史存量数据采集时，同时开启CDC增量采集
      - 历史存量数据采集：采集历史存量数据任务，单个任务数据写入到单分区中，采集数据写入前先写入一条**开始标识**，采集数据写入完成后写入一条**结束标识**
      - CDC增量数据采集：开启CDC增量采集时，写入一条开启**表CDC增量的开始标识**

    根据以上策略，保证单表的历史存量数据和增量数据的边界划分和顺序性

- 消费端设计：

  - 订阅模式：

    - 历史存量数据： **共享**模式
    - 增量数据：**Key共享**模式

  - 实时流处理JOB生命周期：JOB在第一次采集启动，一直运行

  - 入库方式：

    - 历史存量数据：表任务分区直接追加到每个目标表的分区中

    - 增量数据：当消费到某张表**表CDC增量的开始标识**时，判断该表的历史存量是否完成采集

      - **如果未完成，则停止整个库的CDC增量的消费，直到该表历史存量数据都已经入库**

      - **如果已完成，查找对应分区的历史存量数据任务的采集时间，如果大于采集时间则入库，否则放弃入库**

#### 缺点

- 增量数据入库的方式，当遇到历史数据未采集完成的表时，会阻塞整库的增量数据入库，直到该表历史存量数据采集完成才重新启动，**是通过损失增量入库的效率来达到存量和增量数据入库的顺序性**

## 总结

以上三个场景的设计基本上覆盖了我们的业务场景，设计定义了不同场景的特点从数据采集到入库的方案。

